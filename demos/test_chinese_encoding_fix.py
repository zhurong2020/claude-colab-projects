#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¸­æ–‡OCRè¯†åˆ«ç¼–ç é—®é¢˜ä¿®å¤æµ‹è¯•
é’ˆå¯¹æ–¹æ¡ˆAï¼šç¯å¢ƒä¿®å¤ + ä»£ç ä¼˜åŒ–
"""

import os
import sys
import warnings
import locale
import pandas as pd
from paddleocr import PaddleOCR
from PIL import Image, ImageDraw, ImageFont

# è®¾ç½®ç¼–ç å’Œè­¦å‘Š
warnings.filterwarnings('ignore')
os.environ['PYTHONIOENCODING'] = 'utf-8'

def setup_encoding():
    """è®¾ç½®ç¼–ç ç¯å¢ƒ"""
    print("ğŸ”§ è®¾ç½®ç¼–ç ç¯å¢ƒ...")
    
    # å°è¯•è®¾ç½®UTF-8ç¼–ç 
    try:
        if sys.platform.startswith('linux'):
            locale.setlocale(locale.LC_ALL, 'C.UTF-8')
        else:
            locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
        print("âœ… Localeè®¾ç½®æˆåŠŸ")
    except locale.Error as e:
        print(f"âš ï¸ Localeè®¾ç½®å¤±è´¥: {e}")
        print("ğŸ“ ä½¿ç”¨é»˜è®¤ç¼–ç è®¾ç½®")
    
    # å¼ºåˆ¶è®¾ç½®stdoutç¼–ç 
    if hasattr(sys.stdout, 'reconfigure'):
        sys.stdout.reconfigure(encoding='utf-8')
        print("âœ… æ ‡å‡†è¾“å‡ºç¼–ç è®¾ç½®ä¸ºUTF-8")
    
    return True

def safe_chinese_print(text, confidence=None):
    """å®‰å…¨çš„ä¸­æ–‡å­—ç¬¦æ‰“å°å‡½æ•°"""
    try:
        # æ–¹æ³•1ï¼šç›´æ¥æ‰“å°ï¼ˆé€‚ç”¨äºUTF-8ç¯å¢ƒï¼‰
        if confidence is not None:
            output = f"{text} (ç½®ä¿¡åº¦: {confidence:.3f})"
        else:
            output = text
        print(output)
        return True
    except UnicodeEncodeError:
        try:
            # æ–¹æ³•2ï¼šä½¿ç”¨ASCIIè¡¨ç¤ºä¸å¯æ‰“å°å­—ç¬¦
            safe_text = text.encode('ascii', 'replace').decode('ascii')
            if confidence is not None:
                output = f"{safe_text} (ç½®ä¿¡åº¦: {confidence:.3f})"
            else:
                output = safe_text
            print(output)
            return True
        except Exception as e:
            # æ–¹æ³•3ï¼šæ˜¾ç¤ºå­—èŠ‚è¡¨ç¤º
            try:
                byte_repr = text.encode('utf-8')
                print(f"[å­—èŠ‚è¡¨ç¤º: {byte_repr}] (ç½®ä¿¡åº¦: {confidence:.3f})" if confidence else f"[å­—èŠ‚è¡¨ç¤º: {byte_repr}]")
                return True
            except Exception as final_e:
                print(f"âŒ å­—ç¬¦æ˜¾ç¤ºå¤±è´¥: {final_e}")
                return False

def analyze_chinese_characters(text):
    """åˆ†æå­—ç¬¦ä¸²ä¸­çš„ä¸­æ–‡å­—ç¬¦"""
    chinese_chars = []
    ascii_chars = []
    other_chars = []
    
    for char in text:
        if '\u4e00' <= char <= '\u9fff':  # ä¸­æ–‡å­—ç¬¦èŒƒå›´
            chinese_chars.append(char)
        elif char.isascii():
            ascii_chars.append(char)
        else:
            other_chars.append(char)
    
    return {
        'chinese_count': len(chinese_chars),
        'ascii_count': len(ascii_chars),
        'other_count': len(other_chars),
        'chinese_chars': chinese_chars,
        'ascii_chars': ascii_chars,
        'has_chinese': len(chinese_chars) > 0
    }

def create_test_chinese_document():
    """åˆ›å»ºæµ‹è¯•ç”¨çš„ä¸­æ–‡åŒ»ç–—æ–‡æ¡£"""
    print("ğŸ“„ åˆ›å»ºæµ‹è¯•ä¸­æ–‡åŒ»ç–—æ–‡æ¡£...")
    
    img = Image.new('RGB', (800, 600), color='white')
    draw = ImageDraw.Draw(img)
    
    # æ·»åŠ è¾¹æ¡†
    draw.rectangle([(10, 10), (790, 590)], outline='black', width=2)
    
    # ç®€å•çš„ä¸­æ–‡æ–‡æœ¬ï¼ˆé¿å…å¤æ‚å­—ç¬¦ï¼‰
    test_texts = [
        "åŒ»ç–—æŠ¥å‘Š",
        "æ‚£è€…ï¼šå¼ ä¸‰",
        "å¹´é¾„ï¼š45å²",
        "è¯Šæ–­ï¼šé«˜è¡€å‹",
        "è¯ç‰©ï¼šé™å‹ç‰‡",
        "å‰‚é‡ï¼š10mg",
        "é¢‘æ¬¡ï¼šæ¯æ—¥ä¸€æ¬¡",
        "åŒ»ç”Ÿï¼šæåŒ»ç”Ÿ"
    ]
    
    # ä½¿ç”¨ç®€å•å­—ä½“ç»˜åˆ¶
    try:
        font_paths = [
            '~/.fonts/simhei.ttf',
            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf'
        ]
        
        font = None
        for path in font_paths:
            expanded_path = os.path.expanduser(path)
            if os.path.exists(expanded_path):
                try:
                    font = ImageFont.truetype(expanded_path, 36)
                    print(f"âœ… ä½¿ç”¨å­—ä½“: {expanded_path}")
                    break
                except Exception as e:
                    print(f"âš ï¸ å­—ä½“åŠ è½½å¤±è´¥: {path} - {e}")
        
        if font is None:
            font = ImageFont.load_default()
            print("âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“")
        
        # ç»˜åˆ¶æ–‡å­—
        y_pos = 50
        for i, text in enumerate(test_texts):
            x_pos = 50 if i > 0 else 200  # æ ‡é¢˜å±…ä¸­
            draw.text((x_pos, y_pos), text, fill='black', font=font)
            y_pos += 60
        
        output_path = 'test_chinese_simple.png'
        img.save(output_path, quality=95)
        print(f"âœ… ä¸­æ–‡æµ‹è¯•æ–‡æ¡£å·²åˆ›å»º: {output_path}")
        return output_path
        
    except Exception as e:
        print(f"âŒ åˆ›å»ºä¸­æ–‡æ–‡æ¡£å¤±è´¥: {e}")
        return None

def test_ocr_with_encoding_fix():
    """æµ‹è¯•å¸¦ç¼–ç ä¿®å¤çš„OCRè¯†åˆ«"""
    
    print("ğŸ¥ ä¸­æ–‡OCRè¯†åˆ«ç¼–ç ä¿®å¤æµ‹è¯•")
    print("=" * 50)
    
    # è®¾ç½®ç¼–ç ç¯å¢ƒ
    setup_encoding()
    
    # åˆ›å»ºæµ‹è¯•æ–‡æ¡£
    test_doc = create_test_chinese_document()
    if not test_doc:
        print("âŒ æ— æ³•åˆ›å»ºæµ‹è¯•æ–‡æ¡£")
        return
    
    # åˆå§‹åŒ–OCR
    print("\nğŸ”§ åˆå§‹åŒ–PaddleOCR...")
    try:
        ocr = PaddleOCR(use_angle_cls=True, lang='ch')
        print("âœ… OCRå¼•æ“åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # è¿›è¡ŒOCRè¯†åˆ«
    print(f"\nğŸ” è¯†åˆ«æµ‹è¯•æ–‡æ¡£: {test_doc}")
    try:
        result = ocr.ocr(test_doc)
        
        if not result or len(result) == 0:
            print("âŒ OCRæ— è¯†åˆ«ç»“æœ")
            return
        
        page_result = result[0]
        extracted_texts = []
        
        # å¤„ç†è¯†åˆ«ç»“æœ
        if isinstance(page_result, dict) and 'rec_texts' in page_result:
            texts = page_result['rec_texts']
            scores = page_result['rec_scores']
            for text, score in zip(texts, scores):
                if text and text.strip():
                    extracted_texts.append({
                        'text': text.strip(),
                        'confidence': score
                    })
        elif page_result is not None:
            try:
                for line in page_result:
                    if (line and len(line) >= 2 and 
                        line[1] and len(line[1]) >= 2 and 
                        isinstance(line[1][0], str)):
                        
                        text = line[1][0]
                        confidence = line[1][1]
                        
                        if text and text.strip():
                            extracted_texts.append({
                                'text': text.strip(),
                                'confidence': confidence
                            })
            except Exception as e:
                print(f"âš ï¸ å¤„ç†è¯†åˆ«ç»“æœå¤±è´¥: {e}")
        
        # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
        print(f"\nğŸ“Š è¯†åˆ«ç»“æœ (å…±{len(extracted_texts)}è¡Œ):")
        print("-" * 60)
        
        chinese_detected = 0
        encoding_issues = 0
        successful_displays = 0
        
        for i, item in enumerate(extracted_texts, 1):
            text = item['text']
            confidence = item['confidence']
            
            # åˆ†æå­—ç¬¦ç»„æˆ
            char_analysis = analyze_chinese_characters(text)
            
            print(f"\nè¡Œ {i:2d}:")
            print(f"  åŸå§‹æ–‡æœ¬: {repr(text)}")
            print(f"  ç½®ä¿¡åº¦: {confidence:.3f}")
            print(f"  å­—ç¬¦åˆ†æ: ä¸­æ–‡{char_analysis['chinese_count']}ä¸ª, ASCII{char_analysis['ascii_count']}ä¸ª")
            
            # å°è¯•å®‰å…¨æ˜¾ç¤º
            print(f"  æ˜¾ç¤ºæµ‹è¯•: ", end="")
            if safe_chinese_print(text, confidence):
                successful_displays += 1
                if char_analysis['has_chinese']:
                    chinese_detected += 1
            else:
                encoding_issues += 1
        
        # ç»Ÿè®¡æŠ¥å‘Š
        print(f"\nğŸ“ˆ æµ‹è¯•ç»Ÿè®¡:")
        print(f"  æ€»è¯†åˆ«è¡Œæ•°: {len(extracted_texts)}")
        print(f"  åŒ…å«ä¸­æ–‡è¡Œæ•°: {chinese_detected}")
        print(f"  æˆåŠŸæ˜¾ç¤ºè¡Œæ•°: {successful_displays}")
        print(f"  ç¼–ç é—®é¢˜è¡Œæ•°: {encoding_issues}")
        
        # ä¿å­˜ç»“æœåˆ°CSV
        if extracted_texts:
            results_df = pd.DataFrame([
                {
                    'line_number': i,
                    'text': item['text'],
                    'confidence': item['confidence'],
                    'has_chinese': analyze_chinese_characters(item['text'])['has_chinese']
                }
                for i, item in enumerate(extracted_texts, 1)
            ])
            
            csv_path = 'chinese_ocr_encoding_test_results.csv'
            results_df.to_csv(csv_path, index=False, encoding='utf-8-sig')
            print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {csv_path}")
        
        # ç»“è®º
        print(f"\nğŸ¯ æµ‹è¯•ç»“è®º:")
        if chinese_detected > 0:
            print(f"âœ… æˆåŠŸæ£€æµ‹åˆ°ä¸­æ–‡å­—ç¬¦ï¼")
            print(f"âœ… ä¸­æ–‡è¯†åˆ«åŠŸèƒ½æ­£å¸¸")
            if encoding_issues == 0:
                print(f"âœ… ç¼–ç æ˜¾ç¤ºé—®é¢˜å·²è§£å†³")
            else:
                print(f"âš ï¸ éƒ¨åˆ†ç¼–ç æ˜¾ç¤ºä»éœ€ä¼˜åŒ–")
        else:
            print(f"âš ï¸ æœªæ£€æµ‹åˆ°ä¸­æ–‡å­—ç¬¦ï¼Œå¯èƒ½æ˜¯å›¾ç‰‡è´¨é‡æˆ–å­—ä½“é—®é¢˜")
        
    except Exception as e:
        print(f"âŒ OCRæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")

if __name__ == "__main__":
    test_ocr_with_encoding_fix()