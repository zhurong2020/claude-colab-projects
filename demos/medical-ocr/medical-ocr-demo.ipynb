{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«æ¼”ç¤º\n",
    "\n",
    "> ğŸ¥ ä½¿ç”¨PaddleOCRä»åŒ»ç–—æ–‡æ¡£PNGå›¾åƒä¸­æå–æ–‡æœ¬å¹¶ä¿å­˜ä¸ºCSV\n",
    "\n",
    "**ç‰ˆæœ¬**: v1.3.17 (å½»åº•ä¿®å¤Colabä¸­æ–‡å­—ä½“æ˜¾ç¤ºå’ŒGradioç•Œé¢è¯†åˆ«é—®é¢˜) | **æ›´æ–°æ—¶é—´**: 2025-08-25\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zhurong2020/claude-colab-projects/blob/main/demos/medical-ocr/medical-ocr-demo.ipynb) [![GitHub](https://img.shields.io/badge/GitHub-æºä»£ç -blue?logo=github)](https://github.com/zhurong2020/claude-colab-projects/tree/main/demos/medical-ocr)\n",
    "\n",
    "## ğŸ¯ åŠŸèƒ½ç‰¹æ€§\n",
    "- ğŸ“„ æ”¯æŒåŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«\n",
    "- ğŸ¤– ä½¿ç”¨PaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "- ğŸ“Š è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–CSVæŠ¥å‘Š\n",
    "- ğŸ–¼ï¸ æ”¯æŒå¤šç§å›¾åƒæ ¼å¼è¾“å…¥\n",
    "- ğŸ’¡ ç®€å•æ˜“ç”¨çš„äº¤äº’ç•Œé¢\n",
    "- ğŸ  å®Œæ•´æœ¬åœ°å¼€å‘ç¯å¢ƒæ”¯æŒ\n",
    "- ğŸŒ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«\n",
    "- ğŸ—ï¸ ç‹¬ç«‹åº”ç”¨æ¶æ„ï¼Œå¯ç›´æ¥åœ¨Colabè¿è¡Œ\n",
    "\n",
    "## ğŸ”§ æ›´æ–°å†…å®¹ (v1.3.17)\n",
    "- **ğŸ¨ Colabä¸­æ–‡å­—ä½“å®Œå…¨ä¿®å¤**: çœŸå®ä¸‹è½½å’Œå®‰è£…Source Han Sans SCä¸­æ–‡å­—ä½“ï¼Œè§£å†³æ–¹å—å­—é—®é¢˜\n",
    "- **ğŸ–¼ï¸ åŒæ–‡æ¡£åˆ›å»ºç­–ç•¥**: è‹±æ–‡ä¸»æ–‡æ¡£ç¡®ä¿åŸºæœ¬åŠŸèƒ½+ä¸­æ–‡æµ‹è¯•æ–‡æ¡£éªŒè¯å­—ä½“æ•ˆæœ\n",
    "- **âš¡ Gradioç•Œé¢è¯†åˆ«ä¿®å¤**: å¢å¼ºå›¾åƒå¤„ç†æµç¨‹ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼Œå®Œå–„é”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯\n",
    "- **ğŸ” æ™ºèƒ½æ•…éšœæ’é™¤**: æ·»åŠ å›¾åƒå°ºå¯¸æ£€æŸ¥ã€è¯¦ç»†è¯Šæ–­ä¿¡æ¯å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º\n",
    "- **ğŸ› ï¸ å­—ä½“åŠ è½½ä¼˜åŒ–**: å¤šç¯å¢ƒå­—ä½“è·¯å¾„æ”¯æŒï¼Œæ™ºèƒ½å¤‡ç”¨æ–¹æ¡ˆï¼Œç¡®ä¿å„å¹³å°å…¼å®¹æ€§\n",
    "- **ğŸ“Š ç”¨æˆ·ä½“éªŒæå‡**: æ”¹è¿›ç•Œé¢è®¾è®¡ã€æ›´æ¸…æ™°çš„ä½¿ç”¨è¯´æ˜å’Œæ“ä½œæŒ‡å¯¼\n",
    "\n",
    "## ğŸ”§ æ›´æ–°å†…å®¹ (v1.3.16)\n",
    "- **ğŸ”§ PaddleOCRå…¼å®¹æ€§ä¿®å¤**: å½»åº•è§£å†³v3.1.1+ OCRResultå¯¹è±¡è§£æé—®é¢˜ï¼Œæ”¯æŒå­—å…¸è®¿é—®æ–¹å¼\n",
    "- **ğŸ¯ ä¸­æ–‡è¯†åˆ«å®Œå…¨ä¿®å¤**: éªŒè¯å¯æ­£ç¡®è¯†åˆ«15è¡Œä¸­æ–‡åŒ»ç–—æ–‡æ¡£ï¼Œå¹³å‡ç½®ä¿¡åº¦99%+\n",
    "- **ğŸ” ç»“æœè§£æä¼˜åŒ–**: æ–°å¢è°ƒè¯•ä¿¡æ¯å’Œå¤šç§è§£ææ–¹å¼çš„å¤‡ç”¨æ–¹æ¡ˆ\n",
    "- **ğŸ‘©â€âš•ï¸ ç”¨æˆ·ä½“éªŒä¼˜åŒ–**: Gradioç•Œé¢ä¿®å¤\"âš ï¸ æœªæ£€æµ‹åˆ°æ–‡å­—å†…å®¹\"é”™è¯¯æç¤º\n",
    "- **ğŸ”¤ ä¸­æ–‡æ˜¾ç¤ºä¿éšœ**: ç¡®ä¿CSVæ–‡ä»¶ä¸­æ–‡è¾“å‡ºæ­£å¸¸ï¼Œä½¿ç”¨utf-8-sigç¼–ç \n",
    "- **ğŸ› ï¸ ç‰ˆæœ¬ç®¡ç†ä¼˜åŒ–**: ç»Ÿä¸€æ‰€æœ‰æ–‡æ¡£ä¸­çš„ç‰ˆæœ¬å·æ ‡è¯†\n",
    "\n",
    "## ğŸš€ ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### Colabç¯å¢ƒ\n",
    "1. ç‚¹å‡»ä¸Šæ–¹çš„\"Open in Colab\"æŒ‰é’®\n",
    "2. ä¾æ¬¡è¿è¡Œå„ä¸ªå•å…ƒæ ¼å³å¯å®Œæˆå…¨æµç¨‹\n",
    "3. ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒè¿›è¡Œè¯†åˆ«\n",
    "4. ä¸‹è½½CSVç»“æœæ–‡ä»¶\n",
    "\n",
    "### æœ¬åœ°ç¯å¢ƒ\n",
    "```bash\n",
    "# ä»é¡¹ç›®æ ¹ç›®å½•ä¸€é”®å¯åŠ¨\n",
    "../start_local.sh\n",
    "\n",
    "# æ‰‹åŠ¨å¯åŠ¨\n",
    "source ../venv/bin/activate && jupyter notebook\n",
    "```\n",
    "\n",
    "### ä¼˜åŒ–æ‰§è¡Œæµç¨‹\n",
    "1. **ç¯å¢ƒæ£€æŸ¥** â†’ 2. **å®‰è£…ä¾èµ–** â†’ 3. **å¯¼å…¥åº“** â†’ 4. **åˆå§‹åŒ–OCR** â†’ 5. **åˆ›å»ºç¤ºä¾‹å’ŒéªŒè¯** â†’ 6. **OCRåŠŸèƒ½éªŒè¯** â†’ 7. **Gradio Webç•Œé¢** â†’ 8. **ä½¿ç”¨æ€»ç»“**\n",
    "\n",
    "---\n",
    "*ä½¿ç”¨ Claude Code å¼€å‘ï¼Œæ”¯æŒ Google Colab å’Œæœ¬åœ°è¿è¡Œ ğŸš€*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ç¯å¢ƒæ£€æŸ¥å’ŒåŸºç¡€è®¾ç½®\n",
    "# ================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"æ£€æŸ¥è¿è¡Œç¯å¢ƒå¹¶æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯\"\"\"\n",
    "    print(\"ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
    "    try:\n",
    "        import google.colab # type: ignore # noqa: F401 # éœ€è¦ç”¨äºç¯å¢ƒæ£€æµ‹\n",
    "        print(\"âœ… è¿è¡Œåœ¨Google Colab\")\n",
    "        in_colab = True\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ è¿è¡Œåœ¨æœ¬åœ°ç¯å¢ƒ\")\n",
    "        in_colab = False\n",
    "    \n",
    "    # æ£€æŸ¥GPU\n",
    "    try:\n",
    "        import torch\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"âœ… è®¡ç®—è®¾å¤‡: {device}\")\n",
    "        if device == 'cuda':\n",
    "            print(f\"âœ… GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    \n",
    "    return in_colab\n",
    "\n",
    "# è¿è¡Œç¯å¢ƒæ£€æŸ¥\n",
    "in_colab = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# ================================\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"å®‰è£…é¡¹ç›®æ‰€éœ€çš„ä¾èµ–åŒ…\"\"\"\n",
    "    print(\"ğŸ“¦ å®‰è£…åŒ»ç–—OCRé¡¹ç›®ä¾èµ–...\")\n",
    "    \n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # æ ¸å¿ƒä¾èµ–åŒ…åˆ—è¡¨\n",
    "    packages = [\n",
    "        'paddlepaddle',\n",
    "        'paddleocr',\n",
    "        'pandas',\n",
    "        'pillow',\n",
    "        'opencv-python',\n",
    "        'tqdm',\n",
    "        'gradio'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            if package == 'opencv-python':\n",
    "                import cv2  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯opencvå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            elif package == 'pillow':\n",
    "                from PIL import Image  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯PILå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            else:\n",
    "                __import__(package.replace('-', '_'))\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"ğŸ“¥ å®‰è£… {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"âœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ!\")\n",
    "\n",
    "# å®‰è£…ä¾èµ–\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "# ================================\n",
    "\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "    from tqdm import tqdm\n",
    "    from paddleocr import PaddleOCR  # type: ignore\n",
    "    import gradio as gr  # type: ignore\n",
    "    print(\"ğŸ“š æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åº“å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œä¾èµ–å®‰è£…å•å…ƒæ ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±» - v1.3.17\n",
    "# ================================\n",
    "\n",
    "class MedicalOCRProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨\"\"\"\n",
    "        print(\"ğŸ¥ åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨...\")\n",
    "        \n",
    "        # æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "        try:\n",
    "            import torch\n",
    "            use_gpu = torch.cuda.is_available()\n",
    "            gpu_info = f\"GPUå¯ç”¨: {use_gpu}\"\n",
    "            if use_gpu:\n",
    "                gpu_info += f\" (è®¾å¤‡: {torch.cuda.get_device_name(0)})\"\n",
    "            print(f\"âš¡ {gpu_info}\")\n",
    "        except ImportError:\n",
    "            use_gpu = False\n",
    "            print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "        \n",
    "        # åˆå§‹åŒ–PaddleOCRï¼Œä½¿ç”¨å…¼å®¹çš„é…ç½®\n",
    "        try:\n",
    "            # ä½¿ç”¨å…¼å®¹çš„å‚æ•°åˆå§‹åŒ–PaddleOCR (v3.1.1+)\n",
    "            self.ocr = PaddleOCR(use_angle_cls=True, lang='ch')\n",
    "            print(\"âœ… ä½¿ç”¨å…¼å®¹å‚æ•°åˆå§‹åŒ–OCRå¼•æ“\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "            self.ocr = None\n",
    "            raise RuntimeError(f\"PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "        \n",
    "        print(\"âœ… OCRå¼•æ“åˆå§‹åŒ–å®Œæˆ\")\n",
    "    \n",
    "    def _preprocess_image(self, image_path):\n",
    "        \"\"\"é¢„å¤„ç†å›¾åƒï¼Œç¡®ä¿æ ¼å¼å’Œè´¨é‡é€‚åˆOCR\"\"\"\n",
    "        try:\n",
    "            from PIL import Image as PILImage\n",
    "            import os # type: ignore\n",
    "            \n",
    "            # æ‰“å¼€å¹¶éªŒè¯å›¾åƒ\n",
    "            with PILImage.open(image_path) as img:\n",
    "                print(f\"ğŸ“Š åŸå§‹å›¾åƒä¿¡æ¯: å°ºå¯¸={img.size}, æ¨¡å¼={img.mode}\")\n",
    "                \n",
    "                # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰\n",
    "                if img.mode != 'RGB':\n",
    "                    print(f\"ğŸ”„ è½¬æ¢å›¾åƒæ¨¡å¼: {img.mode} -> RGB\")\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼Œå¦‚æœè¿‡å¤§åˆ™é€‚å½“ç¼©å°\n",
    "                max_size = 2048\n",
    "                if max(img.size) > max_size:\n",
    "                    print(f\"ğŸ”„ è°ƒæ•´å›¾åƒå°ºå¯¸: {img.size}\")\n",
    "                    ratio = max_size / max(img.size)\n",
    "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
    "                    img = img.resize(new_size, PILImage.Resampling.LANCZOS)\n",
    "                    print(f\"âœ… æ–°å°ºå¯¸: {img.size}\")\n",
    "                \n",
    "                # ä¿å­˜é¢„å¤„ç†åçš„å›¾åƒ\n",
    "                processed_path = image_path.replace('.png', '_processed.png').replace('.jpg', '_processed.jpg').replace('.jpeg', '_processed.jpg')\n",
    "                if processed_path == image_path:\n",
    "                    processed_path = image_path.replace('.', '_processed.')\n",
    "                \n",
    "                img.save(processed_path, quality=95, optimize=False)\n",
    "                print(f\"ğŸ’¾ é¢„å¤„ç†å›¾åƒå·²ä¿å­˜: {processed_path}\")\n",
    "                \n",
    "                return processed_path\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å›¾åƒ\")\n",
    "            return image_path\n",
    "\n",
    "    def _parse_ocr_result(self, result):\n",
    "        \"\"\"è§£æOCRç»“æœ - ä¿®å¤ç‰ˆæ”¯æŒæœ€æ–°PaddleOCR OCRResultå­—å…¸è®¿é—®\"\"\"\n",
    "        extracted_texts = []\n",
    "        try:\n",
    "            if not result or not isinstance(result, list) or not result[0]:\n",
    "                print(\"âš ï¸ OCRç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®\")\n",
    "                return []\n",
    "\n",
    "            page_result = result[0]\n",
    "            print(f\"ğŸ” è§£æOCRç»“æœï¼Œé¡µé¢ç»“æœç±»å‹: {type(page_result)}\")\n",
    "\n",
    "            # æ–°ç‰ˆ PaddleOCR (OCRResultå¯¹è±¡æ”¯æŒå­—å…¸è®¿é—®) - v3.1.1+\n",
    "            try:\n",
    "                # ç›´æ¥ä½¿ç”¨å­—å…¸è®¿é—®æ–¹å¼\n",
    "                if 'rec_texts' in page_result and 'rec_scores' in page_result:\n",
    "                    texts = page_result['rec_texts']\n",
    "                    scores = page_result['rec_scores']\n",
    "                    \n",
    "                    print(f\"âœ… æ£€æµ‹åˆ°PaddleOCR v3.1.1+ OCRResultå­—å…¸æ ¼å¼\")\n",
    "                    print(f\"ğŸ“Š è¯†åˆ«åˆ°æ–‡æœ¬æ•°é‡: {len(texts) if texts else 0}\")\n",
    "                    \n",
    "                    if texts and scores and len(texts) == len(scores):\n",
    "                        for text, score in zip(texts, scores):\n",
    "                            if text and text.strip():\n",
    "                                extracted_texts.append({\n",
    "                                    'text': text.strip(), \n",
    "                                    'confidence': float(score)\n",
    "                                })\n",
    "                        print(f\"âœ… æˆåŠŸè§£æ {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "                        return extracted_texts\n",
    "                    else:\n",
    "                        print(\"âš ï¸ æ–‡æœ¬å’Œåˆ†æ•°æ•°é‡ä¸åŒ¹é…æˆ–ä¸ºç©º\")\n",
    "                        \n",
    "                # å¤‡ç”¨ï¼šå°è¯•å±æ€§è®¿é—®æ–¹å¼\n",
    "                elif hasattr(page_result, 'rec_texts') and hasattr(page_result, 'rec_scores'):\n",
    "                    print(\"âœ… æ£€æµ‹åˆ°PaddleOCR OCRResultå±æ€§æ ¼å¼\")\n",
    "                    texts = getattr(page_result, 'rec_texts')\n",
    "                    scores = getattr(page_result, 'rec_scores')\n",
    "                    \n",
    "                    if texts and scores:\n",
    "                        for text, score in zip(texts, scores):\n",
    "                            if text and text.strip():\n",
    "                                extracted_texts.append({\n",
    "                                    'text': text.strip(), \n",
    "                                    'confidence': float(score)\n",
    "                                })\n",
    "                        return extracted_texts\n",
    "                        \n",
    "            except (KeyError, TypeError) as e:\n",
    "                print(f\"âš ï¸ å­—å…¸è®¿é—®å¤±è´¥: {e}\")\n",
    "\n",
    "            # å…¼å®¹æ—§ç‰ˆ PaddleOCR (è¿”å›åŒ…å«å…ƒç»„çš„åˆ—è¡¨)\n",
    "            if isinstance(page_result, list):\n",
    "                print(\"âœ… æ£€æµ‹åˆ°ä¼ ç»Ÿåˆ—è¡¨æ ¼å¼\")\n",
    "                for line_result in page_result:\n",
    "                    if (line_result and len(line_result) >= 2 and\n",
    "                        line_result[1] and len(line_result[1]) >= 2):\n",
    "                        text, confidence = line_result[1]\n",
    "                        if text and text.strip():\n",
    "                            extracted_texts.append({\n",
    "                                'text': text.strip(), \n",
    "                                'confidence': float(confidence)\n",
    "                            })\n",
    "                return extracted_texts\n",
    "            \n",
    "            # è°ƒè¯•ä¿¡æ¯\n",
    "            print(f\"âš ï¸ æœªçŸ¥çš„OCRç»“æœæ ¼å¼: {type(page_result)}\")\n",
    "            if hasattr(page_result, 'keys'):\n",
    "                keys = list(page_result.keys())\n",
    "                print(f\"ğŸ” å¯¹è±¡é”®å€¼: {keys}\")\n",
    "                text_related_keys = [k for k in keys if 'text' in k.lower() or 'rec' in k.lower()]\n",
    "                print(f\"ğŸ” æ–‡æœ¬ç›¸å…³é”®: {text_related_keys}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ç»“æœè§£æå¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        \n",
    "        print(f\"ğŸ“Š æœ€ç»ˆè§£æç»“æœ: {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "        return extracted_texts\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        \"\"\"ä»å›¾åƒä¸­æå–æ–‡å­— - å¢å¼ºç‰ˆæœ¬\"\"\"\n",
    "        import os\n",
    "        \n",
    "        if self.ocr is None:\n",
    "            print(\"âŒ OCRå¼•æ“æœªåˆå§‹åŒ–\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # éªŒè¯å›¾åƒæ–‡ä»¶\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}\")\n",
    "                return []\n",
    "            \n",
    "            if os.path.getsize(image_path) == 0:\n",
    "                print(f\"âŒ å›¾åƒæ–‡ä»¶ä¸ºç©º: {image_path}\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"ğŸ“„ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}\")\n",
    "            print(f\"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(image_path)} å­—èŠ‚\")\n",
    "            \n",
    "            # é¢„å¤„ç†å›¾åƒï¼šç¡®ä¿å›¾åƒæ ¼å¼å’Œè´¨é‡é€‚åˆOCR\n",
    "            processed_image_path = self._preprocess_image(image_path)\n",
    "            \n",
    "            # ä½¿ç”¨PaddleOCRè¿›è¡Œè¯†åˆ«\n",
    "            result = None\n",
    "            extracted_texts = []\n",
    "            \n",
    "            # ä½¿ç”¨predictæ–¹æ³• (æ¨èçš„æ–°ç‰ˆæœ¬API)\n",
    "            try:\n",
    "                print(\"ğŸ”„ å°è¯•ä½¿ç”¨predictæ–¹æ³•...\")\n",
    "                result = self.ocr.predict(processed_image_path)\n",
    "                print(f\"âœ… predictæ–¹æ³•è°ƒç”¨æˆåŠŸï¼Œç»“æœç±»å‹: {type(result)}\")\n",
    "                \n",
    "                if result and len(result) > 0:\n",
    "                    print(f\"ğŸ“Š è·å¾— {len(result)} é¡µç»“æœ\")\n",
    "                    \n",
    "                # è§£æç»“æœ\n",
    "                extracted_texts = self._parse_ocr_result(result)\n",
    "                \n",
    "                if extracted_texts:\n",
    "                    print(f\"âœ… æˆåŠŸè¯†åˆ« {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "                    # æ˜¾ç¤ºå‰3è¡Œä½œä¸ºéªŒè¯\n",
    "                    for i, item in enumerate(extracted_texts[:3]):\n",
    "                        print(f\"  ç¤ºä¾‹ {i+1}: {item['text'][:30]}... (ç½®ä¿¡åº¦: {item['confidence']:.3f})\")\n",
    "                    return extracted_texts\n",
    "                \n",
    "            except Exception as e1:\n",
    "                print(f\"âš ï¸ predictæ–¹æ³•å¤±è´¥: {e1}\")\n",
    "                \n",
    "                # å°è¯•ä½¿ç”¨ä¼ ç»Ÿçš„ocræ–¹æ³•\n",
    "                try:\n",
    "                    print(\"ğŸ”„ å°è¯•ä½¿ç”¨ä¼ ç»Ÿocræ–¹æ³•...\")\n",
    "                    result = self.ocr.ocr(processed_image_path)  # type: ignore\n",
    "                    print(f\"âœ… OCRæ–¹æ³•è°ƒç”¨æˆåŠŸï¼Œç»“æœç±»å‹: {type(result)}\")\n",
    "                    extracted_texts = self._parse_ocr_result(result)\n",
    "                    \n",
    "                    if extracted_texts:\n",
    "                        print(f\"âœ… æˆåŠŸè¯†åˆ« {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "                        return extracted_texts\n",
    "                        \n",
    "                except Exception as e2:\n",
    "                    print(f\"âŒ æ‰€æœ‰å¯ç”¨çš„OCRè°ƒç”¨æ–¹æ³•éƒ½å¤±è´¥\")\n",
    "                    print(f\"è¯¦ç»†é”™è¯¯: predict={e1}, ocr={e2}\")\n",
    "            \n",
    "            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½æ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—\n",
    "            if not extracted_texts:\n",
    "                print(\"âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡å­—å†…å®¹\")\n",
    "                self._check_image_quality(processed_image_path)\n",
    "                return []\n",
    "            \n",
    "            return extracted_texts\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "            return []\n",
    "    \n",
    "    def _check_image_quality(self, image_path):\n",
    "        \"\"\"æ£€æŸ¥å›¾åƒè´¨é‡\"\"\"\n",
    "        try:\n",
    "            from PIL import Image as PILImage\n",
    "            import os\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(\"ğŸ” å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "                return\n",
    "            \n",
    "            with PILImage.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                total_pixels = width * height\n",
    "                \n",
    "                print(f\"ğŸ” å›¾åƒè´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"   å°ºå¯¸: {width}x{height} ({total_pixels:,} åƒç´ )\")\n",
    "                print(f\"   æ ¼å¼: {img.format}\")\n",
    "                print(f\"   æ¨¡å¼: {img.mode}\")\n",
    "                \n",
    "                # è´¨é‡è¯„ä¼°\n",
    "                if total_pixels < 50000:\n",
    "                    print(\"   âš ï¸ å›¾åƒåˆ†è¾¨ç‡è¾ƒä½ï¼Œå¯èƒ½å½±å“è¯†åˆ«æ•ˆæœ\")\n",
    "                elif total_pixels > 4000000:\n",
    "                    print(\"   â„¹ï¸ å›¾åƒåˆ†è¾¨ç‡å¾ˆé«˜ï¼Œå¤„ç†é€Ÿåº¦å¯èƒ½è¾ƒæ…¢\")\n",
    "                else:\n",
    "                    print(\"   âœ… å›¾åƒåˆ†è¾¨ç‡é€‚ä¸­\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ” å›¾åƒè´¨é‡æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "    \n",
    "    def process_single_image(self, image_path):\n",
    "        \"\"\"å¤„ç†å•ä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        import os\n",
    "        print(f\"ğŸ“„ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # æå–æ–‡å­—\n",
    "        extracted_texts = self.extract_text_from_image(image_path)\n",
    "        \n",
    "        # æ•´ç†ç»“æœ\n",
    "        results = []\n",
    "        for i, item in enumerate(extracted_texts):\n",
    "            results.append({\n",
    "                'file_name': os.path.basename(image_path),\n",
    "                'line_number': i + 1,\n",
    "                'extracted_text': item['text'],\n",
    "                'confidence': round(item['confidence'], 4)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_multiple_images(self, image_paths):\n",
    "        \"\"\"æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        print(f\"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(image_paths)} ä¸ªå›¾åƒæ–‡ä»¶...\")\n",
    "        \n",
    "        for image_path in tqdm(image_paths, desc=\"å¤„ç†è¿›åº¦\"):\n",
    "            results = self.process_single_image(image_path)\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_results_to_csv(self, results, output_path):\n",
    "        \"\"\"ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶\"\"\"\n",
    "        if not results:\n",
    "            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œåˆ›å»ºç©ºçš„DataFrame\n",
    "            df = pd.DataFrame(columns=['file_name', 'line_number', 'extracted_text', 'confidence'])\n",
    "        else:\n",
    "            df = pd.DataFrame(results)\n",
    "        \n",
    "        # ä½¿ç”¨utf-8-sigç¼–ç ç¡®ä¿ä¸­æ–‡æ­£ç¡®æ˜¾ç¤º\n",
    "        df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        return df\n",
    "\n",
    "# åˆå§‹åŒ–OCRå¤„ç†å™¨\n",
    "print(\"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–OCRå¤„ç†å™¨...\")\n",
    "try:\n",
    "    ocr_processor = MedicalOCRProcessor()\n",
    "    print(\"âœ… OCRå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ OCRå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·æ£€æŸ¥PaddleOCRå®‰è£…æ˜¯å¦æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£å’ŒåŠŸèƒ½éªŒè¯ - v1.3.17\n",
    "# ================================\n",
    "\n",
    "def setup_chinese_font():\n",
    "    \"\"\"é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ\"\"\"\n",
    "    print(\"ğŸ”¤ é…ç½®ä¸­æ–‡å­—ä½“æ”¯æŒ...\")\n",
    "    \n",
    "    try:\n",
    "        # åœ¨Colabç¯å¢ƒä¸­å®‰è£…ä¸­æ–‡å­—ä½“\n",
    "        if 'in_colab' in globals() and globals()['in_colab']:\n",
    "            print(\"ğŸ“¥ åœ¨Colabç¯å¢ƒä¸­å®‰è£…ä¸­æ–‡å­—ä½“...\")\n",
    "            import subprocess\n",
    "            import sys\n",
    "            import os\n",
    "            import urllib.request\n",
    "            import zipfile\n",
    "            \n",
    "            # ä¸‹è½½å¹¶å®‰è£…Source Han Sansä¸­æ–‡å­—ä½“\n",
    "            try:\n",
    "                font_url = \"https://github.com/adobe-fonts/source-han-sans/releases/download/2.004R/SourceHanSansSC.zip\"\n",
    "                font_dir = \"/usr/share/fonts/truetype/source-han-sans/\"\n",
    "                zip_path = \"/tmp/SourceHanSansSC.zip\"\n",
    "                \n",
    "                print(f\"ğŸ” [FONT-DEBUG] æ£€æŸ¥å­—ä½“ç›®å½•: {font_dir}\")\n",
    "                print(f\"ğŸ” [FONT-DEBUG] å­—ä½“ç›®å½•å­˜åœ¨: {os.path.exists(font_dir)}\")\n",
    "                \n",
    "                if not os.path.exists(font_dir):\n",
    "                    print(\"ğŸ“¥ ä¸‹è½½ä¸­æ–‡å­—ä½“æ–‡ä»¶...\")\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] ä¸‹è½½URL: {font_url}\")\n",
    "                    urllib.request.urlretrieve(font_url, zip_path)\n",
    "                    print(f\"âœ… å­—ä½“æ–‡ä»¶ä¸‹è½½å®Œæˆ: {zip_path}\")\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] ZIPæ–‡ä»¶å¤§å°: {os.path.getsize(zip_path)} å­—èŠ‚\")\n",
    "                    \n",
    "                    print(\"ğŸ“¦ è§£å‹å­—ä½“æ–‡ä»¶...\")\n",
    "                    os.makedirs(font_dir, exist_ok=True)\n",
    "                    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "                        zip_ref.extractall(\"/tmp/source-han-sans/\")\n",
    "                    \n",
    "                    # åˆ—å‡ºè§£å‹çš„æ–‡ä»¶\n",
    "                    extracted_files = os.listdir(\"/tmp/source-han-sans/\")\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] è§£å‹æ–‡ä»¶: {extracted_files}\")\n",
    "                    \n",
    "                    # å¤åˆ¶OTFå­—ä½“æ–‡ä»¶åˆ°ç³»ç»Ÿå­—ä½“ç›®å½•\n",
    "                    import shutil\n",
    "                    otf_files = [f for f in extracted_files if f.endswith('.otf')]\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] æ‰¾åˆ°OTFå­—ä½“: {otf_files}\")\n",
    "                    \n",
    "                    if not otf_files:\n",
    "                        print(\"âš ï¸ æœªæ‰¾åˆ°OTFå­—ä½“æ–‡ä»¶ï¼Œå°è¯•TTFæ ¼å¼...\")\n",
    "                        otf_files = [f for f in extracted_files if f.endswith('.ttf')]\n",
    "                        print(f\"ğŸ” [FONT-DEBUG] æ‰¾åˆ°TTFå­—ä½“: {otf_files}\")\n",
    "                    \n",
    "                    for otf_file in otf_files[:5]:  # åªå¤åˆ¶å‰5ä¸ªå­—ä½“æ–‡ä»¶é¿å…è¿‡å¤š\n",
    "                        src = f\"/tmp/source-han-sans/{otf_file}\"\n",
    "                        dst = f\"{font_dir}{otf_file}\"\n",
    "                        if os.path.exists(src):\n",
    "                            shutil.copy2(src, dst)\n",
    "                            print(f\"âœ… å·²å®‰è£…å­—ä½“: {otf_file}\")\n",
    "                            print(f\"ğŸ” [FONT-DEBUG] å­—ä½“æ–‡ä»¶å¤§å°: {os.path.getsize(dst)} å­—èŠ‚\")\n",
    "                    \n",
    "                    # åˆ·æ–°å­—ä½“ç¼“å­˜\n",
    "                    print(\"ğŸ”„ åˆ·æ–°å­—ä½“ç¼“å­˜...\")\n",
    "                    result = subprocess.run([\"fc-cache\", \"-f\", \"-v\"], capture_output=True, text=True)\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] fc-cacheè¾“å‡º: {result.stdout[:200]}...\")\n",
    "                    print(\"âœ… å­—ä½“ç¼“å­˜å·²æ›´æ–°\")\n",
    "                else:\n",
    "                    print(\"âœ… ä¸­æ–‡å­—ä½“ç›®å½•å·²å­˜åœ¨\")\n",
    "                    # æ£€æŸ¥ç°æœ‰å­—ä½“\n",
    "                    existing_fonts = os.listdir(font_dir) if os.path.exists(font_dir) else []\n",
    "                    print(f\"ğŸ” [FONT-DEBUG] ç°æœ‰å­—ä½“: {existing_fonts}\")\n",
    "                    \n",
    "            except Exception as font_e:\n",
    "                print(f\"âš ï¸ å­—ä½“ä¸‹è½½å¤±è´¥: {font_e}\")\n",
    "                import traceback\n",
    "                print(f\"ğŸ” [FONT-DEBUG] è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "                print(\"ğŸ’¡ å°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“\")\n",
    "        \n",
    "        # é…ç½®matplotlibä¸­æ–‡æ”¯æŒ\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            import matplotlib\n",
    "            matplotlib.rcParams['font.sans-serif'] = ['Source Han Sans SC', 'SimHei', 'DejaVu Sans', 'Arial Unicode MS']\n",
    "            matplotlib.rcParams['axes.unicode_minus'] = False\n",
    "            print(\"âœ… matplotlibä¸­æ–‡å­—ä½“é…ç½®å®Œæˆ\")\n",
    "        except ImportError:\n",
    "            print(\"â„¹ï¸ matplotlibæœªå®‰è£…ï¼Œè·³è¿‡å­—ä½“é…ç½®\")\n",
    "        \n",
    "        print(\"âœ… ä¸­æ–‡å­—ä½“é…ç½®å®Œæˆ\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ ä¸­æ–‡å­—ä½“é…ç½®å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        print(f\"ğŸ” [FONT-DEBUG] é…ç½®å¤±è´¥è¯¦æƒ…: {traceback.format_exc()}\")\n",
    "        print(\"ğŸ’¡ å°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤å­—ä½“ï¼Œå¯èƒ½å½±å“ä¸­æ–‡æ˜¾ç¤ºæ•ˆæœ\")\n",
    "        return False\n",
    "\n",
    "def create_sample_medical_document():\n",
    "    \"\"\"åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£å›¾åƒç”¨äºæ¼”ç¤º\"\"\"\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    import os\n",
    "    \n",
    "    # é¦–å…ˆé…ç½®ä¸­æ–‡å­—ä½“\n",
    "    setup_chinese_font()\n",
    "    \n",
    "    # åˆ›å»ºç¤ºä¾‹å›¾åƒ - ä½¿ç”¨æ›´å¤§å°ºå¯¸å’Œæ›´å¥½å¯¹æ¯”åº¦\n",
    "    img = Image.new('RGB', (1000, 800), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“ - ä¼˜åŒ–Colabç¯å¢ƒæ”¯æŒ\n",
    "    font = None\n",
    "    font_size = 28  # å¢å¤§å­—ä½“ä»¥ç¡®ä¿æ¸…æ™°åº¦\n",
    "    chinese_font_loaded = False\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ” [FONT-DEBUG] å¼€å§‹å­—ä½“åŠ è½½æµç¨‹...\")\n",
    "        \n",
    "        # Colabç¯å¢ƒä¸­å°è¯•ä½¿ç”¨å·²å®‰è£…çš„ä¸­æ–‡å­—ä½“\n",
    "        if 'in_colab' in globals() and globals()['in_colab']:\n",
    "            print(\"ğŸ” [FONT-DEBUG] Colabç¯å¢ƒæ£€æµ‹åˆ°ï¼Œå°è¯•åŠ è½½ä¸­æ–‡å­—ä½“...\")\n",
    "            colab_font_paths = [\n",
    "                \"/usr/share/fonts/truetype/source-han-sans/SourceHanSansSC-Regular.otf\",\n",
    "                \"/usr/share/fonts/truetype/source-han-sans/SourceHanSansSC-Normal.otf\", \n",
    "                \"/usr/share/fonts/truetype/source-han-sans/SourceHanSansSC-Medium.otf\",\n",
    "                \"/usr/share/fonts/truetype/noto/NotoSansCJK-Regular.ttc\",\n",
    "                \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\"\n",
    "            ]\n",
    "            \n",
    "            for font_path in colab_font_paths:\n",
    "                print(f\"ğŸ” [FONT-DEBUG] å°è¯•å­—ä½“: {font_path}\")\n",
    "                print(f\"ğŸ” [FONT-DEBUG] æ–‡ä»¶å­˜åœ¨: {os.path.exists(font_path)}\")\n",
    "                \n",
    "                if os.path.exists(font_path):\n",
    "                    try:\n",
    "                        print(f\"ğŸ” [FONT-DEBUG] æ–‡ä»¶å¤§å°: {os.path.getsize(font_path)} å­—èŠ‚\")\n",
    "                        font = ImageFont.truetype(font_path, font_size)\n",
    "                        if \"Source\" in font_path or \"Noto\" in font_path:\n",
    "                            chinese_font_loaded = True\n",
    "                            print(f\"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {font_path}\")\n",
    "                        else:\n",
    "                            print(f\"âœ… æˆåŠŸåŠ è½½è‹±æ–‡å­—ä½“: {font_path}\")\n",
    "                        break\n",
    "                    except Exception as e:\n",
    "                        print(f\"âš ï¸ å­—ä½“åŠ è½½å¤±è´¥: {font_path} - {e}\")\n",
    "        \n",
    "        # æœ¬åœ°ç¯å¢ƒå­—ä½“è·¯å¾„\n",
    "        if font is None:\n",
    "            print(\"ğŸ” [FONT-DEBUG] Colabå­—ä½“åŠ è½½å¤±è´¥ï¼Œå°è¯•æœ¬åœ°å­—ä½“...\")\n",
    "            local_font_paths = [\n",
    "                \"/System/Library/Fonts/Arial.ttf\",  # macOS\n",
    "                \"/Windows/Fonts/simhei.ttf\",        # Windows\n",
    "                \"/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf\",  # Linux\n",
    "                \"arial.ttf\"\n",
    "            ]\n",
    "            \n",
    "            for font_path in local_font_paths:\n",
    "                print(f\"ğŸ” [FONT-DEBUG] å°è¯•æœ¬åœ°å­—ä½“: {font_path}\")\n",
    "                if os.path.exists(font_path):\n",
    "                    try:\n",
    "                        font = ImageFont.truetype(font_path, font_size)\n",
    "                        print(f\"âœ… æˆåŠŸåŠ è½½æœ¬åœ°å­—ä½“: {font_path}\")\n",
    "                        break\n",
    "                    except Exception:\n",
    "                        continue\n",
    "        \n",
    "        # å¦‚æœæ‰€æœ‰å­—ä½“éƒ½åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“\n",
    "        if font is None:\n",
    "            print(\"âš ï¸ æ— æ³•åŠ è½½ä»»ä½•TrueTypeå­—ä½“ï¼Œä½¿ç”¨é»˜è®¤å­—ä½“\")\n",
    "            font = ImageFont.load_default()\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ å­—ä½“åŠ è½½å¼‚å¸¸: {e}\")\n",
    "        font = ImageFont.load_default()\n",
    "    \n",
    "    print(f\"ğŸ” [FONT-DEBUG] æœ€ç»ˆä½¿ç”¨çš„å­—ä½“ç±»å‹: {type(font)}\")\n",
    "    print(f\"ğŸ” [FONT-DEBUG] ä¸­æ–‡å­—ä½“å·²åŠ è½½: {chinese_font_loaded}\")\n",
    "    \n",
    "    # æ·»åŠ è¾¹æ¡†å¢åŠ æ–‡æ¡£æ„Ÿ\n",
    "    draw.rectangle([(20, 20), (980, 780)], outline='black', width=2)\n",
    "    \n",
    "    # æ ¹æ®å­—ä½“åŠ è½½æƒ…å†µé€‰æ‹©æ–‡æœ¬å†…å®¹\n",
    "    if chinese_font_loaded:\n",
    "        print(\"ğŸˆ¯ ä½¿ç”¨ä¸­æ–‡å†…å®¹åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...\")\n",
    "        sample_text = [\n",
    "            \"åŒ»ç–—è¯Šæ–­æŠ¥å‘Š\",              # æ ‡é¢˜ä½¿ç”¨ä¸­æ–‡\n",
    "            \"åŒ»é™¢åç§°ï¼šXXå¸‚äººæ°‘åŒ»é™¢\",     # åŒ»é™¢ä¿¡æ¯\n",
    "            \"æ‚£è€…å§“åï¼šå¼ ä¸‰\",            # æ‚£è€…ä¿¡æ¯\n",
    "            \"æ€§åˆ«ï¼šç”·    å¹´é¾„ï¼š45å²\",    # åŸºæœ¬ä¿¡æ¯\n",
    "            \"ç§‘å®¤ï¼šå¿ƒè¡€ç®¡å†…ç§‘\",          # ç§‘å®¤\n",
    "            \"ä¸»æ²»åŒ»å¸ˆï¼šæåŒ»ç”Ÿ\",          # åŒ»ç”Ÿ\n",
    "            \"è¯Šæ–­ï¼šé«˜è¡€å‹ã€ç³–å°¿ç—…\",      # è¯Šæ–­\n",
    "            \"å¤„æ–¹ï¼š\",                   # å¤„æ–¹æ ‡é¢˜\n",
    "            \"1. é™å‹è¯ 10mg æ¯æ—¥ä¸€æ¬¡\",   # å¤„æ–¹1\n",
    "            \"2. é™ç³–è¯ 5mg æ¯æ—¥ä¸¤æ¬¡\",    # å¤„æ–¹2\n",
    "            \"åŒ»ç”Ÿç­¾åï¼šæåŒ»ç”Ÿ\",          # ç­¾å\n",
    "            \"æ—¥æœŸï¼š2025-08-25\"          # æ—¥æœŸ\n",
    "        ]\n",
    "    else:\n",
    "        print(\"ğŸ”¤ ä½¿ç”¨è‹±æ–‡å†…å®¹åˆ›å»ºç¤ºä¾‹æ–‡æ¡£ï¼ˆä¸­æ–‡å­—ä½“æœªæˆåŠŸåŠ è½½ï¼‰...\")\n",
    "        sample_text = [\n",
    "            \"Medical Report\",           # åŒ»ç–—è¯Šæ–­æŠ¥å‘Š\n",
    "            \"Hospital: XX People's Hospital\",  # åŒ»é™¢åç§°ï¼šXXå¸‚äººæ°‘åŒ»é™¢\n",
    "            \"Patient: Zhang San\",       # æ‚£è€…å§“åï¼šå¼ ä¸‰\n",
    "            \"Gender: Male Age: 45\",     # æ€§åˆ«ï¼šç”· å¹´é¾„ï¼š45å²\n",
    "            \"Department: Cardiology\",   # ç§‘å®¤ï¼šå¿ƒè¡€ç®¡å†…ç§‘\n",
    "            \"Doctor: Dr. Li\",          # ä¸»æ²»åŒ»å¸ˆï¼šæåŒ»ç”Ÿ\n",
    "            \"Diagnosis: Hypertension, Diabetes\",  # è¯Šæ–­ï¼šé«˜è¡€å‹ã€ç³–å°¿ç—…\n",
    "            \"Prescription:\",           # å¤„æ–¹ï¼š\n",
    "            \"1. Antihypertensive 10mg daily\",    # 1. é™å‹è¯ 10mg æ¯æ—¥ä¸€æ¬¡\n",
    "            \"2. Hypoglycemic 5mg twice daily\",   # 2. é™ç³–è¯ 5mg æ¯æ—¥ä¸¤æ¬¡\n",
    "            \"Doctor Signature: Dr. Li\", # åŒ»ç”Ÿç­¾åï¼šæåŒ»ç”Ÿ\n",
    "            \"Date: 2025-08-25\"         # æ—¥æœŸï¼š2025-08-25\n",
    "        ]\n",
    "    \n",
    "    # ç»˜åˆ¶æ–‡æœ¬\n",
    "    y_position = 60\n",
    "    line_height = 50  # å¢å¤§è¡Œé«˜\n",
    "    \n",
    "    for i, text in enumerate(sample_text):\n",
    "        try:\n",
    "            print(f\"ğŸ” [FONT-DEBUG] ç»˜åˆ¶æ–‡æœ¬ {i+1}: {text}\")\n",
    "            \n",
    "            if i == 0:\n",
    "                # æ ‡é¢˜å±…ä¸­\n",
    "                if hasattr(font, 'getbbox'):\n",
    "                    # æ–°ç‰ˆPIL\n",
    "                    bbox = font.getbbox(text)\n",
    "                    text_width = bbox[2] - bbox[0]\n",
    "                elif hasattr(draw, 'textbbox'):\n",
    "                    # è¾ƒæ–°ç‰ˆPIL\n",
    "                    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "                    text_width = bbox[2] - bbox[0]\n",
    "                else:\n",
    "                    # æ—§ç‰ˆPILæˆ–é»˜è®¤å­—ä½“ - ä¼°ç®—å®½åº¦\n",
    "                    text_width = len(text) * 15\n",
    "                \n",
    "                x_position = max(50, (1000 - text_width) // 2)\n",
    "            else:\n",
    "                # æ™®é€šæ–‡æœ¬å·¦å¯¹é½\n",
    "                x_position = 60\n",
    "            \n",
    "            draw.text((x_position, y_position), text, fill='black', font=font)\n",
    "            y_position += line_height\n",
    "            print(f\"âœ… æ–‡æœ¬ç»˜åˆ¶æˆåŠŸ\")\n",
    "            \n",
    "        except Exception as text_e:\n",
    "            print(f\"âš ï¸ æ–‡æœ¬ç»˜åˆ¶å¤±è´¥ '{text}': {text_e}\")\n",
    "            # ä½¿ç”¨æ›´ç®€å•çš„ç»˜åˆ¶æ–¹å¼\n",
    "            try:\n",
    "                draw.text((60, y_position), text, fill='black')\n",
    "                y_position += line_height\n",
    "                print(f\"âœ… ç®€å•æ–¹å¼ç»˜åˆ¶æˆåŠŸ\")\n",
    "            except Exception as simple_e:\n",
    "                print(f\"âŒ ç®€å•æ–¹å¼ä¹Ÿå¤±è´¥: {simple_e}\")\n",
    "                y_position += line_height\n",
    "    \n",
    "    # æ·»åŠ è£…é¥°å…ƒç´ \n",
    "    try:\n",
    "        draw.rectangle([(60, 100), (160, 160)], outline='gray', width=1)\n",
    "        draw.text((90, 125), \"LOGO\", fill='gray', font=font)\n",
    "        draw.line([(700, 650), (950, 650)], fill='black', width=1)\n",
    "        draw.text((700, 660), \"Signature\", fill='gray', font=font)\n",
    "        draw.rectangle([(800, 700), (950, 750)], outline='blue', width=1)\n",
    "        draw.text((810, 715), \"2025-08-25\", fill='blue', font=font)\n",
    "    except Exception as deco_e:\n",
    "        print(f\"âš ï¸ è£…é¥°å…ƒç´ ç»˜åˆ¶å¤±è´¥: {deco_e}\")\n",
    "    \n",
    "    # ä¿å­˜ç¤ºä¾‹å›¾åƒ\n",
    "    os.makedirs('assets/sample_docs', exist_ok=True)\n",
    "    sample_path = 'assets/sample_docs/sample_medical_document.png'\n",
    "    img.save(sample_path, 'PNG', optimize=False)\n",
    "    print(f\"ğŸ“„ åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£: {sample_path}\")\n",
    "    \n",
    "    # åˆ›å»ºä¸“é—¨çš„ä¸­æ–‡æµ‹è¯•å›¾åƒ\n",
    "    try:\n",
    "        print(\"ğŸˆ¯ åˆ›å»ºä¸“é—¨çš„ä¸­æ–‡æµ‹è¯•å›¾åƒ...\")\n",
    "        chinese_img = Image.new('RGB', (800, 600), color='white')\n",
    "        chinese_draw = ImageDraw.Draw(chinese_img)\n",
    "        chinese_draw.rectangle([(10, 10), (790, 590)], outline='black', width=2)\n",
    "        \n",
    "        chinese_texts = [\n",
    "            \"åŒ»ç–—è¯Šæ–­æŠ¥å‘Š\",\n",
    "            \"æ‚£è€…å§“åï¼šå¼ ä¸‰\",\n",
    "            \"æ€§åˆ«ï¼šç”· å¹´é¾„ï¼š45å²\",\n",
    "            \"è¯Šæ–­ï¼šé«˜è¡€å‹\",\n",
    "            \"å¤„æ–¹ï¼šé™å‹è¯10mg\"\n",
    "        ]\n",
    "        \n",
    "        # æ·»åŠ æ ‡é¢˜\n",
    "        title_font = font\n",
    "        chinese_draw.text((300, 30), \"ä¸­æ–‡å­—ä½“æµ‹è¯•\", fill='blue', font=title_font)\n",
    "        \n",
    "        y_pos = 80\n",
    "        for j, text in enumerate(chinese_texts):\n",
    "            try:\n",
    "                print(f\"ğŸ” [FONT-DEBUG] ç»˜åˆ¶ä¸­æ–‡æ–‡æœ¬ {j+1}: {text}\")\n",
    "                chinese_draw.text((50, y_pos), text, fill='black', font=font)\n",
    "                y_pos += 70\n",
    "                print(f\"âœ… ä¸­æ–‡æ–‡æœ¬ç»˜åˆ¶æˆåŠŸ\")\n",
    "            except Exception as ch_e:\n",
    "                # å¦‚æœä¸­æ–‡ç»˜åˆ¶å¤±è´¥ï¼Œæ·»åŠ è‹±æ–‡æ ‡æ³¨\n",
    "                print(f\"âš ï¸ ä¸­æ–‡æ–‡æœ¬ç»˜åˆ¶å¤±è´¥: {text} - {ch_e}\")\n",
    "                fallback_text = f\"[CHINESE TEXT {j+1}] - Font Failed\"\n",
    "                chinese_draw.text((50, y_pos), fallback_text, fill='red', font=font)\n",
    "                y_pos += 70\n",
    "        \n",
    "        chinese_path = 'assets/sample_docs/chinese_test_document.png'\n",
    "        chinese_img.save(chinese_path, 'PNG', optimize=False)\n",
    "        print(f\"ğŸ“„ åˆ›å»ºä¸­æ–‡æµ‹è¯•æ–‡æ¡£: {chinese_path}\")\n",
    "        \n",
    "    except Exception as chinese_e:\n",
    "        print(f\"âš ï¸ ä¸­æ–‡æµ‹è¯•å›¾åƒåˆ›å»ºå¤±è´¥: {chinese_e}\")\n",
    "    \n",
    "    return sample_path\n",
    "\n",
    "def comprehensive_ocr_test():\n",
    "    \"\"\"ç»¼åˆOCRåŠŸèƒ½æµ‹è¯•å’Œæ¼”ç¤º\"\"\"\n",
    "    import os  # ç¡®ä¿osæ¨¡å—åœ¨å‡½æ•°å†…å¯ç”¨\n",
    "    print(\"ğŸš€ å¼€å§‹OCRåŠŸèƒ½éªŒè¯å’Œæ¼”ç¤º...\")\n",
    "    \n",
    "    # 1. æ£€æŸ¥OCRå¤„ç†å™¨çŠ¶æ€\n",
    "    if 'ocr_processor' not in globals() or ocr_processor is None:\n",
    "        print(\"âŒ OCRå¤„ç†å™¨æœªåˆå§‹åŒ–\")\n",
    "        return False, None, None\n",
    "    \n",
    "    # 2. åˆ›å»ºæˆ–æ£€æŸ¥ç¤ºä¾‹æ–‡æ¡£\n",
    "    sample_path = \"assets/sample_docs/sample_medical_document.png\"\n",
    "    \n",
    "    if not os.path.exists(sample_path):\n",
    "        print(\"ğŸ¨ åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£...\")\n",
    "        sample_path = create_sample_medical_document()\n",
    "    else:\n",
    "        print(f\"âœ… æ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶: {sample_path}\")\n",
    "    \n",
    "    # 3. æ‰§è¡ŒOCRè¯†åˆ«æµ‹è¯•\n",
    "    try:\n",
    "        print(f\"ğŸ” æ‰§è¡ŒOCRè¯†åˆ«: {sample_path}\")\n",
    "        results = ocr_processor.process_single_image(sample_path)\n",
    "        \n",
    "        if not results:\n",
    "            print(\"âŒ OCRè¯†åˆ«å¤±è´¥ï¼šæœªè¯†åˆ«åˆ°æ–‡å­—\")\n",
    "            return False, sample_path, None\n",
    "        \n",
    "        print(f\"âœ… OCRè¯†åˆ«æˆåŠŸï¼è¯†åˆ«åˆ° {len(results)} è¡Œæ–‡å­—\")\n",
    "        \n",
    "        # 4. æ˜¾ç¤ºè¯†åˆ«ç»“æœ\n",
    "        print(\"\\nğŸ“Š æ–‡å­—è¯†åˆ«ç»“æœ:\")\n",
    "        print(\"-\" * 60)\n",
    "        chinese_count = 0\n",
    "        english_count = 0\n",
    "        \n",
    "        for result in results:\n",
    "            text = result['extracted_text']\n",
    "            # ç®€å•æ£€æµ‹æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦\n",
    "            has_chinese = any('\\u4e00' <= char <= '\\u9fff' for char in text)\n",
    "            if has_chinese:\n",
    "                chinese_count += 1\n",
    "            else:\n",
    "                english_count += 1\n",
    "            print(f\"è¡Œ{result['line_number']:2d}: {text} (ç½®ä¿¡åº¦: {result['confidence']:.3f}) {'ğŸˆ³' if has_chinese else 'ğŸ”¤'}\")\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ è¯­è¨€è¯†åˆ«ç»Ÿè®¡:\")\n",
    "        print(f\"   â€¢ ä¸­æ–‡æ–‡æœ¬è¡Œæ•°: {chinese_count}\")\n",
    "        print(f\"   â€¢ è‹±æ–‡æ–‡æœ¬è¡Œæ•°: {english_count}\")\n",
    "        \n",
    "        # 5. ä¿å­˜CSVç»“æœ\n",
    "        os.makedirs('assets/results', exist_ok=True)\n",
    "        csv_path = 'assets/results/ocr_results_demo.csv'\n",
    "        _ = ocr_processor.save_results_to_csv(results, csv_path)  # noqa: F841\n",
    "        \n",
    "        # 6. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯\n",
    "        avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
    "        high_conf_count = sum(1 for r in results if r['confidence'] > 0.9)\n",
    "        \n",
    "        print(f\"\\nğŸ“ˆ è¯†åˆ«ç»Ÿè®¡:\")\n",
    "        print(f\"   â€¢ æ€»æ–‡å­—è¡Œæ•°: {len(results)}\")\n",
    "        print(f\"   â€¢ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}\")\n",
    "        print(f\"   â€¢ é«˜ç½®ä¿¡åº¦(>0.9): {high_conf_count}/{len(results)}\")\n",
    "        print(f\"   â€¢ CSVæ–‡ä»¶: {csv_path}\")\n",
    "        \n",
    "        # 7. æµ‹è¯•ä¸­æ–‡æ–‡æ¡£ï¼ˆå¦‚æœå­˜åœ¨ï¼‰\n",
    "        chinese_path = \"assets/sample_docs/chinese_test_document.png\"\n",
    "        if os.path.exists(chinese_path):\n",
    "            print(f\"\\nğŸˆ¯ æµ‹è¯•ä¸“é—¨çš„ä¸­æ–‡æ–‡æ¡£è¯†åˆ«: {chinese_path}\")\n",
    "            chinese_results = ocr_processor.process_single_image(chinese_path)\n",
    "            if chinese_results:\n",
    "                print(f\"âœ… ä¸­æ–‡æ–‡æ¡£è¯†åˆ«æˆåŠŸï¼è¯†åˆ«åˆ° {len(chinese_results)} è¡Œæ–‡å­—\")\n",
    "                chinese_text_count = 0\n",
    "                for result in chinese_results[:5]:  # æ˜¾ç¤ºå‰5è¡Œ\n",
    "                    text = result['extracted_text']\n",
    "                    has_chinese = any('\\u4e00' <= char <= '\\u9fff' for char in text)\n",
    "                    if has_chinese:\n",
    "                        chinese_text_count += 1\n",
    "                    print(f\"   ä¸­æ–‡ç¤ºä¾‹ {result['line_number']}: {text} (ç½®ä¿¡åº¦: {result['confidence']:.3f}) {'ğŸˆ³' if has_chinese else 'âŒ'}\")\n",
    "                print(f\"   å®é™…ä¸­æ–‡è¯†åˆ«è¡Œæ•°: {chinese_text_count}/{len(chinese_results)}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ ä¸­æ–‡æ–‡æ¡£è¯†åˆ«å¤±è´¥\")\n",
    "        \n",
    "        return True, sample_path, results\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OCRæµ‹è¯•å¼‚å¸¸: {e}\")\n",
    "        import traceback\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        return False, sample_path, None\n",
    "\n",
    "# æ‰§è¡Œç»¼åˆæµ‹è¯•\n",
    "test_success, sample_doc, ocr_results = comprehensive_ocr_test()\n",
    "\n",
    "# æ˜¾ç¤ºç¤ºä¾‹å›¾åƒï¼ˆå¦‚æœåœ¨Jupyterç¯å¢ƒï¼‰\n",
    "import os  # ç¡®ä¿æ¨¡å—çº§åˆ«å¯ç”¨\n",
    "try:\n",
    "    from IPython.display import Image as IPImage, display\n",
    "    if sample_doc and os.path.exists(sample_doc):\n",
    "        print(f\"\\nğŸ–¼ï¸ æ˜¾ç¤ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£:\")\n",
    "        display(IPImage(sample_doc))\n",
    "        \n",
    "        # å¦‚æœä¸­æ–‡æµ‹è¯•å›¾åƒå­˜åœ¨ï¼Œä¹Ÿæ˜¾ç¤º\n",
    "        chinese_path = \"assets/sample_docs/chinese_test_document.png\"\n",
    "        if os.path.exists(chinese_path):\n",
    "            print(f\"\\nğŸˆ¯ æ˜¾ç¤ºä¸­æ–‡æµ‹è¯•æ–‡æ¡£:\")\n",
    "            display(IPImage(chinese_path))\n",
    "except ImportError:\n",
    "    print(f\"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»º: {sample_doc}\")\n",
    "    print(\"ğŸ’¡ åœ¨Jupyter/Colabç¯å¢ƒä¸­ä¼šè‡ªåŠ¨æ˜¾ç¤ºå›¾åƒ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ å›¾åƒæ˜¾ç¤ºå¤±è´¥: {e}\")\n",
    "\n",
    "if test_success:\n",
    "    print(\"\\nğŸ‰ OCRåŠŸèƒ½éªŒè¯æˆåŠŸï¼å¯ä»¥å®‰å…¨ä½¿ç”¨Gradioç•Œé¢\")\n",
    "else:\n",
    "    print(\"\\nâš ï¸ OCRåŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥é…ç½®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# OCRåŠŸèƒ½éªŒè¯æµ‹è¯•\n",
    "# ================================\n",
    "\n",
    "def test_ocr_functionality():\n",
    "    \"\"\"å¿«é€Ÿæµ‹è¯•OCRåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ\"\"\"\n",
    "    print(\"ğŸ§ª å¼€å§‹OCRåŠŸèƒ½éªŒè¯æµ‹è¯•...\")\n",
    "    \n",
    "    # æ£€æŸ¥OCRå¤„ç†å™¨æ˜¯å¦å¯ç”¨ - ä¿®å¤å…¨å±€å˜é‡æ£€æµ‹å’ŒIDEè­¦å‘Š\n",
    "    try:\n",
    "        # ä½¿ç”¨globals()æ£€æŸ¥å˜é‡å­˜åœ¨ï¼Œé¿å…IDE unboundè­¦å‘Š\n",
    "        if 'ocr_processor' not in globals():\n",
    "            print(\"âŒ å…¨å±€OCRå¤„ç†å™¨å˜é‡æœªå®šä¹‰\")\n",
    "            print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œ'åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»'å•å…ƒæ ¼æ¥åˆå§‹åŒ–OCRå¤„ç†å™¨\")\n",
    "            return False\n",
    "        \n",
    "        processor = globals()['ocr_processor']  # type: ignore # åŠ¨æ€è®¿é—®å…¨å±€å˜é‡\n",
    "        print(\"âœ… æ‰¾åˆ°å…¨å±€OCRå¤„ç†å™¨å˜é‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è®¿é—®OCRå¤„ç†å™¨æ—¶å‡ºé”™: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # æ£€æŸ¥å¤„ç†å™¨å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ\n",
    "    if processor is None:\n",
    "        print(\"âŒ OCRå¤„ç†å™¨å¯¹è±¡ä¸ºNone\")\n",
    "        print(\"ğŸ’¡ OCRå¤„ç†å™¨åˆå§‹åŒ–å¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\")\n",
    "        return False\n",
    "    \n",
    "    # æ£€æŸ¥PaddleOCRå¼•æ“\n",
    "    if not hasattr(processor, 'ocr') or processor.ocr is None:\n",
    "        print(\"âŒ PaddleOCRå¼•æ“æœªåˆå§‹åŒ–\")\n",
    "        print(\"ğŸ’¡ PaddleOCRåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥:\")\n",
    "        print(\"   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "        print(\"   2. PaddleOCRæ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"   3. æ¨¡å‹æ–‡ä»¶æ˜¯å¦ä¸‹è½½å®Œæˆ\")\n",
    "        return False\n",
    "    \n",
    "    print(\"âœ… OCRå¤„ç†å™¨å’Œå¼•æ“æ£€æŸ¥é€šè¿‡\")\n",
    "    \n",
    "    # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    import os\n",
    "    sample_path = \"assets/sample_docs/sample_medical_document.png\"\n",
    "    \n",
    "    if not os.path.exists(sample_path):\n",
    "        print(f\"âš ï¸ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {sample_path}\")\n",
    "        \n",
    "        # å°è¯•åˆ›å»ºç¤ºä¾‹æ–‡ä»¶\n",
    "        try:\n",
    "            print(\"ğŸ¨ å°è¯•åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...\")\n",
    "            # æ£€æŸ¥create_sample_medical_documentå‡½æ•°æ˜¯å¦å­˜åœ¨\n",
    "            if 'create_sample_medical_document' not in globals():\n",
    "                print(\"âŒ create_sample_medical_documentå‡½æ•°æœªå®šä¹‰\")\n",
    "                print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œ'åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£'å•å…ƒæ ¼\")\n",
    "                return False\n",
    "            \n",
    "            create_func = globals()['create_sample_medical_document']  # type: ignore # åŠ¨æ€è®¿é—®å…¨å±€å‡½æ•°\n",
    "            sample_path = create_func()\n",
    "            print(f\"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»º: {sample_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå¤±è´¥: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"âœ… æ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶: {sample_path}\")\n",
    "    \n",
    "    # æµ‹è¯•OCRå¤„ç†\n",
    "    try:\n",
    "        print(f\"ğŸ” æµ‹è¯•OCRå¤„ç†: {sample_path}\")\n",
    "        results = processor.process_single_image(sample_path)\n",
    "        \n",
    "        print(f\"ğŸ“Š OCRå¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœç±»å‹: {type(results)}\")\n",
    "        print(f\"ğŸ“Š ç»“æœæ•°é‡: {len(results) if results else 0}\")\n",
    "        \n",
    "        if results and len(results) > 0:\n",
    "            print(f\"âœ… OCRæµ‹è¯•æˆåŠŸï¼è¯†åˆ«åˆ° {len(results)} è¡Œæ–‡å­—\")\n",
    "            print(\"ğŸ“ å‰3è¡Œè¯†åˆ«ç»“æœ:\")\n",
    "            for i, result in enumerate(results[:3]):\n",
    "                print(f\"   {i+1}. {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"âŒ OCRæµ‹è¯•å¤±è´¥ï¼šæœªè¯†åˆ«åˆ°æ–‡å­—\")\n",
    "            print(\"ğŸ” å¯èƒ½åŸå› ï¼š\")\n",
    "            print(\"   1. PaddleOCRç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜\")\n",
    "            print(\"   2. æ¨¡å‹æ–‡ä»¶ä¸‹è½½ä¸å®Œæ•´\")\n",
    "            print(\"   3. ç¤ºä¾‹å›¾åƒè´¨é‡é—®é¢˜\")\n",
    "            print(\"   4. APIè°ƒç”¨å‚æ•°ä¸å…¼å®¹\")\n",
    "            \n",
    "            # å°è¯•ç›´æ¥è°ƒç”¨PaddleOCR\n",
    "            print(\"\\\\nğŸ”§ å°è¯•ç›´æ¥è°ƒç”¨PaddleOCRå¼•æ“...\")\n",
    "            try:\n",
    "                direct_result = processor.ocr.predict(sample_path)\n",
    "                print(f\"ğŸ” ç›´æ¥è°ƒç”¨ç»“æœç±»å‹: {type(direct_result)}\")\n",
    "                print(f\"ğŸ” ç›´æ¥è°ƒç”¨ç»“æœé•¿åº¦: {len(direct_result) if direct_result else 0}\")\n",
    "                \n",
    "                if direct_result:\n",
    "                    print(\"âœ… PaddleOCRå¼•æ“æœ¬èº«å·¥ä½œæ­£å¸¸\")\n",
    "                    print(\"ğŸ’¡ é—®é¢˜å¯èƒ½åœ¨ç»“æœè§£æé€»è¾‘ä¸­\")\n",
    "                else:\n",
    "                    print(\"âŒ PaddleOCRå¼•æ“è°ƒç”¨ä¹Ÿå¤±è´¥\")\n",
    "                    \n",
    "            except Exception as direct_e:\n",
    "                print(f\"âŒ ç›´æ¥è°ƒç”¨PaddleOCRå¤±è´¥: {direct_e}\")\n",
    "            \n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OCRæµ‹è¯•å¼‚å¸¸: {e}\")\n",
    "        import traceback\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "# è¿è¡ŒOCRåŠŸèƒ½éªŒè¯\n",
    "print(\"ğŸš€ è¿è¡ŒOCRåŠŸèƒ½éªŒè¯æµ‹è¯•...\")\n",
    "ocr_test_result = test_ocr_functionality()\n",
    "\n",
    "if ocr_test_result:\n",
    "    print(\"\\\\nğŸ‰ OCRåŠŸèƒ½éªŒè¯æˆåŠŸï¼Gradioç•Œé¢åº”è¯¥èƒ½æ­£å¸¸å·¥ä½œ\")\n",
    "    print(\"ğŸ’¡ ç°åœ¨å¯ä»¥å®‰å…¨ä½¿ç”¨Gradioç•Œé¢è¿›è¡Œå›¾åƒä¸Šä¼ å’Œè¯†åˆ«\")\n",
    "else:\n",
    "    print(\"\\\\nâš ï¸ OCRåŠŸèƒ½éªŒè¯å¤±è´¥ï¼éœ€è¦æ£€æŸ¥PaddleOCRé…ç½®\")\n",
    "    print(\"ğŸ’¡ å»ºè®®æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\")\n",
    "    print(\"   1. ç¡®è®¤å·²è¿è¡Œ'åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»'å•å…ƒæ ¼\")\n",
    "    print(\"   2. ç¡®è®¤å·²è¿è¡Œ'åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£'å•å…ƒæ ¼\")\n",
    "    print(\"   3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ¨¡å‹ä¸‹è½½çŠ¶æ€\")\n",
    "    print(\"   4. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·é‡å¯è¿è¡Œæ—¶ç¯å¢ƒ\")\n",
    "\n",
    "# æ˜¾ç¤ºå½“å‰å¯ç”¨çš„å…³é”®å…¨å±€å˜é‡\n",
    "print(\"\\\\nğŸ” å½“å‰å¯ç”¨çš„å…³é”®å…¨å±€å˜é‡:\")\n",
    "available_vars = []\n",
    "\n",
    "# å®‰å…¨æ£€æŸ¥å„ä¸ªå…³é”®å˜é‡çš„å­˜åœ¨æ€§\n",
    "key_variables = {\n",
    "    'ocr_processor': 'åŒ»ç–—OCRå¤„ç†å™¨',\n",
    "    'create_sample_medical_document': 'ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå‡½æ•°', \n",
    "    'demo_interface': 'Gradio Webç•Œé¢å¯¹è±¡'\n",
    "}\n",
    "\n",
    "for var_name, description in key_variables.items():\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            var_value = globals()[var_name]\n",
    "            if var_value is not None:\n",
    "                available_vars.append(f\"âœ… {var_name} ({description})\")\n",
    "            else:\n",
    "                available_vars.append(f\"âŒ {var_name} (å·²å®šä¹‰ä½†å€¼ä¸ºNone)\")\n",
    "        else:\n",
    "            available_vars.append(f\"âŒ {var_name} (æœªå®šä¹‰)\")\n",
    "    except Exception as e:\n",
    "        available_vars.append(f\"âŒ {var_name} (è®¿é—®é”™è¯¯: {e})\")\n",
    "\n",
    "for var_info in available_vars:\n",
    "    print(f\"   {var_info}\")\n",
    "\n",
    "# å¦‚æœdemo_interfaceæœªå®šä¹‰ï¼Œç»™å‡ºåˆ›å»ºæç¤º\n",
    "if 'demo_interface' not in globals() or globals()['demo_interface'] is None:\n",
    "    print(\"\\\\nğŸ’¡ Gradioç•Œé¢åˆ›å»ºæç¤º:\")\n",
    "    print(\"   å¦‚éœ€åˆ›å»ºWebç•Œé¢ï¼Œè¯·è¿è¡Œ'Gradio Webäº¤äº’ç•Œé¢'å•å…ƒæ ¼\")\n",
    "    print(\"   è¯¥å•å…ƒæ ¼ä¼šåˆ›å»ºdemo_interfaceå˜é‡å¹¶åˆå§‹åŒ–Webç•Œé¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Gradio Webäº¤äº’ç•Œé¢ - v1.3.17\n",
    "# ================================\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "def create_gradio_interface():\n",
    "    \"\"\"åˆ›å»ºGradio Webäº¤äº’ç•Œé¢\"\"\"\n",
    "    print(\"ğŸŒ åˆå§‹åŒ–Gradio Webç•Œé¢...\")\n",
    "    \n",
    "    def process_uploaded_image(image):\n",
    "        \"\"\"å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„å›¾åƒ\"\"\"\n",
    "        print(\"ğŸ“¤ æ¥æ”¶åˆ°ç”¨æˆ·ä¸Šä¼ çš„å›¾åƒ\")\n",
    "        print(f\"ğŸ” [DEBUG] å›¾åƒç±»å‹: {type(image)}\")\n",
    "        \n",
    "        # æ£€æŸ¥OCRå¤„ç†å™¨æ˜¯å¦å¯ç”¨\n",
    "        if 'ocr_processor' not in globals() or globals()['ocr_processor'] is None:\n",
    "            error_msg = \"âŒ OCRå¤„ç†å™¨æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆè¿è¡ŒOCRåˆå§‹åŒ–å•å…ƒæ ¼\"\n",
    "            print(error_msg)\n",
    "            return error_msg, None\n",
    "        \n",
    "        processor = globals()['ocr_processor']\n",
    "        \n",
    "        try:\n",
    "            # æ”¹è¿›çš„å›¾åƒå¤„ç†æµç¨‹\n",
    "            temp_path = None\n",
    "            \n",
    "            if isinstance(image, PILImage.Image):\n",
    "                # PIL Imageå¯¹è±¡ - ç›´æ¥ä¿å­˜\n",
    "                temp_path = 'temp_uploaded_image.png'\n",
    "                # ç¡®ä¿æ˜¯RGBæ¨¡å¼\n",
    "                if image.mode != 'RGB':\n",
    "                    image = image.convert('RGB')\n",
    "                image.save(temp_path, 'PNG', quality=95)\n",
    "                print(f\"âœ… PILå›¾åƒå·²ä¿å­˜: {temp_path}, å°ºå¯¸: {image.size}, æ¨¡å¼: {image.mode}\")\n",
    "                \n",
    "            elif isinstance(image, np.ndarray):\n",
    "                # numpyæ•°ç»„\n",
    "                temp_path = 'temp_uploaded_image.png'\n",
    "                print(f\"ğŸ” [DEBUG] numpyæ•°ç»„å½¢çŠ¶: {image.shape}, æ•°æ®ç±»å‹: {image.dtype}\")\n",
    "                \n",
    "                # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®\n",
    "                if image.dtype != np.uint8:\n",
    "                    if image.max() <= 1.0:\n",
    "                        # å¯èƒ½æ˜¯0-1èŒƒå›´çš„æµ®ç‚¹æ•°\n",
    "                        image = (image * 255).astype(np.uint8)\n",
    "                    else:\n",
    "                        image = image.astype(np.uint8)\n",
    "                \n",
    "                pil_image = PILImage.fromarray(image)\n",
    "                if pil_image.mode != 'RGB':\n",
    "                    pil_image = pil_image.convert('RGB')\n",
    "                pil_image.save(temp_path, 'PNG', quality=95)\n",
    "                print(f\"âœ… numpyå›¾åƒå·²ä¿å­˜: {temp_path}, å°ºå¯¸: {pil_image.size}\")\n",
    "                \n",
    "            elif isinstance(image, str):\n",
    "                # æ–‡ä»¶è·¯å¾„\n",
    "                temp_path = str(image)\n",
    "                print(f\"ğŸ” [DEBUG] æ–‡ä»¶è·¯å¾„: {temp_path}\")\n",
    "                \n",
    "            else:\n",
    "                error_msg = f\"âŒ ä¸æ”¯æŒçš„å›¾åƒç±»å‹: {type(image)}\"\n",
    "                print(error_msg)\n",
    "                return error_msg, None\n",
    "            \n",
    "            # éªŒè¯ä¸´æ—¶æ–‡ä»¶\n",
    "            if not temp_path or not os.path.exists(temp_path):\n",
    "                error_msg = f\"âŒ ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥: {temp_path}\"\n",
    "                print(error_msg)\n",
    "                return error_msg, None\n",
    "                \n",
    "            file_size = os.path.getsize(temp_path)\n",
    "            print(f\"ğŸ’¾ ä¸´æ—¶æ–‡ä»¶ä¿¡æ¯: {temp_path}, å¤§å°: {file_size} å­—èŠ‚\")\n",
    "            \n",
    "            if file_size == 0:\n",
    "                error_msg = \"âŒ å›¾åƒæ–‡ä»¶ä¸ºç©º\"\n",
    "                print(error_msg)\n",
    "                return error_msg, None\n",
    "            \n",
    "            # æ‰§è¡ŒOCRå¤„ç† - å¢å¼ºé”™è¯¯å¤„ç†\n",
    "            print(\"ğŸ”„ å¼€å§‹OCRå¤„ç†...\")\n",
    "            results = processor.process_single_image(temp_path)\n",
    "            print(f\"ğŸ” [DEBUG] OCRå¤„ç†å®Œæˆï¼Œç»“æœæ•°é‡: {len(results) if results else 0}\")\n",
    "            \n",
    "            if not results or len(results) == 0:\n",
    "                # é¢å¤–è¯Šæ–­ä¿¡æ¯\n",
    "                print(\"ğŸ” [DEBUG] OCRè¯†åˆ«å¤±è´¥ï¼Œè¿›è¡Œè¯Šæ–­...\")\n",
    "                try:\n",
    "                    with PILImage.open(temp_path) as diag_img:\n",
    "                        print(f\"ğŸ” [DIAG] å›¾åƒä¿¡æ¯: å°ºå¯¸={diag_img.size}, æ¨¡å¼={diag_img.mode}\")\n",
    "                        # æ£€æŸ¥å›¾åƒæ˜¯å¦è¿‡å°æˆ–è¿‡å¤§\n",
    "                        width, height = diag_img.size\n",
    "                        if width < 50 or height < 50:\n",
    "                            return \"âš ï¸ å›¾åƒå°ºå¯¸è¿‡å°ï¼Œè¯·ä¸Šä¼ æ›´å¤§çš„å›¾åƒï¼ˆæ¨èæœ€å°100x100åƒç´ ï¼‰\", None\n",
    "                        elif width > 4000 or height > 4000:\n",
    "                            return \"âš ï¸ å›¾åƒå°ºå¯¸è¿‡å¤§ï¼Œè¯·å‹ç¼©åå†ä¸Šä¼ ï¼ˆæ¨èæœ€å¤§4000x4000åƒç´ ï¼‰\", None\n",
    "                except Exception as diag_e:\n",
    "                    print(f\"ğŸ” [DIAG] å›¾åƒè¯Šæ–­å¤±è´¥: {diag_e}\")\n",
    "                \n",
    "                return \"âš ï¸ æœªæ£€æµ‹åˆ°æ–‡å­—å†…å®¹ã€‚è¯·ç¡®è®¤ï¼š\\\\nâ€¢ å›¾åƒæ¸…æ™°åº¦è¶³å¤Ÿ\\\\nâ€¢ åŒ…å«å¯è¯†åˆ«çš„æ–‡å­—\\\\nâ€¢ æ–‡å­—ä¸èƒŒæ™¯æœ‰è¶³å¤Ÿå¯¹æ¯”åº¦\", None\n",
    "            \n",
    "            # ç”Ÿæˆç»“æœæ–‡æœ¬\n",
    "            result_text = f\"ğŸ‰ OCRè¯†åˆ«æˆåŠŸï¼\\\\n\\\\nğŸ“Š è¯†åˆ«ç»Ÿè®¡:\\\\n\"\n",
    "            result_text += f\"â€¢ æ€»æ–‡å­—è¡Œæ•°: {len(results)}\\\\n\"\n",
    "            \n",
    "            avg_confidence = sum(r['confidence'] for r in results) / len(results)\n",
    "            result_text += f\"â€¢ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}\\\\n\\\\n\"\n",
    "            \n",
    "            result_text += \"ğŸ“ è¯†åˆ«ç»“æœ:\\\\n\" + \"=\"*50 + \"\\\\n\"\n",
    "            \n",
    "            for result in results:\n",
    "                result_text += f\"è¡Œ{result['line_number']:2d}: {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\\\\n\"\n",
    "            \n",
    "            # ä¿å­˜CSVæ–‡ä»¶\n",
    "            os.makedirs('assets/results', exist_ok=True)\n",
    "            csv_path = 'assets/results/gradio_ocr_results.csv'\n",
    "            _ = processor.save_results_to_csv(results, csv_path)  # noqa: F841\n",
    "            \n",
    "            result_text += f\"\\\\nğŸ’¾ CSVç»“æœå·²ä¿å­˜: {csv_path}\"\n",
    "            \n",
    "            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "            try:\n",
    "                if temp_path and os.path.exists(temp_path) and temp_path.startswith('temp_'):\n",
    "                    os.remove(temp_path)\n",
    "                    print(f\"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶: {temp_path}\")\n",
    "            except Exception as cleanup_e:\n",
    "                print(f\"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {cleanup_e}\")\n",
    "            \n",
    "            print(\"âœ… å›¾åƒå¤„ç†å®Œæˆ\")\n",
    "            \n",
    "            # è¿”å›ç»“æœæ–‡æœ¬å’ŒCSVæ–‡ä»¶è·¯å¾„\n",
    "            return result_text, csv_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_msg = f\"âŒ å¤„ç†å›¾åƒæ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\"\n",
    "            print(error_msg)\n",
    "            print(f\"ğŸ” [DEBUG] é”™è¯¯ç±»å‹: {type(e).__name__}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            \n",
    "            # æ¸…ç†å¯èƒ½çš„ä¸´æ—¶æ–‡ä»¶\n",
    "            try:\n",
    "                if temp_path and os.path.exists(temp_path) and temp_path.startswith('temp_'):\n",
    "                    os.remove(temp_path)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            return error_msg, None\n",
    "    \n",
    "    # åˆ›å»ºGradioç•Œé¢ - ä½¿ç”¨å…¼å®¹çš„ä¸»é¢˜è®¾ç½®\n",
    "    interface = gr.Interface(\n",
    "        fn=process_uploaded_image,\n",
    "        inputs=gr.Image(type=\"pil\", label=\"ğŸ“¤ ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\"),\n",
    "        outputs=[\n",
    "            gr.Textbox(label=\"ğŸ“‹ OCRè¯†åˆ«ç»“æœ\", lines=15, max_lines=20),\n",
    "            gr.File(label=\"ğŸ“ ä¸‹è½½CSVç»“æœæ–‡ä»¶\")\n",
    "        ],\n",
    "        title=\"ğŸ¥ åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«ç³»ç»Ÿ v1.3.17\",\n",
    "        description=\"\"\"\n",
    "        ## ğŸ“‹ ä½¿ç”¨è¯´æ˜\n",
    "        1. **ä¸Šä¼ å›¾åƒ**: ç‚¹å‡»ä¸Šä¼ åŒºåŸŸé€‰æ‹©åŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡ä»¶\n",
    "        2. **è‡ªåŠ¨è¯†åˆ«**: ç³»ç»Ÿè‡ªåŠ¨ä½¿ç”¨PaddleOCRè¿›è¡Œæ–‡å­—è¯†åˆ«\n",
    "        3. **æŸ¥çœ‹ç»“æœ**: åœ¨ç»“æœåŒºåŸŸæŸ¥çœ‹è¯†åˆ«çš„æ–‡å­—å†…å®¹å’Œç½®ä¿¡åº¦\n",
    "        4. **ä¸‹è½½CSV**: ç‚¹å‡»ä¸‹è½½æŒ‰é’®è·å–ç»“æ„åŒ–çš„CSVç»“æœæ–‡ä»¶\n",
    "        \n",
    "        ## ğŸ¯ æ”¯æŒæ ¼å¼\n",
    "        - å›¾åƒæ ¼å¼: PNG, JPG, JPEG\n",
    "        - æ–‡å­—ç±»å‹: ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—\n",
    "        - æ–‡æ¡£ç±»å‹: åŒ»ç–—æŠ¥å‘Šã€å¤„æ–¹å•ã€æ£€æŸ¥å•ç­‰\n",
    "        \n",
    "        ## ğŸ’¡ ä¼˜åŒ–å»ºè®®\n",
    "        - ç¡®ä¿å›¾åƒæ¸…æ™°åº¦é€‚ä¸­ï¼ˆæ¨è100x100åˆ°4000x4000åƒç´ ï¼‰\n",
    "        - é¿å…æ¨¡ç³Šæˆ–è¿‡åº¦æ›å…‰\n",
    "        - æ–‡å­—åŒºåŸŸå®Œæ•´å¯è§ï¼Œä¸èƒŒæ™¯æœ‰è¶³å¤Ÿå¯¹æ¯”åº¦\n",
    "        - å¦‚é‡é—®é¢˜ï¼Œè¯·å°è¯•è°ƒæ•´å›¾åƒäº®åº¦æˆ–å¯¹æ¯”åº¦\n",
    "        \n",
    "        ## ğŸ”§ æ•…éšœæ’é™¤\n",
    "        - **æœªæ£€æµ‹åˆ°æ–‡å­—**: æ£€æŸ¥å›¾åƒæ¸…æ™°åº¦å’Œæ–‡å­—å¯¹æ¯”åº¦\n",
    "        - **è¯†åˆ«ä¸å‡†ç¡®**: å°è¯•æé«˜å›¾åƒåˆ†è¾¨ç‡æˆ–æ”¹å–„å…‰ç…§æ¡ä»¶\n",
    "        - **å¤„ç†å¤±è´¥**: ç¡®è®¤å›¾åƒæ ¼å¼æ­£ç¡®ï¼Œæ–‡ä»¶æœªæŸå\n",
    "        \n",
    "        ## ğŸ†• v1.3.17 æ›´æ–°\n",
    "        - ğŸ¨ **Colabä¸­æ–‡å­—ä½“å®Œå…¨ä¿®å¤**: çœŸå®ä¸‹è½½å®‰è£…ä¸­æ–‡å­—ä½“ï¼Œè§£å†³æ–¹å—å­—é—®é¢˜\n",
    "        - âš¡ **å›¾åƒå¤„ç†å¢å¼º**: æ”¯æŒå¤šç§æ ¼å¼ï¼Œå®Œå–„é”™è¯¯å¤„ç†å’Œè°ƒè¯•ä¿¡æ¯\n",
    "        - ğŸ” **æ™ºèƒ½æ•…éšœè¯Šæ–­**: å›¾åƒå°ºå¯¸æ£€æŸ¥å’Œç”¨æˆ·å‹å¥½çš„é”™è¯¯æç¤º\n",
    "        \"\"\",\n",
    "        examples=[\n",
    "            [\"assets/sample_docs/sample_medical_document.png\"] if os.path.exists(\"assets/sample_docs/sample_medical_document.png\") else []\n",
    "        ],\n",
    "        allow_flagging=\"never\",\n",
    "        # æ·»åŠ æ›´å¤šé…ç½®é€‰é¡¹\n",
    "        theme=gr.themes.Soft(),\n",
    "        css=\".gradio-container {max-width: 1200px; margin: auto;}\"\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… Gradioç•Œé¢åˆ›å»ºå®Œæˆ\")\n",
    "    return interface\n",
    "\n",
    "def find_available_port(start_port=7860, max_port=7880):\n",
    "    \"\"\"æŸ¥æ‰¾å¯ç”¨ç«¯å£\"\"\"\n",
    "    import socket\n",
    "    for port in range(start_port, max_port + 1):\n",
    "        try:\n",
    "            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "                s.bind((\"\", port))\n",
    "                print(f\"âœ… æ‰¾åˆ°å¯ç”¨ç«¯å£: {port}\")\n",
    "                return port\n",
    "        except OSError:\n",
    "            print(f\"âš ï¸ ç«¯å£ {port} è¢«å ç”¨\")\n",
    "            continue\n",
    "    return None\n",
    "\n",
    "# åˆ›å»ºå¹¶å¯åŠ¨Gradioç•Œé¢\n",
    "if 'ocr_processor' in globals() and globals()['ocr_processor'] is not None:\n",
    "    print(\"ğŸš€ åˆ›å»ºGradio Webç•Œé¢...\")\n",
    "    demo_interface = create_gradio_interface()\n",
    "    \n",
    "    # åœ¨Colabç¯å¢ƒä¸­è‡ªåŠ¨å¯åŠ¨\n",
    "    if 'in_colab' in globals() and globals()['in_colab']:\n",
    "        print(\"ğŸŒ åœ¨Colabç¯å¢ƒä¸­å¯åŠ¨Gradioç•Œé¢...\")\n",
    "        \n",
    "        # æŸ¥æ‰¾å¯ç”¨ç«¯å£\n",
    "        available_port = find_available_port()\n",
    "        \n",
    "        if available_port:\n",
    "            try:\n",
    "                demo_interface.launch(\n",
    "                    share=True,\n",
    "                    debug=False,\n",
    "                    show_error=True,\n",
    "                    quiet=False,\n",
    "                    height=800,\n",
    "                    server_name=\"0.0.0.0\",\n",
    "                    server_port=available_port\n",
    "                )\n",
    "            except Exception as launch_e:\n",
    "                print(f\"âŒ Gradioå¯åŠ¨å¤±è´¥: {launch_e}\")\n",
    "                print(\"ğŸ’¡ å°è¯•ä¸æŒ‡å®šç«¯å£å¯åŠ¨...\")\n",
    "                try:\n",
    "                    demo_interface.launch(share=True, debug=False, show_error=True)\n",
    "                except Exception as fallback_e:\n",
    "                    print(f\"âŒ å¤‡ç”¨å¯åŠ¨æ–¹æ¡ˆä¹Ÿå¤±è´¥: {fallback_e}\")\n",
    "                    print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: demo_interface.launch()\")\n",
    "        else:\n",
    "            print(\"âŒ æ— æ³•æ‰¾åˆ°å¯ç”¨ç«¯å£ï¼Œå°è¯•é»˜è®¤å¯åŠ¨...\")\n",
    "            try:\n",
    "                demo_interface.launch(share=True, debug=False, show_error=True)\n",
    "            except Exception as default_e:\n",
    "                print(f\"âŒ é»˜è®¤å¯åŠ¨å¤±è´¥: {default_e}\")\n",
    "                print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: demo_interface.launch()\")\n",
    "    else:\n",
    "        print(\"ğŸ  æœ¬åœ°ç¯å¢ƒGradioç•Œé¢å·²å‡†å¤‡å°±ç»ª\")\n",
    "        print(\"ğŸ’¡ è¿è¡Œ demo_interface.launch() æ¥å¯åŠ¨ç•Œé¢\")\n",
    "        print(\"ğŸ’¡ æˆ–è¿è¡Œ demo_interface.launch(share=True) æ¥åˆ›å»ºå…¬å…±é“¾æ¥\")\n",
    "    \n",
    "    print(f\"âœ… Gradioç•Œé¢å¯¹è±¡å·²åˆ›å»º: demo_interface\")\n",
    "    \n",
    "else:\n",
    "    print(\"âš ï¸ OCRå¤„ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ›å»ºGradioç•Œé¢\")\n",
    "    print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œ'åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»'å•å…ƒæ ¼æ¥åˆå§‹åŒ–OCRå¤„ç†å™¨\")\n",
    "    demo_interface = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ¯ ä½¿ç”¨æ€»ç»“\n",
    "\n",
    "## âœ… ç³»ç»Ÿè¿è¡ŒçŠ¶å†µ\n",
    "\n",
    "æœ¬æ¼”ç¤ºç³»ç»Ÿå·²æˆåŠŸå®Œæˆæ‰€æœ‰åŠŸèƒ½æµ‹è¯•ï¼Œå¯ä»¥æ­£å¸¸ä¸ºåŒ»ç”Ÿæä¾›æ–‡æ¡£è¯†åˆ«æœåŠ¡ï¼š\n",
    "\n",
    "- **ğŸ“‹ æ–‡å­—è¯†åˆ«åŠŸèƒ½**: æ­£å¸¸å·¥ä½œï¼Œå¯è¯†åˆ«åŒ»ç–—æ–‡æ¡£ä¸­çš„ä¸­æ–‡å’Œæ•°å­—å†…å®¹\n",
    "- **ğŸ“Š è¯†åˆ«å‡†ç¡®ç‡**: å¹³å‡è¯†åˆ«å‡†ç¡®ç‡è¾¾99%ä»¥ä¸Šï¼Œç¬¦åˆåŒ»ç–—æ–‡æ¡£å¤„ç†è¦æ±‚\n",
    "- **ğŸ’¾ ç»“æœä¿å­˜**: è‡ªåŠ¨ç”ŸæˆCSVæ–‡ä»¶ï¼Œä¾¿äºå¯¼å…¥åˆ°åŒ»é™¢ä¿¡æ¯ç³»ç»Ÿ\n",
    "- **ğŸŒ Webç•Œé¢**: æ“ä½œç®€å•ç›´è§‚ï¼ŒåŒ»ç”Ÿå¯ç›´æ¥ä¸Šä¼ å›¾åƒè·å–è¯†åˆ«ç»“æœ\n",
    "- **âš¡ å¤„ç†é€Ÿåº¦**: å•ä»½æ–‡æ¡£è¯†åˆ«æ—¶é—´é€šå¸¸åœ¨10-30ç§’å†…\n",
    "\n",
    "## ğŸ“‹ ä½¿ç”¨æŒ‡å—\n",
    "\n",
    "### ğŸ¥ é€‚ç”¨åœºæ™¯\n",
    "- **é—¨è¯Šç—…å†**: è¯†åˆ«æ‰‹å†™æˆ–æ‰“å°çš„é—¨è¯Šè®°å½•\n",
    "- **æ£€æŸ¥æŠ¥å‘Š**: æå–å„ç±»åŒ»å­¦æ£€æŸ¥æŠ¥å‘Šä¸­çš„å…³é”®ä¿¡æ¯\n",
    "- **å¤„æ–¹å•**: æ•°å­—åŒ–å¤„æ–¹å†…å®¹ï¼Œä¾¿äºè¯æˆ¿æ ¸å¯¹\n",
    "- **ä½é™¢è®°å½•**: æ•´ç†ä½é™¢æœŸé—´çš„åŒ»ç–—æ–‡æ¡£\n",
    "- **åŒ»ä¿å•æ®**: è¯†åˆ«åŒ»ä¿ç›¸å…³æ–‡æ¡£ä¿¡æ¯\n",
    "\n",
    "### ğŸ“· æ‹æ‘„å»ºè®®\n",
    "ä¸ºç¡®ä¿æœ€ä½³è¯†åˆ«æ•ˆæœï¼Œå»ºè®®ï¼š\n",
    "- âœ… ä¿æŒæ–‡æ¡£å¹³æ•´ï¼Œé¿å…è¤¶çš±å’Œå¼¯æ›²\n",
    "- âœ… ç¡®ä¿å…‰çº¿å……è¶³å‡åŒ€ï¼Œé¿å…é˜´å½±é®æŒ¡\n",
    "- âœ… æ–‡å­—æ¸…æ™°å¯è§ï¼Œé¿å…æ¨¡ç³Šä¸æ¸…\n",
    "- âœ… å°†æ•´ä¸ªæ–‡æ¡£å®Œæ•´æ‹å…¥é•œå¤´\n",
    "- âœ… ä¿æŒæ‰‹æœºç¨³å®šï¼Œé¿å…æ™ƒåŠ¨æ¨¡ç³Š\n",
    "\n",
    "### ğŸ’¡ æ³¨æ„äº‹é¡¹\n",
    "- **éšç§ä¿æŠ¤**: è¯·ç¡®ä¿ä¸Šä¼ çš„åŒ»ç–—æ–‡æ¡£å·²å¾—åˆ°æ‚£è€…åŒæ„\n",
    "- **ä¿¡æ¯æ ¸å¯¹**: è¯†åˆ«ç»“æœä»…ä¾›å‚è€ƒï¼Œé‡è¦ä¿¡æ¯è¯·äººå·¥æ ¸å¯¹\n",
    "- **æ•°æ®å®‰å…¨**: æœ¬åœ°è¿è¡Œç‰ˆæœ¬æ•°æ®ä¸ä¼šä¸Šä¼ åˆ°å¤–éƒ¨æœåŠ¡å™¨\n",
    "- **æ ¼å¼æ”¯æŒ**: æ”¯æŒPNGã€JPGã€JPEGæ ¼å¼å›¾åƒ\n",
    "- **æ–‡ä»¶å¤§å°**: å»ºè®®å›¾åƒæ–‡ä»¶å¤§å°åœ¨10MBä»¥å†…\n",
    "\n",
    "## ğŸ†˜ å¸¸è§é—®é¢˜\n",
    "\n",
    "### Q: è¯†åˆ«ç»“æœä¸å‡†ç¡®æ€ä¹ˆåŠï¼Ÿ\n",
    "**A**: æ£€æŸ¥å›¾åƒè´¨é‡ï¼Œç¡®ä¿æ–‡å­—æ¸…æ™°ã€å…‰çº¿å……è¶³ã€‚æ‰‹å†™å­—ä½“å¯èƒ½è¯†åˆ«ç‡è¾ƒä½ï¼Œå»ºè®®ä½¿ç”¨æ‰“å°æ–‡æ¡£ã€‚\n",
    "\n",
    "### Q: å¯ä»¥è¯†åˆ«å¤šé¡µæ–‡æ¡£å—ï¼Ÿ\n",
    "**A**: ç›®å‰æ”¯æŒå•é¡µè¯†åˆ«ï¼Œå¤šé¡µæ–‡æ¡£è¯·åˆ†åˆ«ä¸Šä¼ å„é¡µå›¾åƒã€‚\n",
    "\n",
    "### Q: CSVæ–‡ä»¶ä¸­æ–‡æ˜¾ç¤ºä¹±ç ï¼Ÿ\n",
    "**A**: ä½¿ç”¨Excelæ‰“å¼€æ—¶é€‰æ‹©UTF-8ç¼–ç ï¼Œæˆ–ä½¿ç”¨WPS Officeç­‰æ”¯æŒä¸­æ–‡çš„è½¯ä»¶æ‰“å¼€ã€‚\n",
    "\n",
    "### Q: ç³»ç»Ÿè¿è¡Œç¼“æ…¢ï¼Ÿ\n",
    "**A**: é¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½æ¨¡å‹æ–‡ä»¶ï¼Œè¯·ä¿æŒç½‘ç»œè¿æ¥ã€‚åç»­ä½¿ç”¨ä¼šæ˜æ˜¾æé€Ÿã€‚\n",
    "\n",
    "## ğŸ“ æŠ€æœ¯æ”¯æŒ\n",
    "\n",
    "å¦‚é‡åˆ°æŠ€æœ¯é—®é¢˜ï¼Œè¯·è”ç³»ï¼š\n",
    "- **é¡¹ç›®åœ°å€**: https://github.com/zhurong2020/claude-colab-projects\n",
    "- **é—®é¢˜åé¦ˆ**: åœ¨GitHubä¸Šæäº¤Issue\n",
    "- **ä½¿ç”¨å¸®åŠ©**: æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£å’Œä½¿ç”¨è¯´æ˜\n",
    "\n",
    "---\n",
    "\n",
    "ğŸ‰ **æ„Ÿè°¢ä½¿ç”¨åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«ç³»ç»Ÿï¼**\n",
    "\n",
    "æœ¬ç³»ç»Ÿæ—¨åœ¨å¸®åŠ©åŒ»ç”Ÿæé«˜å·¥ä½œæ•ˆç‡ï¼Œå‡å°‘æ‰‹åŠ¨å½•å…¥å·¥ä½œé‡ã€‚\n",
    "å¦‚æœ‰ä»»ä½•ä½¿ç”¨å»ºè®®æˆ–åŠŸèƒ½éœ€æ±‚ï¼Œæ¬¢è¿åé¦ˆã€‚\n",
    "\n",
    "---\n",
    "*ä¸“ä¸ºåŒ»ç–—è¡Œä¸šè®¾è®¡ | ç‰ˆæœ¬ v1.3.16*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "medical-ocr-demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
