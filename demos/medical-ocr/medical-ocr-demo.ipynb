{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ç‰ˆæœ¬**: v1.3.12 (ä¿®å¤Gradioç•Œé¢è°ƒè¯•ä¿¡æ¯æ˜¾ç¤ºå’Œæ¸…ç†ä¸å‡†ç¡®æè¿°) | **æ›´æ–°æ—¶é—´**: 2025-08-24\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/zhurong2020/claude-colab-projects/blob/main/demos/medical-ocr/medical-ocr-demo.ipynb) [![GitHub](https://img.shields.io/badge/GitHub-æºä»£ç -blue?logo=github)](https://github.com/zhurong2020/claude-colab-projects/tree/main/demos/medical-ocr)\n",
    "\n",
    "## ğŸ¯ åŠŸèƒ½ç‰¹æ€§\n",
    "- ğŸ“„ æ”¯æŒåŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«\n",
    "- ğŸ¤– ä½¿ç”¨PaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "- ğŸ“Š è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–CSVæŠ¥å‘Š\n",
    "- ğŸ–¼ï¸ æ”¯æŒå¤šç§å›¾åƒæ ¼å¼è¾“å…¥\n",
    "- ğŸ’¡ ç®€å•æ˜“ç”¨çš„äº¤äº’ç•Œé¢\n",
    "- ğŸ  å®Œæ•´æœ¬åœ°å¼€å‘ç¯å¢ƒæ”¯æŒ\n",
    "- ğŸŒ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«\n",
    "- ğŸ—ï¸ ç‹¬ç«‹åº”ç”¨æ¶æ„ï¼Œå¯ç›´æ¥åœ¨Colabè¿è¡Œ\n",
    "\n",
    "## ğŸ”§ æ›´æ–°å†…å®¹ (v1.3.12)\n",
    "- **ğŸ”§ Gradioä¿®å¤**: ä¿®å¤webç•Œé¢è°ƒè¯•ä¿¡æ¯æ— æ³•æ˜¾ç¤ºçš„é—®é¢˜\n",
    "- **ğŸ“Š è°ƒè¯•æ•è·**: ä½¿ç”¨redirect_stdoutæ•è·OCRå¤„ç†è¿‡ç¨‹çš„è°ƒè¯•ä¿¡æ¯\n",
    "- **ğŸ¯ é—®é¢˜å®šä½**: è°ƒè¯•ä¿¡æ¯ç°åœ¨ä¼šæ˜¾ç¤ºåœ¨webç•Œé¢ä¸­ï¼Œä¾¿äºé—®é¢˜è¯Šæ–­\n",
    "- **ğŸ“ æ–‡æ¡£æ¸…ç†**: æ¸…ç†ä»£ç ä¸­ä¸å‡†ç¡®çš„\"ä¿®å¤XXXé—®é¢˜\"æè¿°\n",
    "- **ğŸ”„ ç‰ˆæœ¬è¿½è¸ª**: æŒ‰çº¦å®šæ›´æ–°æœ€å°ç‰ˆæœ¬å·ä¾¿äºè§‚å¯Ÿå˜åŒ–\n",
    "\n",
    "## ğŸš€ ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### Colabç¯å¢ƒ\n",
    "1. ç‚¹å‡»ä¸Šæ–¹çš„\"Open in Colab\"æŒ‰é’®\n",
    "2. è¿è¡Œç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "3. ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\n",
    "4. æ‰§è¡ŒOCRæ–‡å­—è¯†åˆ«\n",
    "5. ä¸‹è½½CSVç»“æœæ–‡ä»¶\n",
    "\n",
    "### æœ¬åœ°ç¯å¢ƒ\n",
    "```bash\n",
    "# ä»é¡¹ç›®æ ¹ç›®å½•ä¸€é”®å¯åŠ¨\n",
    "../start_local.sh\n",
    "\n",
    "# æ‰‹åŠ¨å¯åŠ¨\n",
    "source ../venv/bin/activate && jupyter notebook\n",
    "```\n",
    "\n",
    "### ç›®å½•ç»“æ„\n",
    "```\n",
    "medical-ocr/\n",
    "â”œâ”€â”€ medical-ocr-demo.ipynb    # æœ¬æ¼”ç¤ºæ–‡ä»¶\n",
    "â”œâ”€â”€ gradio_demo.py           # Webç•Œé¢ç‰ˆæœ¬\n",
    "â”œâ”€â”€ test_chinese_encoding_fix.py  # ä¸­æ–‡ç¼–ç æµ‹è¯•\n",
    "â””â”€â”€ assets/                  # èµ„æºæ–‡ä»¶\n",
    "    â”œâ”€â”€ sample_docs/         # ç¤ºä¾‹æ–‡æ¡£\n",
    "    â””â”€â”€ results/            # OCRç»“æœ\n",
    "```\n",
    "\n",
    "---\n",
    "*ä½¿ç”¨ Claude Code å¼€å‘ï¼Œæ”¯æŒ Google Colab å’Œæœ¬åœ°è¿è¡Œ ğŸš€*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ç¯å¢ƒæ£€æŸ¥å’ŒåŸºç¡€è®¾ç½®\n",
    "# ================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"æ£€æŸ¥è¿è¡Œç¯å¢ƒå¹¶æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯\"\"\"\n",
    "    print(\"ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
    "    try:\n",
    "        import google.colab # type: ignore # noqa: F401 # éœ€è¦ç”¨äºç¯å¢ƒæ£€æµ‹\n",
    "        print(\"âœ… è¿è¡Œåœ¨Google Colab\")\n",
    "        in_colab = True\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ è¿è¡Œåœ¨æœ¬åœ°ç¯å¢ƒ\")\n",
    "        in_colab = False\n",
    "    \n",
    "    # æ£€æŸ¥GPU\n",
    "    try:\n",
    "        import torch\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"âœ… è®¡ç®—è®¾å¤‡: {device}\")\n",
    "        if device == 'cuda':\n",
    "            print(f\"âœ… GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    \n",
    "    return in_colab\n",
    "\n",
    "# è¿è¡Œç¯å¢ƒæ£€æŸ¥\n",
    "in_colab = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# ================================\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"å®‰è£…é¡¹ç›®æ‰€éœ€çš„ä¾èµ–åŒ…\"\"\"\n",
    "    print(\"ğŸ“¦ å®‰è£…åŒ»ç–—OCRé¡¹ç›®ä¾èµ–...\")\n",
    "    \n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # æ ¸å¿ƒä¾èµ–åŒ…åˆ—è¡¨\n",
    "    packages = [\n",
    "        'paddlepaddle',\n",
    "        'paddleocr',\n",
    "        'pandas',\n",
    "        'pillow',\n",
    "        'opencv-python',\n",
    "        'tqdm',\n",
    "        'gradio'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            if package == 'opencv-python':\n",
    "                import cv2  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯opencvå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            elif package == 'pillow':\n",
    "                from PIL import Image  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯PILå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            else:\n",
    "                __import__(package.replace('-', '_'))\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"ğŸ“¥ å®‰è£… {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"âœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ!\")\n",
    "\n",
    "# å®‰è£…ä¾èµ–\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "# ================================\n",
    "\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "    from tqdm import tqdm\n",
    "    from paddleocr import PaddleOCR  # type: ignore\n",
    "    import gradio as gr  # type: ignore\n",
    "    print(\"ğŸ“š æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åº“å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œä¾èµ–å®‰è£…å•å…ƒæ ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»\n",
    "# ================================\n",
    "\n",
    "class MedicalOCRProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨\"\"\"\n",
    "        print(\"ğŸ¥ åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨...\")\n",
    "        \n",
    "        # æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "        try:\n",
    "            import torch\n",
    "            use_gpu = torch.cuda.is_available()\n",
    "            gpu_info = f\"GPUå¯ç”¨: {use_gpu}\"\n",
    "            if use_gpu:\n",
    "                gpu_info += f\" (è®¾å¤‡: {torch.cuda.get_device_name(0)})\"\n",
    "            print(f\"âš¡ {gpu_info}\")\n",
    "        except ImportError:\n",
    "            use_gpu = False\n",
    "            print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "        \n",
    "        # åˆå§‹åŒ–PaddleOCRï¼Œä½¿ç”¨å…¼å®¹çš„é…ç½®\n",
    "        try:\n",
    "            # ä½¿ç”¨å…¼å®¹çš„å‚æ•°åˆå§‹åŒ–PaddleOCR (v3.1.1)\n",
    "            self.ocr = PaddleOCR(use_angle_cls=True, lang='ch')\n",
    "            print(\"âœ… ä½¿ç”¨å…¼å®¹å‚æ•°åˆå§‹åŒ–OCRå¼•æ“\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ OCRåˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "            self.ocr = None\n",
    "            raise RuntimeError(f\"PaddleOCRåˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "        \n",
    "        print(\"âœ… OCRå¼•æ“åˆå§‹åŒ–å®Œæˆ\")\n",
    "    \n",
    "    def _preprocess_image(self, image_path):\n",
    "        \"\"\"é¢„å¤„ç†å›¾åƒï¼Œç¡®ä¿æ ¼å¼å’Œè´¨é‡é€‚åˆOCR\"\"\"\n",
    "        try:\n",
    "            from PIL import Image as PILImage\n",
    "            import os # type: ignore\n",
    "            \n",
    "            # æ‰“å¼€å¹¶éªŒè¯å›¾åƒ\n",
    "            with PILImage.open(image_path) as img:\n",
    "                print(f\"ğŸ“Š åŸå§‹å›¾åƒä¿¡æ¯: å°ºå¯¸={img.size}, æ¨¡å¼={img.mode}\")\n",
    "                \n",
    "                # è½¬æ¢ä¸ºRGBæ ¼å¼ï¼ˆå¦‚æœä¸æ˜¯çš„è¯ï¼‰\n",
    "                if img.mode != 'RGB':\n",
    "                    print(f\"ğŸ”„ è½¬æ¢å›¾åƒæ¨¡å¼: {img.mode} -> RGB\")\n",
    "                    img = img.convert('RGB')\n",
    "                \n",
    "                # æ£€æŸ¥å›¾åƒå°ºå¯¸ï¼Œå¦‚æœè¿‡å¤§åˆ™é€‚å½“ç¼©å°\n",
    "                max_size = 2048\n",
    "                if max(img.size) > max_size:\n",
    "                    print(f\"ğŸ”„ è°ƒæ•´å›¾åƒå°ºå¯¸: {img.size}\")\n",
    "                    ratio = max_size / max(img.size)\n",
    "                    new_size = (int(img.size[0] * ratio), int(img.size[1] * ratio))\n",
    "                    img = img.resize(new_size, PILImage.Resampling.LANCZOS)\n",
    "                    print(f\"âœ… æ–°å°ºå¯¸: {img.size}\")\n",
    "                \n",
    "                # ä¿å­˜é¢„å¤„ç†åçš„å›¾åƒ\n",
    "                processed_path = image_path.replace('.png', '_processed.png').replace('.jpg', '_processed.jpg').replace('.jpeg', '_processed.jpg')\n",
    "                if processed_path == image_path:\n",
    "                    processed_path = image_path.replace('.', '_processed.')\n",
    "                \n",
    "                img.save(processed_path, quality=95, optimize=False)\n",
    "                print(f\"ğŸ’¾ é¢„å¤„ç†å›¾åƒå·²ä¿å­˜: {processed_path}\")\n",
    "                \n",
    "                return processed_path\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ å›¾åƒé¢„å¤„ç†å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹å›¾åƒ\")\n",
    "            return image_path\n",
    "\n",
    "    def _parse_ocr_result(self, result):\n",
    "        \"\"\"è§£æOCRç»“æœ - å…¼å®¹å¤šç§PaddleOCRè¿”å›æ ¼å¼\"\"\"\n",
    "        extracted_texts = []\n",
    "        try:\n",
    "            if not result or not isinstance(result, list) or not result[0]:\n",
    "                print(\"âš ï¸ OCRç»“æœä¸ºç©ºæˆ–æ ¼å¼ä¸æ­£ç¡®\")\n",
    "                return []\n",
    "\n",
    "            page_result = result[0]\n",
    "\n",
    "            # æ–°ç‰ˆ PaddleOCR v3.1.1+ (è¿”å›å¸¦ .json å±æ€§çš„ OCRResult å¯¹è±¡)\n",
    "            if hasattr(page_result, 'json'):\n",
    "                print(\"âœ… æ£€æµ‹åˆ°PaddleOCR v3.1.1+ OCRResultå¯¹è±¡æ ¼å¼\")\n",
    "                json_result = page_result.json\n",
    "                if isinstance(json_result, dict) and 'res' in json_result:\n",
    "                    res_data = json_result['res']\n",
    "                    if res_data and 'rec_texts' in res_data and 'rec_scores' in res_data:\n",
    "                        texts, scores = res_data['rec_texts'], res_data['rec_scores']\n",
    "                        print(f\"ğŸ“Š è¯†åˆ«åˆ°æ–‡æœ¬æ•°é‡: {len(texts) if texts else 0}\")\n",
    "                        if texts and scores:\n",
    "                            for text, score in zip(texts, scores):\n",
    "                                if text and text.strip():\n",
    "                                    extracted_texts.append({'text': text.strip(), 'confidence': float(score)})\n",
    "                return extracted_texts\n",
    "\n",
    "            # å…¼å®¹ç›´æ¥è¿”å›å­—å…¸åˆ—è¡¨çš„æ ¼å¼\n",
    "            elif isinstance(page_result, list) and page_result and isinstance(page_result[0], dict) and 'text' in page_result[0]:\n",
    "                print(\"âœ… æ£€æµ‹åˆ°å­—å…¸åˆ—è¡¨æ ¼å¼\")\n",
    "                for line in page_result:\n",
    "                    text, confidence = line.get('text', ''), line.get('confidence', 0.0)\n",
    "                    if text.strip():\n",
    "                        extracted_texts.append({'text': text.strip(), 'confidence': float(confidence)})\n",
    "                return extracted_texts\n",
    "\n",
    "            # å…¼å®¹æ—§ç‰ˆ PaddleOCR (è¿”å›åŒ…å«å…ƒç»„çš„åˆ—è¡¨)\n",
    "            elif isinstance(page_result, list):\n",
    "                print(\"âœ… æ£€æµ‹åˆ°ä¼ ç»Ÿåˆ—è¡¨æ ¼å¼\")\n",
    "                for line_result in page_result:\n",
    "                    if (line_result and len(line_result) >= 2 and\n",
    "                        line_result[1] and len(line_result[1]) >= 2):\n",
    "                        text, confidence = line_result[1]\n",
    "                        if text and text.strip():\n",
    "                            extracted_texts.append({'text': text.strip(), 'confidence': float(confidence)})\n",
    "                return extracted_texts\n",
    "            \n",
    "            else:\n",
    "                print(f\"âš ï¸ æœªçŸ¥çš„OCRç»“æœæ ¼å¼: {type(page_result)}\")\n",
    "                self._debug_result_structure(result)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ç»“æœè§£æå¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        \n",
    "        return extracted_texts\n",
    "\n",
    "    def extract_text_from_image(self, image_path):\n",
    "        \"\"\"ä»å›¾åƒä¸­æå–æ–‡å­— - å¢å¼ºç‰ˆæœ¬\"\"\"\n",
    "        import os\n",
    "        \n",
    "        if self.ocr is None:\n",
    "            print(\"âŒ OCRå¼•æ“æœªåˆå§‹åŒ–\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            # éªŒè¯å›¾åƒæ–‡ä»¶\n",
    "            if not os.path.exists(image_path):\n",
    "                print(f\"âŒ å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨: {image_path}\")\n",
    "                return []\n",
    "            \n",
    "            if os.path.getsize(image_path) == 0:\n",
    "                print(f\"âŒ å›¾åƒæ–‡ä»¶ä¸ºç©º: {image_path}\")\n",
    "                return []\n",
    "            \n",
    "            print(f\"ğŸ“„ æ­£åœ¨å¤„ç†å›¾åƒ: {image_path}\")\n",
    "            print(f\"ğŸ“Š æ–‡ä»¶å¤§å°: {os.path.getsize(image_path)} å­—èŠ‚\")\n",
    "            \n",
    "            # é¢„å¤„ç†å›¾åƒï¼šç¡®ä¿å›¾åƒæ ¼å¼å’Œè´¨é‡é€‚åˆOCR\n",
    "            processed_image_path = self._preprocess_image(image_path)\n",
    "            \n",
    "            # ä½¿ç”¨PaddleOCRè¿›è¡Œè¯†åˆ«\n",
    "            result = None\n",
    "            extracted_texts = []\n",
    "            \n",
    "            # ä½¿ç”¨predictæ–¹æ³• (æ¨èçš„æ–°ç‰ˆæœ¬API)\n",
    "            try:\n",
    "                print(\"ğŸ”„ å°è¯•ä½¿ç”¨predictæ–¹æ³•...\")\n",
    "                result = self.ocr.predict(processed_image_path)\n",
    "                print(f\"âœ… predictæ–¹æ³•è°ƒç”¨æˆåŠŸï¼Œç»“æœç±»å‹: {type(result)}\")\n",
    "                extracted_texts = self._parse_ocr_result(result)\n",
    "                \n",
    "                if extracted_texts:\n",
    "                    print(f\"âœ… æˆåŠŸè¯†åˆ« {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "                    return extracted_texts\n",
    "                \n",
    "            except Exception as e1:\n",
    "                print(f\"âš ï¸ predictæ–¹æ³•å¤±è´¥: {e1}\")\n",
    "                \n",
    "                # å°è¯•ä½¿ç”¨ä¼ ç»Ÿçš„ocræ–¹æ³•\n",
    "                try:\n",
    "                    print(\"ğŸ”„ å°è¯•ä½¿ç”¨ä¼ ç»Ÿocræ–¹æ³•...\")\n",
    "                    result = self.ocr.ocr(processed_image_path)  # type: ignore\n",
    "                    print(f\"âœ… OCRæ–¹æ³•è°ƒç”¨æˆåŠŸï¼Œç»“æœç±»å‹: {type(result)}\")\n",
    "                    extracted_texts = self._parse_ocr_result(result)\n",
    "                    \n",
    "                    if extracted_texts:\n",
    "                        print(f\"âœ… æˆåŠŸè¯†åˆ« {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "                        return extracted_texts\n",
    "                        \n",
    "                except Exception as e2:\n",
    "                    print(f\"âŒ æ‰€æœ‰å¯ç”¨çš„OCRè°ƒç”¨æ–¹æ³•éƒ½å¤±è´¥\")\n",
    "                    print(f\"è¯¦ç»†é”™è¯¯: predict={e1}, ocr={e2}\")\n",
    "            \n",
    "            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½æ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—\n",
    "            if not extracted_texts:\n",
    "                print(\"âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡å­—å†…å®¹\")\n",
    "                self._debug_result_structure(result)\n",
    "                self._check_image_quality(processed_image_path)\n",
    "                \n",
    "                return []\n",
    "            \n",
    "            return extracted_texts\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "            return []\n",
    "    \n",
    "    def _debug_result_structure(self, result):\n",
    "        \"\"\"è°ƒè¯•ç»“æœç»“æ„\"\"\"\n",
    "        try:\n",
    "            print(f\"ğŸ” è°ƒè¯•ä¿¡æ¯: resultç±»å‹={type(result)}\")\n",
    "            if result:\n",
    "                print(f\"ğŸ” resulté•¿åº¦: {len(result) if hasattr(result, '__len__') else 'N/A'}\")\n",
    "                if isinstance(result, list) and len(result) > 0:\n",
    "                    first_item = result[0]\n",
    "                    print(f\"ğŸ” ç¬¬ä¸€é¡¹ç±»å‹: {type(first_item)}\")\n",
    "                    if isinstance(first_item, dict):\n",
    "                        print(f\"ğŸ” å­—å…¸é”®: {list(first_item.keys())}\")\n",
    "                    elif hasattr(first_item, '__dict__'):\n",
    "                        print(f\"ğŸ” å¯¹è±¡å±æ€§: {list(vars(first_item).keys())}\")\n",
    "                    elif isinstance(first_item, list) and len(first_item) > 0:\n",
    "                        print(f\"ğŸ” åµŒå¥—åˆ—è¡¨é•¿åº¦: {len(first_item)}\")\n",
    "                        if len(first_item) > 0:\n",
    "                            print(f\"ğŸ” åµŒå¥—é¡¹ç±»å‹: {type(first_item[0])}\")\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ” è°ƒè¯•ä¿¡æ¯è·å–å¤±è´¥: {e}\")\n",
    "    \n",
    "    def _check_image_quality(self, image_path):\n",
    "        \"\"\"æ£€æŸ¥å›¾åƒè´¨é‡\"\"\"\n",
    "        try:\n",
    "            from PIL import Image as PILImage\n",
    "            import os\n",
    "            \n",
    "            if not os.path.exists(image_path):\n",
    "                print(\"ğŸ” å›¾åƒæ–‡ä»¶ä¸å­˜åœ¨\")\n",
    "                return\n",
    "            \n",
    "            with PILImage.open(image_path) as img:\n",
    "                width, height = img.size\n",
    "                total_pixels = width * height\n",
    "                \n",
    "                print(f\"ğŸ” å›¾åƒè´¨é‡æ£€æŸ¥:\")\n",
    "                print(f\"   å°ºå¯¸: {width}x{height} ({total_pixels:,} åƒç´ )\")\n",
    "                print(f\"   æ ¼å¼: {img.format}\")\n",
    "                print(f\"   æ¨¡å¼: {img.mode}\")\n",
    "                \n",
    "                # è´¨é‡è¯„ä¼°\n",
    "                if total_pixels < 50000:\n",
    "                    print(\"   âš ï¸ å›¾åƒåˆ†è¾¨ç‡è¾ƒä½ï¼Œå¯èƒ½å½±å“è¯†åˆ«æ•ˆæœ\")\n",
    "                elif total_pixels > 4000000:\n",
    "                    print(\"   â„¹ï¸ å›¾åƒåˆ†è¾¨ç‡å¾ˆé«˜ï¼Œå¤„ç†é€Ÿåº¦å¯èƒ½è¾ƒæ…¢\")\n",
    "                else:\n",
    "                    print(\"   âœ… å›¾åƒåˆ†è¾¨ç‡é€‚ä¸­\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ” å›¾åƒè´¨é‡æ£€æŸ¥å¤±è´¥: {e}\")\n",
    "    \n",
    "    def process_single_image(self, image_path):\n",
    "        \"\"\"å¤„ç†å•ä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        import os\n",
    "        print(f\"ğŸ“„ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # æå–æ–‡å­—\n",
    "        extracted_texts = self.extract_text_from_image(image_path)\n",
    "        \n",
    "        # æ•´ç†ç»“æœ\n",
    "        results = []\n",
    "        for i, item in enumerate(extracted_texts):\n",
    "            results.append({\n",
    "                'file_name': os.path.basename(image_path),\n",
    "                'line_number': i + 1,\n",
    "                'extracted_text': item['text'],\n",
    "                'confidence': round(item['confidence'], 4)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_multiple_images(self, image_paths):\n",
    "        \"\"\"æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        print(f\"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(image_paths)} ä¸ªå›¾åƒæ–‡ä»¶...\")\n",
    "        \n",
    "        for image_path in tqdm(image_paths, desc=\"å¤„ç†è¿›åº¦\"):\n",
    "            results = self.process_single_image(image_path)\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_results_to_csv(self, results, output_path):\n",
    "        \"\"\"ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶\"\"\"\n",
    "        if not results:\n",
    "            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œåˆ›å»ºç©ºçš„DataFrame\n",
    "            df = pd.DataFrame(columns=['file_name', 'line_number', 'extracted_text', 'confidence'])\n",
    "        else:\n",
    "            df = pd.DataFrame(results)\n",
    "        \n",
    "        df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        return df\n",
    "\n",
    "# åˆå§‹åŒ–OCRå¤„ç†å™¨\n",
    "print(\"ğŸ”§ æ­£åœ¨åˆå§‹åŒ–OCRå¤„ç†å™¨...\")\n",
    "try:\n",
    "    ocr_processor = MedicalOCRProcessor()\n",
    "    print(\"âœ… OCRå¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ OCRå¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·æ£€æŸ¥PaddleOCRå®‰è£…æ˜¯å¦æ­£ç¡®\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£ï¼ˆç”¨äºæ¼”ç¤ºï¼‰- ä¼˜åŒ–å­—ä½“åŠ è½½å’Œæ˜¾ç¤º v1.3.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# æ¼”ç¤ºOCRåŠŸèƒ½\n",
    "# ================================\n",
    "\n",
    "def demo_ocr_functionality():\n",
    "    \"\"\"æ¼”ç¤ºOCRåŠŸèƒ½\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹æ¼”ç¤ºåŒ»ç–—OCRåŠŸèƒ½...\")\n",
    "    \n",
    "    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å›¾åƒè·¯å¾„\n",
    "    import os\n",
    "    sample_image_path = sample_doc # type: ignore\n",
    "    if not os.path.exists(sample_image_path):\n",
    "        # å°è¯•assetsç›®å½•ä¸­çš„ç¤ºä¾‹æ–‡æ¡£\n",
    "        assets_path = 'assets/sample_docs/sample_medical_document.png'\n",
    "        if os.path.exists(assets_path):\n",
    "            sample_image_path = assets_path\n",
    "        else:\n",
    "            sample_image_path = 'sample_medical_document.png'\n",
    "    \n",
    "    print(f\"ğŸ“„ ä½¿ç”¨å›¾åƒæ–‡ä»¶: {sample_image_path}\")\n",
    "    \n",
    "    # å¤„ç†ç¤ºä¾‹æ–‡æ¡£\n",
    "    results = ocr_processor.process_single_image(sample_image_path)\n",
    "    \n",
    "    # æ˜¾ç¤ºè¯†åˆ«ç»“æœ\n",
    "    print(\"\\nğŸ“Š æ–‡å­—è¯†åˆ«ç»“æœ:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"è¡Œ{result['line_number']:2d}: {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœåˆ°CSV (assets/resultsç›®å½•)\n",
    "    os.makedirs('assets/results', exist_ok=True)\n",
    "    csv_path = 'assets/results/ocr_results_demo.csv'\n",
    "    df = ocr_processor.save_results_to_csv(results, csv_path)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å…±è¯†åˆ«å‡º {len(results)} è¡Œæ–‡å­—\")\n",
    "    print(f\"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ° CSV æ–‡ä»¶: {csv_path}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºCSVå†…å®¹é¢„è§ˆ\n",
    "    if len(results) > 0:\n",
    "        print(\"\\nğŸ“‹ CSVæ–‡ä»¶é¢„è§ˆ:\")\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼Œè¯·æ£€æŸ¥å›¾åƒæ–‡ä»¶\")\n",
    "    \n",
    "    return df, csv_path\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demo_df, demo_csv = demo_ocr_functionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å›¾åƒä¸Šä¼ å¤„ç†æ¨¡å—\n",
    "# ================================\n",
    "\n",
    "import os # type: ignore\n",
    "import numpy as np  # type: ignore # noqa: F401\n",
    "from PIL import Image as PILImage  # type: ignore # noqa: F401\n",
    "\n",
    "print(\"ğŸ” å›¾åƒå¤„ç†æ¨¡å—å·²åŠ è½½ï¼Œå‡†å¤‡æ¥æ”¶ä¸Šä¼ å›¾åƒ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# Gradio Webäº¤äº’ç•Œé¢\n",
    "# ================================\n",
    "\n",
    "def create_gradio_interface():\n",
    "    \"\"\"åˆ›å»ºGradio Webç•Œé¢ç”¨äºå›¾åƒä¸Šä¼ å’ŒOCRå¤„ç†\"\"\"\n",
    "    \n",
    "    def process_uploaded_image(image):\n",
    "        \"\"\"å¤„ç†ä¸Šä¼ çš„å›¾åƒ\"\"\"\n",
    "        import tempfile\n",
    "        import os\n",
    "        \n",
    "        if image is None:\n",
    "            return \"âŒ è¯·ä¸Šä¼ ä¸€ä¸ªå›¾åƒæ–‡ä»¶\", None\n",
    "        \n",
    "        try:\n",
    "            print(f\"ğŸ“¸ æ”¶åˆ°ä¸Šä¼ å›¾åƒï¼Œç±»å‹: {type(image)}\")\n",
    "            print(f\"ğŸ“¸ å›¾åƒå°ºå¯¸: {image.size if hasattr(image, 'size') else 'N/A'}\")\n",
    "            print(f\"ğŸ“¸ å›¾åƒæ¨¡å¼: {image.mode if hasattr(image, 'mode') else 'N/A'}\")\n",
    "            \n",
    "            # åˆ›å»ºä¸´æ—¶æ–‡ä»¶ä¿å­˜ä¸Šä¼ çš„å›¾åƒ\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix='.png') as tmp_file:\n",
    "                temp_image_path = tmp_file.name\n",
    "                print(f\"ğŸ’¾ åˆ›å»ºä¸´æ—¶æ–‡ä»¶: {temp_image_path}\")\n",
    "            \n",
    "            # ç¡®ä¿å›¾åƒæ˜¯RGBæ ¼å¼å¹¶ä¿å­˜\n",
    "            if hasattr(image, 'mode') and image.mode != 'RGB':\n",
    "                print(f\"ğŸ”„ è½¬æ¢å›¾åƒæ¨¡å¼: {image.mode} -> RGB\")\n",
    "                image = image.convert('RGB')\n",
    "            \n",
    "            # ä¿å­˜å›¾åƒ\n",
    "            image.save(temp_image_path, 'PNG', quality=95)\n",
    "            print(f\"ğŸ’¾ å›¾åƒå·²ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶\")\n",
    "            \n",
    "            # éªŒè¯ä¸´æ—¶æ–‡ä»¶\n",
    "            if not os.path.exists(temp_image_path):\n",
    "                return \"âŒ ä¸´æ—¶æ–‡ä»¶åˆ›å»ºå¤±è´¥\", None\n",
    "                \n",
    "            file_size = os.path.getsize(temp_image_path)\n",
    "            print(f\"ğŸ“Š ä¸´æ—¶æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚\")\n",
    "            \n",
    "            if file_size == 0:\n",
    "                return \"âŒ å›¾åƒæ–‡ä»¶ä¸ºç©ºï¼Œä¿å­˜å¤±è´¥\", None\n",
    "            \n",
    "            print(\"ğŸš€ å¼€å§‹OCRå¤„ç†...\")\n",
    "            \n",
    "            # ä½¿ç”¨OCRå¤„ç†å™¨å¤„ç†å›¾åƒ\n",
    "            results = ocr_processor.process_single_image(temp_image_path)\n",
    "            \n",
    "            print(f\"ğŸ“Š OCRå¤„ç†å®Œæˆï¼Œè¯†åˆ«åˆ° {len(results) if results else 0} è¡Œæ–‡å­—\")\n",
    "            \n",
    "            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "            try:\n",
    "                os.unlink(temp_image_path)\n",
    "                print(\"ğŸ—‘ï¸ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {e}\")\n",
    "            \n",
    "            # æ ¼å¼åŒ–è¾“å‡ºç»“æœ\n",
    "            if results and len(results) > 0:\n",
    "                output_text = f\"ğŸ‰ æˆåŠŸè¯†åˆ«å‡º {len(results)} è¡Œæ–‡å­—:\\\\n\\\\n\"\n",
    "                for result in results:\n",
    "                    output_text += f\"è¡Œ{result['line_number']:2d}: {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\\\\n\"\n",
    "                \n",
    "                # åˆ›å»ºCSVæ•°æ®ç”¨äºä¸‹è½½\n",
    "                import pandas as pd\n",
    "                import io\n",
    "                \n",
    "                df = pd.DataFrame(results)\n",
    "                csv_buffer = io.StringIO()\n",
    "                df.to_csv(csv_buffer, index=False, encoding='utf-8-sig')\n",
    "                csv_data = csv_buffer.getvalue()\n",
    "                \n",
    "                # å°†CSVæ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ä»¥ä¾›ä¸‹è½½\n",
    "                with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv', encoding='utf-8-sig') as csv_file:\n",
    "                    csv_file.write(csv_data)\n",
    "                    csv_file_path = csv_file.name\n",
    "                \n",
    "                print(f\"ğŸ“„ CSVæ–‡ä»¶å·²åˆ›å»º: {csv_file_path}\")\n",
    "                return output_text, csv_file_path\n",
    "            else:\n",
    "                # æä¾›æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯\n",
    "                debug_info = \"ğŸ” è°ƒè¯•ä¿¡æ¯:\\\\n\"\n",
    "                debug_info += f\"- å›¾åƒå°ºå¯¸: {image.size}\\\\n\" if hasattr(image, 'size') else \"\"\n",
    "                debug_info += f\"- å›¾åƒæ¨¡å¼: {image.mode}\\\\n\" if hasattr(image, 'mode') else \"\"\n",
    "                debug_info += f\"- ä¸´æ—¶æ–‡ä»¶å¤§å°: {file_size} å­—èŠ‚\\\\n\"\n",
    "                debug_info += \"\\\\nå¯èƒ½çš„åŸå› :\\\\n\"\n",
    "                debug_info += \"1. å›¾åƒä¸­æ²¡æœ‰æ¸…æ™°çš„æ–‡å­—\\\\n\"\n",
    "                debug_info += \"2. å›¾åƒåˆ†è¾¨ç‡è¿‡ä½æˆ–è¿‡é«˜\\\\n\"\n",
    "                debug_info += \"3. æ–‡å­—é¢œè‰²ä¸èƒŒæ™¯å¯¹æ¯”åº¦ä¸è¶³\\\\n\"\n",
    "                debug_info += \"4. OCRå¼•æ“åˆå§‹åŒ–é—®é¢˜\\\\n\"\n",
    "                debug_info += \"\\\\nå»ºè®®:\\\\n\"\n",
    "                debug_info += \"- ç¡®ä¿å›¾åƒæ¸…æ™°ä¸”æ–‡å­—å¯è¯»\\\\n\"\n",
    "                debug_info += \"- å°è¯•ä½¿ç”¨é«˜å¯¹æ¯”åº¦çš„å›¾åƒ\\\\n\"\n",
    "                debug_info += \"- æ£€æŸ¥å›¾åƒæ˜¯å¦åŒ…å«ä¸­æ–‡æˆ–è‹±æ–‡æ–‡å­—\"\n",
    "                \n",
    "                return f\"ğŸ˜ æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡å­—å†…å®¹\\\\n\\\\n{debug_info}\", None\n",
    "                \n",
    "        except Exception as e:\n",
    "            error_msg = f\"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}\"\n",
    "            print(f\"ERROR: {error_msg}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            return f\"{error_msg}\\\\n\\\\nğŸ” è¯¦ç»†é”™è¯¯ä¿¡æ¯å·²è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œè¯·æ£€æŸ¥\", None\n",
    "    \n",
    "    # åˆ›å»ºGradioç•Œé¢\n",
    "    with gr.Blocks(title=\"åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«\", theme=gr.themes.Soft()) as demo: # type: ignore\n",
    "        gr.Markdown(\"\"\"\n",
    "        # ğŸ¥ åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«ç³»ç»Ÿ\n",
    "        \n",
    "        ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒï¼Œç³»ç»Ÿå°†è‡ªåŠ¨è¯†åˆ«å…¶ä¸­çš„æ–‡å­—å†…å®¹å¹¶ç”ŸæˆCSVæŠ¥å‘Š\n",
    "        \n",
    "        **æ”¯æŒæ ¼å¼**: PNG, JPG, JPEG  \n",
    "        **è¯†åˆ«è¯­è¨€**: ä¸­æ–‡ã€è‹±æ–‡  \n",
    "        **è¾“å‡ºæ ¼å¼**: CSVæ–‡ä»¶\n",
    "        \"\"\")\n",
    "        \n",
    "        with gr.Row():\n",
    "            with gr.Column():\n",
    "                # å›¾åƒä¸Šä¼ ç»„ä»¶\n",
    "                image_input = gr.Image(\n",
    "                    label=\"ğŸ“„ ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\",\n",
    "                    type=\"pil\",\n",
    "                    height=400\n",
    "                )\n",
    "                \n",
    "                # å¤„ç†æŒ‰é’®\n",
    "                process_btn = gr.Button(\"ğŸš€ å¼€å§‹è¯†åˆ«\", variant=\"primary\", size=\"lg\")\n",
    "                \n",
    "            with gr.Column():\n",
    "                # ç»“æœæ˜¾ç¤º\n",
    "                result_text = gr.Textbox(\n",
    "                    label=\"ğŸ“Š è¯†åˆ«ç»“æœ\",\n",
    "                    lines=15,\n",
    "                    max_lines=20,\n",
    "                    placeholder=\"è¯†åˆ«ç»“æœå°†åœ¨è¿™é‡Œæ˜¾ç¤º...\",\n",
    "                    show_copy_button=True\n",
    "                )\n",
    "                \n",
    "                # CSVä¸‹è½½\n",
    "                csv_download = gr.File(\n",
    "                    label=\"ğŸ’¾ ä¸‹è½½CSVç»“æœ\",\n",
    "                    visible=False\n",
    "                )\n",
    "        \n",
    "        # ç¤ºä¾‹å›¾ç‰‡å±•ç¤º\n",
    "        gr.Markdown(\"### ğŸ“‹ ä½¿ç”¨ç¤ºä¾‹\")\n",
    "        with gr.Row():\n",
    "            # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "            example_path = \"assets/sample_docs/sample_medical_document.png\"\n",
    "            if os.path.exists(example_path):\n",
    "                gr.Examples(\n",
    "                    examples=[[example_path]],\n",
    "                    inputs=image_input,\n",
    "                    label=\"ç‚¹å‡»åŠ è½½ç¤ºä¾‹åŒ»ç–—æ–‡æ¡£\"\n",
    "                )\n",
    "            else:\n",
    "                gr.Markdown(\"âš ï¸ ç¤ºä¾‹æ–‡æ¡£æœªæ‰¾åˆ°ï¼Œè¯·ç›´æ¥ä¸Šä¼ æ‚¨çš„åŒ»ç–—æ–‡æ¡£å›¾åƒ\")\n",
    "        \n",
    "        # ä½¿ç”¨è¯´æ˜\n",
    "        gr.Markdown(\"\"\"\n",
    "        ### ğŸ’¡ ä½¿ç”¨è¯´æ˜\n",
    "        1. **ä¸Šä¼ å›¾åƒ**: ç‚¹å‡»ä¸Šæ–¹åŒºåŸŸä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\n",
    "        2. **å¼€å§‹è¯†åˆ«**: ç‚¹å‡»\"å¼€å§‹è¯†åˆ«\"æŒ‰é’®è¿›è¡ŒOCRå¤„ç†\n",
    "        3. **æŸ¥çœ‹ç»“æœ**: è¯†åˆ«ç»“æœå°†æ˜¾ç¤ºåœ¨å³ä¾§æ–‡æœ¬æ¡†ä¸­\n",
    "        4. **ä¸‹è½½CSV**: å¤„ç†å®Œæˆåå¯ä¸‹è½½CSVæ ¼å¼çš„ç»“æ„åŒ–ç»“æœ\n",
    "        \n",
    "        ### ğŸ”§ æŠ€æœ¯ç‰¹æ€§\n",
    "        - ğŸ¤– åŸºäºPaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "        - ğŸŒ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«\n",
    "        - ğŸ“Š æä¾›ç½®ä¿¡åº¦è¯„ä¼°\n",
    "        - ğŸ’¾ è‡ªåŠ¨ç”ŸæˆCSVæ ¼å¼ç»“æœ\n",
    "        - ğŸ” æ”¯æŒå¤šç§å›¾åƒæ ¼å¼\n",
    "        \n",
    "        ### âš ï¸ æ³¨æ„äº‹é¡¹\n",
    "        - è¯·ç¡®ä¿å›¾åƒæ¸…æ™°å¯è¯»\n",
    "        - æ–‡å­—ä¸èƒŒæ™¯å¯¹æ¯”åº¦è¦è¶³å¤Ÿ\n",
    "        - å›¾åƒåˆ†è¾¨ç‡å»ºè®®åœ¨ 500x500 åˆ° 2000x2000 åƒç´ ä¹‹é—´\n",
    "        - æ–‡å­—è¯†åˆ«ç»“æœä»…ä¾›å‚è€ƒï¼Œé‡è¦åŒ»ç–—ä¿¡æ¯è¯·äººå·¥æ ¸éªŒ\n",
    "        \n",
    "        ### ğŸ› æ•…éšœæ’é™¤\n",
    "        - å¦‚æœè¯†åˆ«å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ§åˆ¶å°è¾“å‡ºçš„è¯¦ç»†é”™è¯¯ä¿¡æ¯\n",
    "        - å°è¯•ä½¿ç”¨ä¸åŒæ ¼å¼æˆ–æ›´æ¸…æ™°çš„å›¾åƒ\n",
    "        - ç¡®ä¿å›¾åƒä¸­åŒ…å«æ¸…æ™°å¯è¯»çš„æ–‡å­—å†…å®¹\n",
    "        \"\"\")\n",
    "        \n",
    "        # ç»‘å®šå¤„ç†å‡½æ•°\n",
    "        def update_result(image):\n",
    "            \"\"\"æ›´æ–°ç»“æœå¹¶æ§åˆ¶ä¸‹è½½æŒ‰é’®å¯è§æ€§\"\"\"\n",
    "            result_text, csv_path = process_uploaded_image(image)\n",
    "            \n",
    "            if csv_path:\n",
    "                # æœ‰CSVæ–‡ä»¶æ—¶æ˜¾ç¤ºä¸‹è½½ç»„ä»¶\n",
    "                return result_text, gr.File(value=csv_path, visible=True)\n",
    "            else:\n",
    "                # æ— CSVæ–‡ä»¶æ—¶éšè—ä¸‹è½½ç»„ä»¶\n",
    "                return result_text, gr.File(visible=False)\n",
    "        \n",
    "        process_btn.click(\n",
    "            fn=update_result,\n",
    "            inputs=image_input,\n",
    "            outputs=[result_text, csv_download]\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢\n",
    "print(\"ğŸŒ åˆ›å»ºGradio Webç•Œé¢...\")\n",
    "try:\n",
    "    demo_interface = create_gradio_interface()\n",
    "    print(\"âœ… Gradioç•Œé¢åˆ›å»ºæˆåŠŸ!\")\n",
    "    print(\"ğŸ’¡ åœ¨æœ¬åœ°ç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨ demo_interface.launch() å¯åŠ¨WebæœåŠ¡\")\n",
    "    print(\"ğŸ’¡ åœ¨Colabç¯å¢ƒä¸­ï¼Œå¯ä»¥ä½¿ç”¨ demo_interface.launch(share=True) è·å–å…¬å…±é“¾æ¥\")\n",
    "    \n",
    "    # æ ¹æ®ç¯å¢ƒé€‰æ‹©å¯åŠ¨æ–¹å¼\n",
    "    try:\n",
    "        import google.colab  # type: ignore # noqa: F401 # æ£€æµ‹Colabç¯å¢ƒ\n",
    "        print(\"ğŸš€ æ£€æµ‹åˆ°Colabç¯å¢ƒï¼Œå¯åŠ¨å…¬å…±åˆ†äº«é“¾æ¥...\")\n",
    "        demo_interface.launch(share=True, height=800)\n",
    "    except ImportError:\n",
    "        print(\"ğŸ  æœ¬åœ°ç¯å¢ƒæ£€æµ‹æˆåŠŸ\")\n",
    "        print(\"ğŸ“ å¦‚éœ€å¯åŠ¨Webç•Œé¢ï¼Œè¯·è¿è¡Œ: demo_interface.launch()\")\n",
    "        # åœ¨æœ¬åœ°ç¯å¢ƒä¸­ä¸è‡ªåŠ¨å¯åŠ¨ï¼Œé¿å…å ç”¨ç«¯å£\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Gradioç•Œé¢åˆ›å»ºå¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·æ£€æŸ¥Gradioæ˜¯å¦æ­£ç¡®å®‰è£…\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# OCRåŠŸèƒ½éªŒè¯æµ‹è¯•\n",
    "# ================================\n",
    "\n",
    "def test_ocr_functionality():\n",
    "    \"\"\"å¿«é€Ÿæµ‹è¯•OCRåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œ\"\"\"\n",
    "    print(\"ğŸ§ª å¼€å§‹OCRåŠŸèƒ½éªŒè¯æµ‹è¯•...\")\n",
    "    \n",
    "    # æ£€æŸ¥OCRå¤„ç†å™¨æ˜¯å¦å¯ç”¨ - ä¿®å¤å…¨å±€å˜é‡æ£€æµ‹å’ŒIDEè­¦å‘Š\n",
    "    try:\n",
    "        # ä½¿ç”¨globals()æ£€æŸ¥å˜é‡å­˜åœ¨ï¼Œé¿å…IDE unboundè­¦å‘Š\n",
    "        if 'ocr_processor' not in globals():\n",
    "            print(\"âŒ å…¨å±€OCRå¤„ç†å™¨å˜é‡æœªå®šä¹‰\")\n",
    "            print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œ'åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»'å•å…ƒæ ¼æ¥åˆå§‹åŒ–OCRå¤„ç†å™¨\")\n",
    "            return False\n",
    "        \n",
    "        processor = globals()['ocr_processor']  # type: ignore # åŠ¨æ€è®¿é—®å…¨å±€å˜é‡\n",
    "        print(\"âœ… æ‰¾åˆ°å…¨å±€OCRå¤„ç†å™¨å˜é‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ è®¿é—®OCRå¤„ç†å™¨æ—¶å‡ºé”™: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # æ£€æŸ¥å¤„ç†å™¨å¯¹è±¡æ˜¯å¦æœ‰æ•ˆ\n",
    "    if processor is None:\n",
    "        print(\"âŒ OCRå¤„ç†å™¨å¯¹è±¡ä¸ºNone\")\n",
    "        print(\"ğŸ’¡ OCRå¤„ç†å™¨åˆå§‹åŒ–å¯èƒ½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯\")\n",
    "        return False\n",
    "    \n",
    "    # æ£€æŸ¥PaddleOCRå¼•æ“\n",
    "    if not hasattr(processor, 'ocr') or processor.ocr is None:\n",
    "        print(\"âŒ PaddleOCRå¼•æ“æœªåˆå§‹åŒ–\")\n",
    "        print(\"ğŸ’¡ PaddleOCRåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·æ£€æŸ¥:\")\n",
    "        print(\"   1. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸\")\n",
    "        print(\"   2. PaddleOCRæ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"   3. æ¨¡å‹æ–‡ä»¶æ˜¯å¦ä¸‹è½½å®Œæˆ\")\n",
    "        return False\n",
    "    \n",
    "    print(\"âœ… OCRå¤„ç†å™¨å’Œå¼•æ“æ£€æŸ¥é€šè¿‡\")\n",
    "    \n",
    "    # æ£€æŸ¥ç¤ºä¾‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    import os\n",
    "    sample_path = \"assets/sample_docs/sample_medical_document.png\"\n",
    "    \n",
    "    if not os.path.exists(sample_path):\n",
    "        print(f\"âš ï¸ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {sample_path}\")\n",
    "        \n",
    "        # å°è¯•åˆ›å»ºç¤ºä¾‹æ–‡ä»¶\n",
    "        try:\n",
    "            print(\"ğŸ¨ å°è¯•åˆ›å»ºç¤ºä¾‹æ–‡æ¡£...\")\n",
    "            # æ£€æŸ¥create_sample_medical_documentå‡½æ•°æ˜¯å¦å­˜åœ¨\n",
    "            if 'create_sample_medical_document' not in globals():\n",
    "                print(\"âŒ create_sample_medical_documentå‡½æ•°æœªå®šä¹‰\")\n",
    "                print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œ'åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£'å•å…ƒæ ¼\")\n",
    "                return False\n",
    "            \n",
    "            create_func = globals()['create_sample_medical_document']  # type: ignore # åŠ¨æ€è®¿é—®å…¨å±€å‡½æ•°\n",
    "            sample_path = create_func()\n",
    "            print(f\"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»º: {sample_path}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå¤±è´¥: {e}\")\n",
    "            return False\n",
    "    else:\n",
    "        print(f\"âœ… æ‰¾åˆ°ç¤ºä¾‹æ–‡ä»¶: {sample_path}\")\n",
    "    \n",
    "    # æµ‹è¯•OCRå¤„ç†\n",
    "    try:\n",
    "        print(f\"ğŸ” æµ‹è¯•OCRå¤„ç†: {sample_path}\")\n",
    "        results = processor.process_single_image(sample_path)\n",
    "        \n",
    "        print(f\"ğŸ“Š OCRå¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœç±»å‹: {type(results)}\")\n",
    "        print(f\"ğŸ“Š ç»“æœæ•°é‡: {len(results) if results else 0}\")\n",
    "        \n",
    "        if results and len(results) > 0:\n",
    "            print(f\"âœ… OCRæµ‹è¯•æˆåŠŸï¼è¯†åˆ«åˆ° {len(results)} è¡Œæ–‡å­—\")\n",
    "            print(\"ğŸ“ å‰3è¡Œè¯†åˆ«ç»“æœ:\")\n",
    "            for i, result in enumerate(results[:3]):\n",
    "                print(f\"   {i+1}. {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"âŒ OCRæµ‹è¯•å¤±è´¥ï¼šæœªè¯†åˆ«åˆ°æ–‡å­—\")\n",
    "            print(\"ğŸ” å¯èƒ½åŸå› ï¼š\")\n",
    "            print(\"   1. PaddleOCRç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜\")\n",
    "            print(\"   2. æ¨¡å‹æ–‡ä»¶ä¸‹è½½ä¸å®Œæ•´\")\n",
    "            print(\"   3. ç¤ºä¾‹å›¾åƒè´¨é‡é—®é¢˜\")\n",
    "            print(\"   4. APIè°ƒç”¨å‚æ•°ä¸å…¼å®¹\")\n",
    "            \n",
    "            # å°è¯•ç›´æ¥è°ƒç”¨PaddleOCR\n",
    "            print(\"\\\\nğŸ”§ å°è¯•ç›´æ¥è°ƒç”¨PaddleOCRå¼•æ“...\")\n",
    "            try:\n",
    "                direct_result = processor.ocr.predict(sample_path)\n",
    "                print(f\"ğŸ” ç›´æ¥è°ƒç”¨ç»“æœç±»å‹: {type(direct_result)}\")\n",
    "                print(f\"ğŸ” ç›´æ¥è°ƒç”¨ç»“æœé•¿åº¦: {len(direct_result) if direct_result else 0}\")\n",
    "                \n",
    "                if direct_result:\n",
    "                    print(\"âœ… PaddleOCRå¼•æ“æœ¬èº«å·¥ä½œæ­£å¸¸\")\n",
    "                    print(\"ğŸ’¡ é—®é¢˜å¯èƒ½åœ¨ç»“æœè§£æé€»è¾‘ä¸­\")\n",
    "                else:\n",
    "                    print(\"âŒ PaddleOCRå¼•æ“è°ƒç”¨ä¹Ÿå¤±è´¥\")\n",
    "                    \n",
    "            except Exception as direct_e:\n",
    "                print(f\"âŒ ç›´æ¥è°ƒç”¨PaddleOCRå¤±è´¥: {direct_e}\")\n",
    "            \n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ OCRæµ‹è¯•å¼‚å¸¸: {e}\")\n",
    "        import traceback\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "# è¿è¡ŒOCRåŠŸèƒ½éªŒè¯\n",
    "print(\"ğŸš€ è¿è¡ŒOCRåŠŸèƒ½éªŒè¯æµ‹è¯•...\")\n",
    "ocr_test_result = test_ocr_functionality()\n",
    "\n",
    "if ocr_test_result:\n",
    "    print(\"\\\\nğŸ‰ OCRåŠŸèƒ½éªŒè¯æˆåŠŸï¼Gradioç•Œé¢åº”è¯¥èƒ½æ­£å¸¸å·¥ä½œ\")\n",
    "    print(\"ğŸ’¡ ç°åœ¨å¯ä»¥å®‰å…¨ä½¿ç”¨Gradioç•Œé¢è¿›è¡Œå›¾åƒä¸Šä¼ å’Œè¯†åˆ«\")\n",
    "else:\n",
    "    print(\"\\\\nâš ï¸ OCRåŠŸèƒ½éªŒè¯å¤±è´¥ï¼éœ€è¦æ£€æŸ¥PaddleOCRé…ç½®\")\n",
    "    print(\"ğŸ’¡ å»ºè®®æŒ‰é¡ºåºæ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š\")\n",
    "    print(\"   1. ç¡®è®¤å·²è¿è¡Œ'åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»'å•å…ƒæ ¼\")\n",
    "    print(\"   2. ç¡®è®¤å·²è¿è¡Œ'åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£'å•å…ƒæ ¼\")\n",
    "    print(\"   3. æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œæ¨¡å‹ä¸‹è½½çŠ¶æ€\")\n",
    "    print(\"   4. å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·é‡å¯è¿è¡Œæ—¶ç¯å¢ƒ\")\n",
    "\n",
    "# æ˜¾ç¤ºå½“å‰å¯ç”¨çš„å…³é”®å…¨å±€å˜é‡\n",
    "print(\"\\\\nğŸ” å½“å‰å¯ç”¨çš„å…³é”®å…¨å±€å˜é‡:\")\n",
    "available_vars = []\n",
    "\n",
    "# å®‰å…¨æ£€æŸ¥å„ä¸ªå…³é”®å˜é‡çš„å­˜åœ¨æ€§\n",
    "key_variables = {\n",
    "    'ocr_processor': 'åŒ»ç–—OCRå¤„ç†å™¨',\n",
    "    'create_sample_medical_document': 'ç¤ºä¾‹æ–‡æ¡£åˆ›å»ºå‡½æ•°', \n",
    "    'demo_interface': 'Gradio Webç•Œé¢å¯¹è±¡'\n",
    "}\n",
    "\n",
    "for var_name, description in key_variables.items():\n",
    "    try:\n",
    "        if var_name in globals():\n",
    "            var_value = globals()[var_name]\n",
    "            if var_value is not None:\n",
    "                available_vars.append(f\"âœ… {var_name} ({description})\")\n",
    "            else:\n",
    "                available_vars.append(f\"âŒ {var_name} (å·²å®šä¹‰ä½†å€¼ä¸ºNone)\")\n",
    "        else:\n",
    "            available_vars.append(f\"âŒ {var_name} (æœªå®šä¹‰)\")\n",
    "    except Exception as e:\n",
    "        available_vars.append(f\"âŒ {var_name} (è®¿é—®é”™è¯¯: {e})\")\n",
    "\n",
    "for var_info in available_vars:\n",
    "    print(f\"   {var_info}\")\n",
    "\n",
    "# å¦‚æœdemo_interfaceæœªå®šä¹‰ï¼Œç»™å‡ºåˆ›å»ºæç¤º\n",
    "if 'demo_interface' not in globals() or globals()['demo_interface'] is None:\n",
    "    print(\"\\\\nğŸ’¡ Gradioç•Œé¢åˆ›å»ºæç¤º:\")\n",
    "    print(\"   å¦‚éœ€åˆ›å»ºWebç•Œé¢ï¼Œè¯·è¿è¡Œ'Gradio Webäº¤äº’ç•Œé¢'å•å…ƒæ ¼\")\n",
    "    print(\"   è¯¥å•å…ƒæ ¼ä¼šåˆ›å»ºdemo_interfaceå˜é‡å¹¶åˆå§‹åŒ–Webç•Œé¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# é¡¹ç›®æ€»ç»“å’Œä½¿ç”¨æŒ‡å—\n",
    "# ================================\n",
    "\n",
    "def show_project_summary():\n",
    "    \"\"\"æ˜¾ç¤ºé¡¹ç›®æ€»ç»“å’Œä½¿ç”¨æŒ‡å—\"\"\"\n",
    "    \n",
    "    summary = \"\"\" # type: ignore\n",
    "ğŸ‰ åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«æ¼”ç¤ºé¡¹ç›®è¿è¡Œå®Œæˆ!\n",
    "\n",
    "ğŸ“‹ é¡¹ç›®åŠŸèƒ½æ€»ç»“:\n",
    "âœ… åŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«\n",
    "âœ… ä¸­è‹±æ–‡æ··åˆæ–‡å­—è¯†åˆ«\n",
    "âœ… æ‰¹é‡å›¾åƒå¤„ç†æ”¯æŒ\n",
    "âœ… CSVæ ¼å¼ç»“æœå¯¼å‡º\n",
    "âœ… ç½®ä¿¡åº¦è¯„ä¼°\n",
    "âœ… ç”¨æˆ·å‹å¥½çš„äº¤äº’ç•Œé¢\n",
    "\n",
    "ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§:\n",
    "â€¢ åŸºäºPaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "â€¢ æ”¯æŒGPUåŠ é€Ÿå¤„ç†\n",
    "â€¢ è‡ªåŠ¨è§’åº¦æ£€æµ‹å’ŒçŸ«æ­£\n",
    "â€¢ ç»“æ„åŒ–æ•°æ®è¾“å‡º\n",
    "\n",
    "ğŸ“– ä½¿ç”¨åœºæ™¯:\n",
    "â€¢ åŒ»ç–—å¤„æ–¹è¯†åˆ«\n",
    "â€¢ ç—…å†æ–‡æ¡£æ•°å­—åŒ–\n",
    "â€¢ æ£€æŸ¥æŠ¥å‘Šæå–\n",
    "â€¢ åŒ»ç–—æ¡£æ¡ˆç®¡ç†\n",
    "\n",
    "ğŸ”— é¡¹ç›®åœ°å€:\n",
    "GitHub: https://github.com/zhurong2020/mcr\n",
    "Colab: å½“å‰notebooké“¾æ¥\n",
    "\n",
    "ğŸ‘¨â€âš•ï¸ é€‚ç”¨ç”¨æˆ·:\n",
    "â€¢ åŒ»ç–—å·¥ä½œè€…\n",
    "â€¢ æ•°æ®åˆ†æå¸ˆ\n",
    "â€¢ ç ”ç©¶äººå‘˜\n",
    "â€¢ å¼€å‘è€…\n",
    "\n",
    "âš ï¸ ä½¿ç”¨è¯´æ˜:\n",
    "1. ç¡®ä¿å›¾åƒæ¸…æ™°å¯è¯»\n",
    "2. æ”¯æŒPNGã€JPGç­‰å¸¸è§æ ¼å¼\n",
    "3. æ‰¹é‡å¤„ç†æ—¶æ³¨æ„æ–‡ä»¶å¤§å°\n",
    "4. ç»“æœä»…ä¾›å‚è€ƒï¼Œé‡è¦ä¿¡æ¯è¯·äººå·¥æ ¸éªŒ\n",
    "\n",
    "ğŸ’¡ æŠ€æœ¯æ”¯æŒ:\n",
    "å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆäº¤æµï¼\n",
    "    \"\"\"\n",
    "    \n",
    "    print(summary)\n",
    "\n",
    "# æ˜¾ç¤ºé¡¹ç›®æ€»ç»“\n",
    "show_project_summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "medical-ocr-demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
