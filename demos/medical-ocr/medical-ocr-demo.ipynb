{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# åŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«æ¼”ç¤º\n",
    "\n",
    "> ğŸ¥ ä½¿ç”¨PaddleOCRä»åŒ»ç–—æ–‡æ¡£PNGå›¾åƒä¸­æå–æ–‡æœ¬å¹¶ä¿å­˜ä¸ºCSV\n",
    "\n",
    "**ç‰ˆæœ¬**: v1.3.6 (ä¿®å¤IDE Pylanceç±»å‹æ£€æŸ¥è­¦å‘Šå’Œä»£ç è´¨é‡é—®é¢˜) | **æ›´æ–°æ—¶é—´**: 2025-08-24\n",
    "\n",
    "## ğŸ¯ åŠŸèƒ½ç‰¹æ€§\n",
    "- ğŸ“„ æ”¯æŒåŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«\n",
    "- ğŸ¤– ä½¿ç”¨PaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "- ğŸ“Š è‡ªåŠ¨ç”Ÿæˆç»“æ„åŒ–CSVæŠ¥å‘Š\n",
    "- ğŸ–¼ï¸ æ”¯æŒå¤šç§å›¾åƒæ ¼å¼è¾“å…¥\n",
    "- ğŸ’¡ ç®€å•æ˜“ç”¨çš„äº¤äº’ç•Œé¢\n",
    "- ğŸ  å®Œæ•´æœ¬åœ°å¼€å‘ç¯å¢ƒæ”¯æŒ\n",
    "- ğŸŒ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«\n",
    "- ğŸ—ï¸ ç‹¬ç«‹åº”ç”¨æ¶æ„ï¼Œå¯ç›´æ¥åœ¨Colabè¿è¡Œ\n",
    "\n",
    "## ğŸš€ ä½¿ç”¨è¯´æ˜\n",
    "\n",
    "### Colabç¯å¢ƒ\n",
    "1. è¿è¡Œç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "2. ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\n",
    "3. æ‰§è¡ŒOCRæ–‡å­—è¯†åˆ«\n",
    "4. ä¸‹è½½CSVç»“æœæ–‡ä»¶\n",
    "\n",
    "### æœ¬åœ°ç¯å¢ƒ\n",
    "```bash\n",
    "# ä»é¡¹ç›®æ ¹ç›®å½•ä¸€é”®å¯åŠ¨\n",
    "../start_local.sh\n",
    "\n",
    "# æ‰‹åŠ¨å¯åŠ¨\n",
    "source ../venv/bin/activate && jupyter notebook\n",
    "```\n",
    "\n",
    "### ç›®å½•ç»“æ„\n",
    "```\n",
    "medical-ocr/\n",
    "â”œâ”€â”€ medical-ocr-demo.ipynb    # æœ¬æ¼”ç¤ºæ–‡ä»¶\n",
    "â”œâ”€â”€ gradio_demo.py           # Webç•Œé¢ç‰ˆæœ¬\n",
    "â”œâ”€â”€ test_chinese_encoding_fix.py  # ä¸­æ–‡ç¼–ç æµ‹è¯•\n",
    "â””â”€â”€ assets/                  # èµ„æºæ–‡ä»¶\n",
    "    â”œâ”€â”€ sample_docs/         # ç¤ºä¾‹æ–‡æ¡£\n",
    "    â””â”€â”€ results/            # OCRç»“æœ\n",
    "```\n",
    "\n",
    "---\n",
    "*ä½¿ç”¨ Claude Code å¼€å‘ï¼Œæ”¯æŒ Google Colab å’Œæœ¬åœ°è¿è¡Œ ğŸš€*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# ç¯å¢ƒæ£€æŸ¥å’ŒåŸºç¡€è®¾ç½®\n",
    "# ================================\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def check_environment():\n",
    "    \"\"\"æ£€æŸ¥è¿è¡Œç¯å¢ƒå¹¶æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯\"\"\"\n",
    "    print(\"ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...\")\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦åœ¨Colabç¯å¢ƒ\n",
    "    try:\n",
    "        import google.colab # type: ignore # noqa: F401 # éœ€è¦ç”¨äºç¯å¢ƒæ£€æµ‹\n",
    "        print(\"âœ… è¿è¡Œåœ¨Google Colab\")\n",
    "        in_colab = True\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ è¿è¡Œåœ¨æœ¬åœ°ç¯å¢ƒ\")\n",
    "        in_colab = False\n",
    "    \n",
    "    # æ£€æŸ¥GPU\n",
    "    try:\n",
    "        import torch\n",
    "        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "        print(f\"âœ… è®¡ç®—è®¾å¤‡: {device}\")\n",
    "        if device == 'cuda':\n",
    "            print(f\"âœ… GPUå‹å·: {torch.cuda.get_device_name(0)}\")\n",
    "            print(f\"âœ… GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "    except ImportError:\n",
    "        print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "    \n",
    "    return in_colab\n",
    "\n",
    "# è¿è¡Œç¯å¢ƒæ£€æŸ¥\n",
    "in_colab = check_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…\n",
    "# ================================\n",
    "\n",
    "def install_dependencies():\n",
    "    \"\"\"å®‰è£…é¡¹ç›®æ‰€éœ€çš„ä¾èµ–åŒ…\"\"\"\n",
    "    print(\"ğŸ“¦ å®‰è£…åŒ»ç–—OCRé¡¹ç›®ä¾èµ–...\")\n",
    "    \n",
    "    import subprocess\n",
    "    import sys\n",
    "    \n",
    "    # æ ¸å¿ƒä¾èµ–åŒ…åˆ—è¡¨\n",
    "    packages = [\n",
    "        'paddlepaddle',\n",
    "        'paddleocr',\n",
    "        'pandas',\n",
    "        'pillow',\n",
    "        'opencv-python',\n",
    "        'tqdm',\n",
    "        'gradio'\n",
    "    ]\n",
    "    \n",
    "    for package in packages:\n",
    "        try:\n",
    "            if package == 'opencv-python':\n",
    "                import cv2  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯opencvå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            elif package == 'pillow':\n",
    "                from PIL import Image  # type: ignore # noqa: F401 # ç”¨äºéªŒè¯PILå®‰è£…\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "            else:\n",
    "                __import__(package.replace('-', '_'))\n",
    "                print(f\"âœ… {package} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"ğŸ“¥ å®‰è£… {package}...\")\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])\n",
    "    \n",
    "    print(\"âœ… æ‰€æœ‰ä¾èµ–å®‰è£…å®Œæˆ!\")\n",
    "\n",
    "# å®‰è£…ä¾èµ–\n",
    "install_dependencies()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "# ================================\n",
    "\n",
    "try:\n",
    "    import pandas as pd  # type: ignore\n",
    "    from PIL import Image\n",
    "    from tqdm import tqdm\n",
    "    from paddleocr import PaddleOCR  # type: ignore\n",
    "    import gradio as gr  # type: ignore\n",
    "    print(\"ğŸ“š æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ!\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åº“å¯¼å…¥å¤±è´¥: {e}\")\n",
    "    print(\"ğŸ’¡ è¯·å…ˆè¿è¡Œä¾èµ–å®‰è£…å•å…ƒæ ¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åŒ»ç–—OCRæ ¸å¿ƒåŠŸèƒ½ç±»\n",
    "# ================================\n",
    "\n",
    "class MedicalOCRProcessor:\n",
    "    def __init__(self):\n",
    "        \"\"\"åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨\"\"\"\n",
    "        print(\"ğŸ¥ åˆå§‹åŒ–åŒ»ç–—OCRå¤„ç†å™¨...\")\n",
    "        \n",
    "        # æ£€æŸ¥GPUå¯ç”¨æ€§\n",
    "        try:\n",
    "            import torch\n",
    "            use_gpu = torch.cuda.is_available()\n",
    "            gpu_info = f\"GPUå¯ç”¨: {use_gpu}\"\n",
    "            if use_gpu:\n",
    "                gpu_info += f\" (è®¾å¤‡: {torch.cuda.get_device_name(0)})\"\n",
    "            print(f\"âš¡ {gpu_info}\")\n",
    "        except ImportError:\n",
    "            use_gpu = False\n",
    "            print(\"â„¹ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPUæ¨¡å¼\")\n",
    "        \n",
    "        # åˆå§‹åŒ–PaddleOCRï¼Œæ”¯æŒä¸­è‹±æ–‡\n",
    "        # æ–°ç‰ˆPaddleOCRä¼šè‡ªåŠ¨æ£€æµ‹å¹¶ä½¿ç”¨GPUï¼ˆå¦‚æœå¯ç”¨ï¼‰\n",
    "        self.ocr = PaddleOCR(use_angle_cls=True, lang='ch')\n",
    "        \n",
    "        print(\"âœ… OCRå¼•æ“åˆå§‹åŒ–å®Œæˆ\")\n",
    "    \n",
    "    def extract_text_from_image(self, image_path):\n",
    "        \"\"\"ä»å›¾åƒä¸­æå–æ–‡å­—\"\"\"\n",
    "        try:\n",
    "            # ä½¿ç”¨PaddleOCRè¯†åˆ«æ–‡å­—ï¼ˆä½¿ç”¨æ–°ç‰ˆpredict APIï¼‰\n",
    "            result = self.ocr.predict(image_path)\n",
    "            \n",
    "            # æå–æ–‡å­—å†…å®¹\n",
    "            extracted_texts = []\n",
    "            \n",
    "            # æ–°ç‰ˆPaddleOCRè¿”å›OCRResultå¯¹è±¡\n",
    "            if result and isinstance(result, list) and len(result) > 0:\n",
    "                # è·å–ç¬¬ä¸€ä¸ªç»“æœï¼ˆé€šå¸¸æ˜¯é¡µé¢ç»“æœï¼‰\n",
    "                page_result = result[0]\n",
    "                \n",
    "                # æ£€æŸ¥æ˜¯å¦ä¸ºæ–°ç‰ˆAPIçš„å­—å…¸æ ¼å¼ï¼ˆæ­£ç¡®çš„è®¿é—®æ–¹å¼ï¼‰\n",
    "                if isinstance(page_result, dict) and 'rec_texts' in page_result and 'rec_scores' in page_result:\n",
    "                    # æ–°ç‰ˆAPIæ ¼å¼ï¼šå­—å…¸è®¿é—®\n",
    "                    texts = page_result['rec_texts']\n",
    "                    scores = page_result['rec_scores']\n",
    "                    \n",
    "                    for text, score in zip(texts, scores):\n",
    "                        if text and text.strip():\n",
    "                            extracted_texts.append({\n",
    "                                'text': text.strip(),\n",
    "                                'confidence': score\n",
    "                            })\n",
    "                elif hasattr(page_result, 'rec_texts') and hasattr(page_result, 'rec_scores'):\n",
    "                    # å¤‡ç”¨ï¼šå±æ€§è®¿é—®\n",
    "                    texts = page_result.rec_texts # type: ignore\n",
    "                    scores = page_result.rec_scores  # type: ignore\n",
    "                    \n",
    "                    for text, score in zip(texts, scores):\n",
    "                        if text and text.strip():\n",
    "                            extracted_texts.append({\n",
    "                                'text': text.strip(),\n",
    "                                'confidence': score\n",
    "                            })\n",
    "                elif page_result is not None and hasattr(page_result, '__iter__'):\n",
    "                    # æ—§ç‰ˆAPIæ ¼å¼ï¼šå…¼å®¹å¤„ç†\n",
    "                    try:\n",
    "                        for line in page_result:\n",
    "                            if (line and len(line) >= 2 and \n",
    "                                line[1] and len(line[1]) >= 2 and \n",
    "                                isinstance(line[1][0], str)):\n",
    "                                \n",
    "                                text = line[1][0]\n",
    "                                confidence = line[1][1]\n",
    "                                \n",
    "                                if text and text.strip():\n",
    "                                    extracted_texts.append({\n",
    "                                        'text': text.strip(),\n",
    "                                        'confidence': confidence\n",
    "                                    })\n",
    "                    except (TypeError, IndexError):\n",
    "                        pass  # ä¸å…¼å®¹çš„æ ¼å¼ï¼Œè·³è¿‡\n",
    "            \n",
    "            if not extracted_texts:\n",
    "                print(\"âš ï¸ æœªæ£€æµ‹åˆ°ä»»ä½•æ–‡å­—å†…å®¹\")\n",
    "                # è°ƒè¯•ä¿¡æ¯\n",
    "                print(f\"ğŸ” è°ƒè¯•ä¿¡æ¯: resultç±»å‹={type(result)}, é•¿åº¦={len(result) if result else 0}\")\n",
    "                if result and len(result) > 0:\n",
    "                    print(f\"ğŸ” ç¬¬ä¸€é¡µç»“æœç±»å‹: {type(result[0])}\")\n",
    "                    if isinstance(result[0], dict):\n",
    "                        print(f\"ğŸ” å­—å…¸é”®: {list(result[0].keys())}\")\n",
    "                    elif hasattr(result[0], '__dict__'):\n",
    "                        print(f\"ğŸ” å¯¹è±¡å±æ€§: {list(vars(result[0]).keys())}\")\n",
    "            else:\n",
    "                print(f\"âœ… æˆåŠŸè¯†åˆ« {len(extracted_texts)} è¡Œæ–‡å­—\")\n",
    "            \n",
    "            return extracted_texts\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}\")\n",
    "            import traceback\n",
    "            print(f\"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "            return []\n",
    "    \n",
    "    def process_single_image(self, image_path):\n",
    "        \"\"\"å¤„ç†å•ä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        import os\n",
    "        print(f\"ğŸ“„ å¤„ç†å›¾åƒ: {os.path.basename(image_path)}\")\n",
    "        \n",
    "        # æå–æ–‡å­—\n",
    "        extracted_texts = self.extract_text_from_image(image_path)\n",
    "        \n",
    "        # æ•´ç†ç»“æœ\n",
    "        results = []\n",
    "        for i, item in enumerate(extracted_texts):\n",
    "            results.append({\n",
    "                'file_name': os.path.basename(image_path),\n",
    "                'line_number': i + 1,\n",
    "                'extracted_text': item['text'],\n",
    "                'confidence': round(item['confidence'], 4)\n",
    "            })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def process_multiple_images(self, image_paths):\n",
    "        \"\"\"æ‰¹é‡å¤„ç†å¤šä¸ªå›¾åƒæ–‡ä»¶\"\"\"\n",
    "        all_results = []\n",
    "        \n",
    "        print(f\"ğŸ“Š å¼€å§‹æ‰¹é‡å¤„ç† {len(image_paths)} ä¸ªå›¾åƒæ–‡ä»¶...\")\n",
    "        \n",
    "        for image_path in tqdm(image_paths, desc=\"å¤„ç†è¿›åº¦\"):\n",
    "            results = self.process_single_image(image_path)\n",
    "            all_results.extend(results)\n",
    "        \n",
    "        return all_results\n",
    "    \n",
    "    def save_results_to_csv(self, results, output_path):\n",
    "        \"\"\"ä¿å­˜ç»“æœåˆ°CSVæ–‡ä»¶\"\"\"\n",
    "        if not results:\n",
    "            # å¦‚æœæ²¡æœ‰ç»“æœï¼Œåˆ›å»ºç©ºçš„DataFrame\n",
    "            df = pd.DataFrame(columns=['file_name', 'line_number', 'extracted_text', 'confidence'])\n",
    "        else:\n",
    "            df = pd.DataFrame(results)\n",
    "        \n",
    "        df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        print(f\"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_path}\")\n",
    "        return df\n",
    "\n",
    "# åˆå§‹åŒ–OCRå¤„ç†å™¨\n",
    "ocr_processor = MedicalOCRProcessor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£ï¼ˆç”¨äºæ¼”ç¤ºï¼‰- ä¿®å¤å­—ä½“å’Œä¸­æ–‡æ˜¾ç¤ºé—®é¢˜\n",
    "# ================================\n",
    "\n",
    "def create_sample_medical_document():\n",
    "    \"\"\"åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£å›¾åƒç”¨äºæ¼”ç¤º\"\"\"\n",
    "    from PIL import Image, ImageDraw, ImageFont\n",
    "    import os\n",
    "    \n",
    "    # åˆ›å»ºç¤ºä¾‹å›¾åƒ - ä½¿ç”¨æ›´å¤§å°ºå¯¸å’Œæ›´å¥½å¯¹æ¯”åº¦\n",
    "    img = Image.new('RGB', (1000, 800), color='white')\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    \n",
    "    # æ·»åŠ è¾¹æ¡†å¢åŠ æ–‡æ¡£æ„Ÿ\n",
    "    draw.rectangle([(20, 20), (980, 780)], outline='black', width=2)\n",
    "    \n",
    "    # ä½¿ç”¨ä¸­æ–‡åŒ»ç–—å†…å®¹è¿›è¡Œè¯†åˆ«æµ‹è¯•\n",
    "    sample_text = [\n",
    "        \"åŒ»ç–—è¯Šæ–­æŠ¥å‘Š\",\n",
    "        \"åŒ»é™¢åç§°ï¼šXXå¸‚äººæ°‘åŒ»é™¢\",\n",
    "        \"æ‚£è€…å§“åï¼šå¼ ä¸‰\",\n",
    "        \"æ€§åˆ«ï¼šç”·    å¹´é¾„ï¼š45å²\",\n",
    "        \"ç§‘å®¤ï¼šå¿ƒè¡€ç®¡å†…ç§‘\",\n",
    "        \"ä¸»æ²»åŒ»å¸ˆï¼šæåŒ»ç”Ÿ\",\n",
    "        \"è¯Šæ–­ï¼šé«˜è¡€å‹ã€ç³–å°¿ç—…\",\n",
    "        \"å¤„æ–¹ï¼š\",\n",
    "        \"1. é™å‹è¯ 10mg æ¯æ—¥ä¸€æ¬¡\",\n",
    "        \"2. é™ç³–è¯ 5mg æ¯æ—¥ä¸¤æ¬¡\",\n",
    "        \"åŒ»ç”Ÿç­¾åï¼šæåŒ»ç”Ÿ\",\n",
    "        \"æ—¥æœŸï¼š2025-08-24\"\n",
    "    ]\n",
    "    \n",
    "    # è·å–ä¸­æ–‡å­—ä½“ - ä¼˜å…ˆæŸ¥æ‰¾ç³»ç»Ÿä¸­çš„ä¸­æ–‡å­—ä½“\n",
    "    font = None\n",
    "    title_font = None\n",
    "    font_size = 28  # é€‚ä¸­çš„å­—ä½“å¤§å°\n",
    "    title_font_size = 36\n",
    "    \n",
    "    # ä¸­æ–‡å­—ä½“è·¯å¾„åˆ—è¡¨ï¼ˆæŒ‰ä¼˜å…ˆçº§æ’åºï¼‰\n",
    "    chinese_font_paths = [\n",
    "        # ç”¨æˆ·å­—ä½“ç›®å½•ä¸­çš„ä¸­æ–‡å­—ä½“\n",
    "        '/home/wuxia/.fonts/simhei.ttf',  # é»‘ä½“\n",
    "        '/home/wuxia/.fonts/simsun.ttf',  # å®‹ä½“\n",
    "        '/home/wuxia/.fonts/simsun.ttc',  # å®‹ä½“TTCæ ¼å¼\n",
    "        '/home/wuxia/.fonts/simkai.ttf',  # æ¥·ä½“\n",
    "        # ç³»ç»Ÿå¯èƒ½å®‰è£…çš„ä¸­æ–‡å­—ä½“\n",
    "        '/usr/share/fonts/truetype/wqy/wqy-zenhei.ttc',  # æ–‡æ³‰é©¿æ­£é»‘\n",
    "        '/usr/share/fonts/truetype/wqy/wqy-microhei.ttc',  # æ–‡æ³‰é©¿å¾®ç±³é»‘\n",
    "        '/usr/share/fonts/truetype/droid/DroidSansFallbackFull.ttf',  # Droidå­—ä½“\n",
    "        '/usr/share/fonts/opentype/noto/NotoSansCJK-Regular.ttc',  # Noto CJK\n",
    "        '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',  # Liberation (æ”¯æŒéƒ¨åˆ†ä¸­æ–‡)\n",
    "        '/System/Library/Fonts/PingFang.ttc',  # macOSè‹¹æœè‹¹æ–¹\n",
    "        'C:\\\\\\\\Windows\\\\\\\\Fonts\\\\\\\\simhei.ttf',  # Windowsé»‘ä½“\n",
    "        'C:\\\\\\\\Windows\\\\\\\\Fonts\\\\\\\\simsun.ttc',  # Windowså®‹ä½“\n",
    "    ]\n",
    "    \n",
    "    print(\"ğŸ” æœç´¢ä¸­æ–‡å­—ä½“...\")\n",
    "    \n",
    "    # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“\n",
    "    for font_path in chinese_font_paths:\n",
    "        if os.path.exists(font_path):\n",
    "            try:\n",
    "                font = ImageFont.truetype(font_path, font_size)\n",
    "                title_font = ImageFont.truetype(font_path, title_font_size)\n",
    "                print(f\"âœ… æˆåŠŸåŠ è½½ä¸­æ–‡å­—ä½“: {font_path}\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ å­—ä½“åŠ è½½å¤±è´¥: {font_path} - {e}\")\n",
    "                continue\n",
    "    \n",
    "    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°è¯•ç³»ç»Ÿé»˜è®¤å­—ä½“\n",
    "    if font is None:\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°ä¸­æ–‡å­—ä½“ï¼Œå°è¯•ç³»ç»Ÿé»˜è®¤å­—ä½“...\")\n",
    "        \n",
    "        # å°è¯•ä¸€äº›å¯èƒ½æ”¯æŒä¸­æ–‡çš„ç³»ç»Ÿå­—ä½“\n",
    "        fallback_fonts = [\n",
    "            '/usr/share/fonts/truetype/dejavu/DejaVuSans.ttf',\n",
    "            '/usr/share/fonts/truetype/liberation/LiberationSans-Regular.ttf',\n",
    "        ]\n",
    "        \n",
    "        for font_path in fallback_fonts:\n",
    "            if os.path.exists(font_path):\n",
    "                try:\n",
    "                    font = ImageFont.truetype(font_path, font_size)\n",
    "                    title_font = ImageFont.truetype(font_path, title_font_size)\n",
    "                    print(f\"âœ… ä½¿ç”¨å¤‡ç”¨å­—ä½“: {font_path}\")\n",
    "                    print(\"âš ï¸ æ³¨æ„: æ­¤å­—ä½“å¯èƒ½æ— æ³•å®Œå…¨æ”¯æŒä¸­æ–‡æ˜¾ç¤º\")\n",
    "                    break\n",
    "                except Exception:\n",
    "                    continue\n",
    "    \n",
    "    # æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨PILé»˜è®¤å­—ä½“\n",
    "    if font is None:\n",
    "        try:\n",
    "            font = ImageFont.load_default()\n",
    "            title_font = font\n",
    "            print(\"âš ï¸ ä½¿ç”¨PILé»˜è®¤å­—ä½“ - ä¸­æ–‡æ˜¾ç¤ºå¯èƒ½å¼‚å¸¸\")\n",
    "        except Exception as e:\n",
    "            font = None\n",
    "            title_font = None\n",
    "            print(f\"âŒ å­—ä½“åŠ è½½å®Œå…¨å¤±è´¥: {e}\")\n",
    "    \n",
    "    # ç»˜åˆ¶æ–‡æœ¬å†…å®¹\n",
    "    y_position = 60\n",
    "    line_height = 45  # ç¨å¾®ç´§å‡‘ä¸€äº›\n",
    "    \n",
    "    for i, text in enumerate(sample_text):\n",
    "        try:\n",
    "            # ç¬¬ä¸€è¡Œæ ‡é¢˜å±…ä¸­åŠ ç²—\n",
    "            if i == 0:\n",
    "                # è®¡ç®—å±…ä¸­ä½ç½®\n",
    "                if title_font:\n",
    "                    try:\n",
    "                        bbox = draw.textbbox((0, 0), text, font=title_font)\n",
    "                        text_width = bbox[2] - bbox[0]\n",
    "                    except Exception:\n",
    "                        # å¦‚æœtextbboxä¸å¯ç”¨ï¼Œä¼°ç®—å®½åº¦\n",
    "                        text_width = int(len(text) * title_font_size * 0.6)\n",
    "                else:\n",
    "                    text_width = len(text) * 20  # ä¼°ç®—å®½åº¦\n",
    "                \n",
    "                x_position = max(50, (1000 - text_width) // 2)  # ç¡®ä¿ä¸ä¼šå¤ªé å·¦\n",
    "                \n",
    "                # ç»˜åˆ¶æ ‡é¢˜\n",
    "                if title_font:\n",
    "                    draw.text((x_position, y_position), text, fill='black', font=title_font)\n",
    "                else:\n",
    "                    draw.text((x_position, y_position), text, fill='black')\n",
    "                \n",
    "                print(f\"âœ… ç»˜åˆ¶æ ‡é¢˜: {text}\")\n",
    "                \n",
    "                # æ·»åŠ ä¸‹åˆ’çº¿\n",
    "                draw.line([(x_position, y_position + title_font_size + 5), \n",
    "                          (x_position + text_width, y_position + title_font_size + 5)], \n",
    "                         fill='black', width=2)\n",
    "                y_position += 20  # æ ‡é¢˜åé¢å¤–é—´è·\n",
    "                \n",
    "            else:\n",
    "                # æ™®é€šæ–‡æœ¬å·¦å¯¹é½\n",
    "                x_position = 60\n",
    "                if font:\n",
    "                    draw.text((x_position, y_position), text, fill='black', font=font)\n",
    "                else:\n",
    "                    draw.text((x_position, y_position), text, fill='black')\n",
    "                \n",
    "                print(f\"âœ… ç»˜åˆ¶æ–‡æœ¬: {text}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ æ–‡å­—ç»˜åˆ¶å¤±è´¥: {e} - æ–‡æœ¬: {text}\")\n",
    "            # ç®€å•å¤‡ç”¨ç»˜åˆ¶ï¼ˆä¸ä½¿ç”¨å­—ä½“ï¼‰\n",
    "            try:\n",
    "                x_pos = 60 if i > 0 else 300\n",
    "                draw.text((x_pos, y_position), text, fill='black')\n",
    "                print(f\"âœ… å¤‡ç”¨æ–¹å¼ç»˜åˆ¶: {text}\")\n",
    "            except Exception as e2:\n",
    "                print(f\"âŒ å¤‡ç”¨ç»˜åˆ¶ä¹Ÿå¤±è´¥: {e2}\")\n",
    "                # å¦‚æœä¸­æ–‡ç»˜åˆ¶å®Œå…¨å¤±è´¥ï¼Œä½¿ç”¨è‹±æ–‡æ›¿ä»£\n",
    "                english_text = translate_to_english(text)\n",
    "                try:\n",
    "                    x_pos = 60 if i > 0 else 300\n",
    "                    draw.text((x_pos, y_position), english_text, fill='red')\n",
    "                    print(f\"ğŸ”„ ä½¿ç”¨è‹±æ–‡æ›¿ä»£: {english_text}\")\n",
    "                except Exception:\n",
    "                    print(f\"âŒ æ‰€æœ‰ç»˜åˆ¶æ–¹å¼éƒ½å¤±è´¥äº†: {text}\")\n",
    "        \n",
    "        y_position += line_height\n",
    "    \n",
    "    # æ·»åŠ ä¸€äº›è£…é¥°å…ƒç´ å¢åŠ çœŸå®æ„Ÿ\n",
    "    try:\n",
    "        # æ·»åŠ åŒ»é™¢LOGOå ä½ç¬¦\n",
    "        draw.rectangle([(60, 100), (160, 160)], outline='gray', width=1)\n",
    "        draw.text((90, 125), \"LOGO\", fill='gray')\n",
    "        \n",
    "        # æ·»åŠ ç­¾åçº¿\n",
    "        draw.line([(700, 650), (950, 650)], fill='black', width=1)\n",
    "        draw.text((700, 660), \"Signature\", fill='gray')\n",
    "        \n",
    "        # æ·»åŠ æ—¥æœŸæˆ³\n",
    "        draw.rectangle([(800, 700), (950, 750)], outline='blue', width=1)\n",
    "        draw.text((810, 715), \"2025-08-24\", fill='blue')\n",
    "        \n",
    "        print(\"âœ… è£…é¥°å…ƒç´ æ·»åŠ å®Œæˆ\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ è£…é¥°å…ƒç´ æ·»åŠ å¤±è´¥: {e}\")\n",
    "    \n",
    "    # ä¿å­˜ç¤ºä¾‹å›¾åƒåˆ°assetsç›®å½•\n",
    "    os.makedirs('assets/sample_docs', exist_ok=True)\n",
    "    sample_path = 'assets/sample_docs/sample_medical_document.png'\n",
    "    \n",
    "    # ä½¿ç”¨æ›´é«˜çš„è´¨é‡è®¾ç½®ä¿å­˜\n",
    "    img.save(sample_path, 'PNG', optimize=False)\n",
    "    print(f\"ğŸ“„ åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£: {sample_path}\")\n",
    "    \n",
    "    # éªŒè¯æ–‡ä»¶åˆ›å»º\n",
    "    if os.path.exists(sample_path):\n",
    "        file_size = os.path.getsize(sample_path)\n",
    "        print(f\"âœ… æ–‡ä»¶åˆ›å»ºæˆåŠŸï¼Œå¤§å°: {file_size} å­—èŠ‚\")\n",
    "        \n",
    "        # æ˜¾ç¤ºå­—ä½“ä½¿ç”¨æƒ…å†µ\n",
    "        if font:\n",
    "            print(\"ğŸ“ å­—ä½“çŠ¶æ€: å·²åŠ è½½å­—ä½“ï¼Œä¸­æ–‡åº”è¯¥å¯ä»¥æ­£å¸¸æ˜¾ç¤º\")\n",
    "        else:\n",
    "            print(\"âš ï¸ å­—ä½“çŠ¶æ€: æœªåŠ è½½å­—ä½“ï¼Œä¸­æ–‡æ˜¾ç¤ºå¯èƒ½å¼‚å¸¸\")\n",
    "            \n",
    "        # ç»™å‡ºä¸­æ–‡å­—ä½“å®‰è£…å»ºè®®\n",
    "        if font is None:\n",
    "            print(\"\\\\nğŸ’¡ ä¸­æ–‡å­—ä½“å®‰è£…å»ºè®®:\")\n",
    "            print(\"1. Ubuntu/Debian: sudo apt install fonts-wqy-zenhei fonts-wqy-microhei\")\n",
    "            print(\"2. æ‰‹åŠ¨å®‰è£…: ä¸‹è½½SimHei.ttfåˆ° ~/.fonts/ ç›®å½•\")\n",
    "            print(\"3. åœ¨Colabä¸­: !apt install fonts-wqy-zenhei -y\")\n",
    "            \n",
    "    else:\n",
    "        print(\"âŒ æ–‡ä»¶åˆ›å»ºå¤±è´¥\")\n",
    "    \n",
    "    return sample_path\n",
    "\n",
    "def translate_to_english(chinese_text: str) -> str:\n",
    "    \"\"\"å°†ä¸­æ–‡æ–‡æœ¬è½¬æ¢ä¸ºè‹±æ–‡ï¼ˆå¤‡ç”¨æ–¹æ¡ˆï¼‰\"\"\"\n",
    "    translations = {\n",
    "        \"åŒ»ç–—è¯Šæ–­æŠ¥å‘Š\": \"Medical Report\",\n",
    "        \"åŒ»é™¢åç§°ï¼šXXå¸‚äººæ°‘åŒ»é™¢\": \"Hospital: XX City People's Hospital\",\n",
    "        \"æ‚£è€…å§“åï¼šå¼ ä¸‰\": \"Patient: Zhang San\",\n",
    "        \"æ€§åˆ«ï¼šç”·    å¹´é¾„ï¼š45å²\": \"Gender: Male    Age: 45\",\n",
    "        \"ç§‘å®¤ï¼šå¿ƒè¡€ç®¡å†…ç§‘\": \"Dept: Cardiology\",\n",
    "        \"ä¸»æ²»åŒ»å¸ˆï¼šæåŒ»ç”Ÿ\": \"Doctor: Dr. Li\",\n",
    "        \"è¯Šæ–­ï¼šé«˜è¡€å‹ã€ç³–å°¿ç—…\": \"Diagnosis: Hypertension, Diabetes\",\n",
    "        \"å¤„æ–¹ï¼š\": \"Prescription:\",\n",
    "        \"1. é™å‹è¯ 10mg æ¯æ—¥ä¸€æ¬¡\": \"1. Antihypertensive 10mg daily\",\n",
    "        \"2. é™ç³–è¯ 5mg æ¯æ—¥ä¸¤æ¬¡\": \"2. Antidiabetic 5mg twice daily\",\n",
    "        \"åŒ»ç”Ÿç­¾åï¼šæåŒ»ç”Ÿ\": \"Doctor Signature: Dr. Li\",\n",
    "        \"æ—¥æœŸï¼š2025-08-24\": \"Date: 2025-08-24\"\n",
    "    }\n",
    "    return translations.get(chinese_text, chinese_text)\n",
    "\n",
    "def install_chinese_fonts_in_colab() -> bool:\n",
    "    \"\"\"åœ¨Google Colabä¸­å®‰è£…ä¸­æ–‡å­—ä½“\"\"\"\n",
    "    try:\n",
    "        import google.colab  # type: ignore # noqa: F401 # ç”¨äºColabç¯å¢ƒæ£€æµ‹\n",
    "        print(\"ğŸ“¦ æ£€æµ‹åˆ°Colabç¯å¢ƒï¼Œå®‰è£…ä¸­æ–‡å­—ä½“...\")\n",
    "        \n",
    "        import subprocess\n",
    "        # å®‰è£…ä¸­æ–‡å­—ä½“åŒ…\n",
    "        font_packages = [\n",
    "            'fonts-wqy-zenhei',      # æ–‡æ³‰é©¿æ­£é»‘\n",
    "            'fonts-wqy-microhei',    # æ–‡æ³‰é©¿å¾®ç±³é»‘  \n",
    "            'fonts-arphic-ukai',     # AR PL UKai CN\n",
    "            'fonts-arphic-uming'     # AR PL UMing CN\n",
    "        ]\n",
    "        \n",
    "        for package in font_packages:\n",
    "            try:\n",
    "                subprocess.run(['apt', 'install', '-y', package], \n",
    "                             capture_output=True, text=True, check=True)\n",
    "                print(f\"âœ… å®‰è£…å­—ä½“åŒ…: {package}\")\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"âš ï¸ å­—ä½“åŒ…å®‰è£…å¤±è´¥: {package} - {e}\")\n",
    "        \n",
    "        # åˆ·æ–°å­—ä½“ç¼“å­˜\n",
    "        try:\n",
    "            subprocess.run(['fc-cache', '-fv'], check=True)\n",
    "            print(\"âœ… å­—ä½“ç¼“å­˜å·²åˆ·æ–°\")\n",
    "        except Exception:\n",
    "            print(\"âš ï¸ å­—ä½“ç¼“å­˜åˆ·æ–°å¤±è´¥\")\n",
    "            \n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        # ä¸åœ¨Colabç¯å¢ƒä¸­\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Colabå­—ä½“å®‰è£…å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "# å¦‚æœåœ¨Colabç¯å¢ƒä¸­ï¼Œå°è¯•å®‰è£…ä¸­æ–‡å­—ä½“\n",
    "print(\"ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒå¹¶å‡†å¤‡å­—ä½“...\")\n",
    "if install_chinese_fonts_in_colab():\n",
    "    print(\"ğŸ”„ é‡æ–°åŠ è½½å­—ä½“ååˆ›å»ºæ–‡æ¡£...\")\n",
    "\n",
    "# åˆ›å»ºç¤ºä¾‹æ–‡æ¡£\n",
    "print(\"ğŸ¨ åˆ›å»ºç¤ºä¾‹åŒ»ç–—æ–‡æ¡£...\")\n",
    "sample_doc = create_sample_medical_document()\n",
    "\n",
    "# æ˜¾ç¤ºç¤ºä¾‹å›¾åƒ\n",
    "try:\n",
    "    from IPython.display import Image as IPImage, display  # type: ignore # noqa: F401\n",
    "    print(\"ğŸ–¼ï¸ æ˜¾ç¤ºç”Ÿæˆçš„åŒ»ç–—æ–‡æ¡£å›¾åƒ:\")\n",
    "    display(IPImage(sample_doc))\n",
    "except ImportError:\n",
    "    # åœ¨éJupyterç¯å¢ƒä¸­çš„å¤‡ç”¨æ–¹æ¡ˆ\n",
    "    print(f\"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»º: {sample_doc}\")\n",
    "    print(\"ğŸ’¡ åœ¨Jupyter/Colabç¯å¢ƒä¸­ä¼šè‡ªåŠ¨æ˜¾ç¤ºå›¾åƒ\")\n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ å›¾åƒæ˜¾ç¤ºå¤±è´¥: {e}\")\n",
    "    print(f\"âœ… ç¤ºä¾‹æ–‡æ¡£å·²åˆ›å»º: {sample_doc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# æ¼”ç¤ºOCRåŠŸèƒ½\n",
    "# ================================\n",
    "\n",
    "def demo_ocr_functionality():\n",
    "    \"\"\"æ¼”ç¤ºOCRåŠŸèƒ½\"\"\"\n",
    "    print(\"ğŸš€ å¼€å§‹æ¼”ç¤ºåŒ»ç–—OCRåŠŸèƒ½...\")\n",
    "    \n",
    "    # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„å›¾åƒè·¯å¾„\n",
    "    import os\n",
    "    sample_image_path = sample_doc\n",
    "    if not os.path.exists(sample_image_path):\n",
    "        # å°è¯•assetsç›®å½•ä¸­çš„ç¤ºä¾‹æ–‡æ¡£\n",
    "        assets_path = 'assets/sample_docs/sample_medical_document.png'\n",
    "        if os.path.exists(assets_path):\n",
    "            sample_image_path = assets_path\n",
    "        else:\n",
    "            sample_image_path = 'sample_medical_document.png'\n",
    "    \n",
    "    print(f\"ğŸ“„ ä½¿ç”¨å›¾åƒæ–‡ä»¶: {sample_image_path}\")\n",
    "    \n",
    "    # å¤„ç†ç¤ºä¾‹æ–‡æ¡£\n",
    "    results = ocr_processor.process_single_image(sample_image_path)\n",
    "    \n",
    "    # æ˜¾ç¤ºè¯†åˆ«ç»“æœ\n",
    "    print(\"\\nğŸ“Š æ–‡å­—è¯†åˆ«ç»“æœ:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    for result in results:\n",
    "        print(f\"è¡Œ{result['line_number']:2d}: {result['extracted_text']} (ç½®ä¿¡åº¦: {result['confidence']:.3f})\")\n",
    "    \n",
    "    # ä¿å­˜ç»“æœåˆ°CSV (assets/resultsç›®å½•)\n",
    "    os.makedirs('assets/results', exist_ok=True)\n",
    "    csv_path = 'assets/results/ocr_results_demo.csv'\n",
    "    df = ocr_processor.save_results_to_csv(results, csv_path)\n",
    "    \n",
    "    print(f\"\\nğŸ“ˆ å…±è¯†åˆ«å‡º {len(results)} è¡Œæ–‡å­—\")\n",
    "    print(f\"ğŸ“„ ç»“æœå·²ä¿å­˜åˆ° CSV æ–‡ä»¶: {csv_path}\")\n",
    "    \n",
    "    # æ˜¾ç¤ºCSVå†…å®¹é¢„è§ˆ\n",
    "    if len(results) > 0:\n",
    "        print(\"\\nğŸ“‹ CSVæ–‡ä»¶é¢„è§ˆ:\")\n",
    "        print(df.to_string(index=False))\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ æ²¡æœ‰è¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼Œè¯·æ£€æŸ¥å›¾åƒæ–‡ä»¶\")\n",
    "    \n",
    "    return df, csv_path\n",
    "\n",
    "# è¿è¡Œæ¼”ç¤º\n",
    "demo_df, demo_csv = demo_ocr_functionality()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# åˆ›å»ºäº¤äº’å¼ç•Œé¢\n",
    "# ================================\n",
    "\n",
    "def create_gradio_interface():\n",
    "    \"\"\"åˆ›å»ºGradioäº¤äº’ç•Œé¢\"\"\"\n",
    "    \n",
    "    def process_uploaded_image(image):\n",
    "        \"\"\"å¤„ç†ä¸Šä¼ çš„å›¾åƒ\"\"\"\n",
    "        if image is None:\n",
    "            return \"è¯·ä¸Šä¼ å›¾åƒæ–‡ä»¶\", None\n",
    "        \n",
    "        try:\n",
    "            import os\n",
    "            import numpy as np\n",
    "            from PIL import Image as PILImage\n",
    "            \n",
    "            print(\"ğŸ” å¼€å§‹å¤„ç†ä¸Šä¼ çš„å›¾åƒ...\")\n",
    "            \n",
    "            # ç¡®ä¿assetsç›®å½•å­˜åœ¨\n",
    "            os.makedirs('assets/sample_docs', exist_ok=True)\n",
    "            temp_path = \"assets/sample_docs/temp_uploaded_image.png\"\n",
    "            \n",
    "            # å¤„ç†ä¸åŒç±»å‹çš„è¾“å…¥å›¾åƒ\n",
    "            if isinstance(image, np.ndarray):\n",
    "                # Gradioä¸Šä¼ çš„numpyæ•°ç»„æ ¼å¼\n",
    "                print(\"ğŸ“¥ å¤„ç†numpyæ•°ç»„æ ¼å¼å›¾åƒ...\")\n",
    "                \n",
    "                # ç¡®ä¿æ•°ç»„æ˜¯æ­£ç¡®çš„å½¢çŠ¶å’Œæ•°æ®ç±»å‹\n",
    "                if image.dtype != np.uint8:\n",
    "                    image = (image * 255).astype(np.uint8)\n",
    "                \n",
    "                # è½¬æ¢ä¸ºPILå›¾åƒ\n",
    "                if len(image.shape) == 3 and image.shape[2] == 3:\n",
    "                    # RGBæ ¼å¼\n",
    "                    pil_image = PILImage.fromarray(image, mode='RGB')\n",
    "                elif len(image.shape) == 3 and image.shape[2] == 4:\n",
    "                    # RGBAæ ¼å¼ï¼Œè½¬æ¢ä¸ºRGB\n",
    "                    pil_image = PILImage.fromarray(image, mode='RGBA').convert('RGB')\n",
    "                elif len(image.shape) == 2:\n",
    "                    # ç°åº¦å›¾åƒ\n",
    "                    pil_image = PILImage.fromarray(image, mode='L').convert('RGB')\n",
    "                else:\n",
    "                    return f\"âŒ ä¸æ”¯æŒçš„å›¾åƒæ ¼å¼: å½¢çŠ¶{image.shape}\", None\n",
    "                \n",
    "                print(f\"âœ… æˆåŠŸè½¬æ¢å›¾åƒï¼Œå°ºå¯¸: {pil_image.size}\")\n",
    "                \n",
    "            elif isinstance(image, str):\n",
    "                # æ–‡ä»¶è·¯å¾„\n",
    "                print(\"ğŸ“¥ å¤„ç†æ–‡ä»¶è·¯å¾„...\")\n",
    "                pil_image = PILImage.open(image).convert('RGB')\n",
    "                \n",
    "            else:\n",
    "                # å°è¯•ç›´æ¥ä½¿ç”¨PILå¤„ç†\n",
    "                print(\"ğŸ“¥ å¤„ç†å…¶ä»–æ ¼å¼å›¾åƒ...\")\n",
    "                if hasattr(image, 'convert'):\n",
    "                    pil_image = image.convert('RGB')\n",
    "                else:\n",
    "                    return f\"âŒ æ— æ³•å¤„ç†çš„å›¾åƒç±»å‹: {type(image)}\", None\n",
    "            \n",
    "            # ä¿å­˜å¤„ç†åçš„å›¾åƒ\n",
    "            pil_image.save(temp_path, format='PNG', quality=95)\n",
    "            print(f\"ğŸ’¾ å›¾åƒå·²ä¿å­˜åˆ°: {temp_path}\")\n",
    "            \n",
    "            # éªŒè¯ä¿å­˜çš„æ–‡ä»¶\n",
    "            if not os.path.exists(temp_path) or os.path.getsize(temp_path) == 0:\n",
    "                return \"âŒ å›¾åƒä¿å­˜å¤±è´¥\", None\n",
    "            \n",
    "            print(f\"âœ… æ–‡ä»¶éªŒè¯æˆåŠŸï¼Œå¤§å°: {os.path.getsize(temp_path)} å­—èŠ‚\")\n",
    "            \n",
    "            # ä½¿ç”¨OCRå¤„ç†å›¾åƒ\n",
    "            print(\"ğŸ” å¼€å§‹OCRè¯†åˆ«...\")\n",
    "            results = ocr_processor.process_single_image(temp_path)\n",
    "            \n",
    "            if not results:\n",
    "                return \"âš ï¸ æœªè¯†åˆ«åˆ°æ–‡å­—å†…å®¹ï¼Œå¯èƒ½çš„åŸå› ï¼š\\\\n1. å›¾åƒä¸­æ²¡æœ‰æ–‡å­—\\\\n2. å›¾åƒè´¨é‡ä¸ä½³\\\\n3. æ–‡å­—è¿‡å°æˆ–æ¨¡ç³Š\\\\n\\\\nğŸ’¡ å»ºè®®ï¼š\\\\n- ç¡®ä¿å›¾åƒæ¸…æ™°\\\\n- æ–‡å­—å¤§å°é€‚ä¸­\\\\n- å°è¯•å…¶ä»–å›¾åƒ\", None\n",
    "            \n",
    "            # ç”Ÿæˆç»“æœæ–‡æœ¬\n",
    "            result_text = \"ğŸ“Š OCRè¯†åˆ«ç»“æœ:\\\\n\" + \"=\"*50 + \"\\\\n\\\\n\"\n",
    "            for i, result in enumerate(results, 1):\n",
    "                confidence_indicator = \"ğŸŸ¢\" if result['confidence'] > 0.8 else \"ğŸŸ¡\" if result['confidence'] > 0.6 else \"ğŸ”´\"\n",
    "                result_text += f\"{i:2d}. {confidence_indicator} {result['extracted_text']}\\\\n\"\n",
    "                result_text += f\"     (ç½®ä¿¡åº¦: {result['confidence']:.3f})\\\\n\\\\n\"\n",
    "            \n",
    "            # ä¿å­˜CSVæ–‡ä»¶\n",
    "            os.makedirs('assets/results', exist_ok=True)\n",
    "            csv_path = \"assets/results/ocr_results_uploaded.csv\"\n",
    "            ocr_processor.save_results_to_csv(results, csv_path)\n",
    "            \n",
    "            # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯\n",
    "            result_text += f\"\\\\nğŸ“ˆ è¯†åˆ«ç»Ÿè®¡:\\\\n\"\n",
    "            result_text += f\"â€¢ æ€»è®¡è¯†åˆ«æ–‡å­—è¡Œæ•°: {len(results)}\\\\n\"\n",
    "            result_text += f\"â€¢ å¹³å‡ç½®ä¿¡åº¦: {sum(r['confidence'] for r in results)/len(results):.3f}\\\\n\"\n",
    "            result_text += f\"â€¢ é«˜ç½®ä¿¡åº¦(>0.8): {sum(1 for r in results if r['confidence'] > 0.8)}è¡Œ\\\\n\"\n",
    "            result_text += f\"â€¢ CSVç»“æœæ–‡ä»¶: {csv_path}\\\\n\"\n",
    "            result_text += f\"\\\\nğŸ’¾ ç»“æœå·²ä¿å­˜ï¼Œå¯ä¸‹è½½CSVæ–‡ä»¶æŸ¥çœ‹è¯¦ç»†æ•°æ®\"\n",
    "            \n",
    "            print(f\"âœ… OCRè¯†åˆ«å®Œæˆï¼Œå…±è¯†åˆ«{len(results)}è¡Œæ–‡å­—\")\n",
    "            return result_text, csv_path\n",
    "            \n",
    "        except Exception as e:\n",
    "            error_message = f\"âŒ å›¾åƒå¤„ç†å¤±è´¥: {str(e)}\\\\n\\\\n\"\n",
    "            error_message += \"ğŸ”§ å¯èƒ½çš„è§£å†³æ–¹æ¡ˆ:\\\\n\"\n",
    "            error_message += \"1. å°è¯•ä¸Šä¼ ä¸åŒæ ¼å¼çš„å›¾åƒï¼ˆPNGã€JPGï¼‰\\\\n\"\n",
    "            error_message += \"2. ç¡®ä¿å›¾åƒæ–‡ä»¶æ²¡æœ‰æŸå\\\\n\"\n",
    "            error_message += \"3. æ£€æŸ¥å›¾åƒå°ºå¯¸æ˜¯å¦åˆç†ï¼ˆå»ºè®®<10MBï¼‰\\\\n\"\n",
    "            error_message += \"4. é‡æ–°è¿è¡Œnotebookå¹¶é‡è¯•\\\\n\"\n",
    "            \n",
    "            import traceback\n",
    "            print(f\"âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}\")\n",
    "            \n",
    "            return error_message, None\n",
    "    \n",
    "    # åˆ›å»ºç•Œé¢\n",
    "    print(\"ğŸ¨ æ„å»ºGradioç•Œé¢ç»„ä»¶...\")\n",
    "    \n",
    "    interface = gr.Interface(\n",
    "        fn=process_uploaded_image,\n",
    "        inputs=[\n",
    "            gr.Image(\n",
    "                label=\"ğŸ“¤ ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒ\", \n",
    "                type=\"numpy\",  # ä½¿ç”¨numpyæ ¼å¼ä¾¿äºå¤„ç†\n",
    "                sources=[\"upload\", \"clipboard\"],  # æ”¯æŒä¸Šä¼ å’Œå‰ªè´´æ¿\n",
    "                format=\"png\"  # ç»Ÿä¸€ä½¿ç”¨PNGæ ¼å¼\n",
    "            )\n",
    "        ],\n",
    "        outputs=[\n",
    "            gr.Textbox(\n",
    "                label=\"ğŸ“Š OCRè¯†åˆ«ç»“æœ\", \n",
    "                lines=20,\n",
    "                max_lines=30,\n",
    "                show_copy_button=True\n",
    "            ),\n",
    "            gr.File(\n",
    "                label=\"ğŸ“¥ ä¸‹è½½CSVç»“æœæ–‡ä»¶\",\n",
    "                file_types=[\".csv\"]\n",
    "            )\n",
    "        ],\n",
    "        title=\"ğŸ¥ åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«ç³»ç»Ÿ\",\n",
    "        description=\"\"\"\n",
    "        **ğŸ¯ åŠŸèƒ½è¯´æ˜**: ä¸Šä¼ åŒ»ç–—æ–‡æ¡£å›¾åƒï¼Œè‡ªåŠ¨è¯†åˆ«å…¶ä¸­çš„æ–‡å­—å†…å®¹å¹¶ç”ŸæˆCSVæŠ¥å‘Š\n",
    "        \n",
    "        **ğŸ“‹ æ”¯æŒæ ¼å¼**: PNGã€JPGã€JPEGç­‰å¸¸è§å›¾åƒæ ¼å¼\n",
    "        \n",
    "        **ğŸŒŸ ç‰¹è‰²åŠŸèƒ½**: \n",
    "        â€¢ æ”¯æŒä¸­è‹±æ–‡æ··åˆè¯†åˆ«  \n",
    "        â€¢ è‡ªåŠ¨ç½®ä¿¡åº¦è¯„ä¼°  \n",
    "        â€¢ ç»“æ„åŒ–CSVè¾“å‡º  \n",
    "        â€¢ é«˜ç²¾åº¦OCRå¼•æ“\n",
    "        \n",
    "        **ğŸ’¡ ä½¿ç”¨æç¤º**: \n",
    "        â€¢ ç¡®ä¿å›¾åƒæ¸…æ™°ï¼Œæ–‡å­—å¤§å°é€‚ä¸­\n",
    "        â€¢ é¿å…å›¾åƒè¿‡æš—æˆ–è¿‡äº®\n",
    "        â€¢ å»ºè®®æ–‡æ¡£å¹³æ•´ï¼Œé¿å…ä¸¥é‡å€¾æ–œ\n",
    "        \"\"\",\n",
    "        examples=[\n",
    "            # æ³¨æ„ï¼šåœ¨Colabç¯å¢ƒä¸­ï¼Œç¤ºä¾‹è·¯å¾„å¯èƒ½éœ€è¦è°ƒæ•´\n",
    "        ],\n",
    "        theme=\"soft\",\n",
    "        css=\"\"\"\n",
    "        .gradio-container {\n",
    "            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;\n",
    "        }\n",
    "        .output-text {\n",
    "            font-family: 'Courier New', monospace;\n",
    "        }\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    return interface\n",
    "\n",
    "# åˆ›å»ºå¹¶å¯åŠ¨ç•Œé¢\n",
    "print(\"ğŸŒ å‡†å¤‡å¯åŠ¨äº¤äº’ç•Œé¢...\")\n",
    "try:\n",
    "    interface = create_gradio_interface()\n",
    "    \n",
    "    if interface:\n",
    "        print(\"âœ… Gradioç•Œé¢åˆ›å»ºæˆåŠŸ!\")\n",
    "        print(\"ğŸš€ å¯åŠ¨WebæœåŠ¡...\")\n",
    "        print(\"â° è¯·ç¨å€™ï¼Œæ­£åœ¨åˆå§‹åŒ–ç•Œé¢ç»„ä»¶...\")\n",
    "        \n",
    "        # å¯åŠ¨ç•Œé¢ï¼Œå¢åŠ é”™è¯¯å¤„ç†\n",
    "        interface.launch(\n",
    "            share=True,      # ç”Ÿæˆå…¬å¼€é“¾æ¥\n",
    "            debug=False,     # å…³é—­debugæ¨¡å¼é¿å…è¿‡å¤šæ—¥å¿—\n",
    "            show_error=True, # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯\n",
    "            server_port=7860, # æŒ‡å®šç«¯å£\n",
    "            inbrowser=True,  # è‡ªåŠ¨æ‰“å¼€æµè§ˆå™¨\n",
    "            quiet=False      # æ˜¾ç¤ºå¯åŠ¨ä¿¡æ¯\n",
    "        )\n",
    "        \n",
    "        print(\"ğŸ‰ ç•Œé¢å·²æˆåŠŸå¯åŠ¨!\")\n",
    "        print(\"ğŸ“± å¯ä»¥å¼€å§‹ä¸Šä¼ å›¾åƒè¿›è¡ŒOCRè¯†åˆ«äº†\")\n",
    "        \n",
    "    else:\n",
    "        print(\"âŒ ç•Œé¢åˆ›å»ºå¤±è´¥\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯åŠ¨ç•Œé¢æ—¶å‡ºç°é”™è¯¯: {str(e)}\")\n",
    "    print(\"ğŸ”§ è¯·å°è¯•é‡æ–°è¿è¡Œæ­¤ä»£ç å—\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# é¡¹ç›®æ€»ç»“å’Œä½¿ç”¨æŒ‡å—\n",
    "# ================================\n",
    "\n",
    "def show_project_summary():\n",
    "    \"\"\"æ˜¾ç¤ºé¡¹ç›®æ€»ç»“å’Œä½¿ç”¨æŒ‡å—\"\"\"\n",
    "    \n",
    "    summary = \"\"\" # type: ignore\n",
    "ğŸ‰ åŒ»ç–—æ–‡æ¡£OCRè¯†åˆ«æ¼”ç¤ºé¡¹ç›®è¿è¡Œå®Œæˆ!\n",
    "\n",
    "ğŸ“‹ é¡¹ç›®åŠŸèƒ½æ€»ç»“:\n",
    "âœ… åŒ»ç–—æ–‡æ¡£å›¾åƒæ–‡å­—è¯†åˆ«\n",
    "âœ… ä¸­è‹±æ–‡æ··åˆæ–‡å­—è¯†åˆ«\n",
    "âœ… æ‰¹é‡å›¾åƒå¤„ç†æ”¯æŒ\n",
    "âœ… CSVæ ¼å¼ç»“æœå¯¼å‡º\n",
    "âœ… ç½®ä¿¡åº¦è¯„ä¼°\n",
    "âœ… ç”¨æˆ·å‹å¥½çš„äº¤äº’ç•Œé¢\n",
    "\n",
    "ğŸ› ï¸ æŠ€æœ¯ç‰¹æ€§:\n",
    "â€¢ åŸºäºPaddleOCRé«˜ç²¾åº¦è¯†åˆ«å¼•æ“\n",
    "â€¢ æ”¯æŒGPUåŠ é€Ÿå¤„ç†\n",
    "â€¢ è‡ªåŠ¨è§’åº¦æ£€æµ‹å’ŒçŸ«æ­£\n",
    "â€¢ ç»“æ„åŒ–æ•°æ®è¾“å‡º\n",
    "\n",
    "ğŸ“– ä½¿ç”¨åœºæ™¯:\n",
    "â€¢ åŒ»ç–—å¤„æ–¹è¯†åˆ«\n",
    "â€¢ ç—…å†æ–‡æ¡£æ•°å­—åŒ–\n",
    "â€¢ æ£€æŸ¥æŠ¥å‘Šæå–\n",
    "â€¢ åŒ»ç–—æ¡£æ¡ˆç®¡ç†\n",
    "\n",
    "ğŸ”— é¡¹ç›®åœ°å€:\n",
    "GitHub: https://github.com/zhurong2020/mcr\n",
    "Colab: å½“å‰notebooké“¾æ¥\n",
    "\n",
    "ğŸ‘¨â€âš•ï¸ é€‚ç”¨ç”¨æˆ·:\n",
    "â€¢ åŒ»ç–—å·¥ä½œè€…\n",
    "â€¢ æ•°æ®åˆ†æå¸ˆ\n",
    "â€¢ ç ”ç©¶äººå‘˜\n",
    "â€¢ å¼€å‘è€…\n",
    "\n",
    "âš ï¸ ä½¿ç”¨è¯´æ˜:\n",
    "1. ç¡®ä¿å›¾åƒæ¸…æ™°å¯è¯»\n",
    "2. æ”¯æŒPNGã€JPGç­‰å¸¸è§æ ¼å¼\n",
    "3. æ‰¹é‡å¤„ç†æ—¶æ³¨æ„æ–‡ä»¶å¤§å°\n",
    "4. ç»“æœä»…ä¾›å‚è€ƒï¼Œé‡è¦ä¿¡æ¯è¯·äººå·¥æ ¸éªŒ\n",
    "\n",
    "ğŸ’¡ æŠ€æœ¯æ”¯æŒ:\n",
    "å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œæ¬¢è¿åé¦ˆäº¤æµï¼\n",
    "    \"\"\"\n",
    "    \n",
    "    print(summary)\n",
    "\n",
    "# æ˜¾ç¤ºé¡¹ç›®æ€»ç»“\n",
    "show_project_summary()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "medical-ocr-demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
